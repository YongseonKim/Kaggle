{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 types of energy to predict <br>\n",
    "    - 0 : electricity\n",
    "    - 1 : chilledwater\n",
    "    - 2 : steam\n",
    "    - 3 : hotwater\n",
    "\n",
    "Electricity and water consumption may have different behavior!<br>\n",
    "     - I will make separately train & predict the model\n",
    "\n",
    "* Reference \n",
    " - https://www.kaggle.com/corochann/ashrae-training-lgbm-by-meter-type\n",
    " - https://www.kaggle.com/caesarlupum/ashrae-start-here-a-gentle-introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No leak data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 파일 읽어오기\n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_df['timestamp'] = pd.to_datetime(train_df['timestamp'], format = '%Y-%m-%d %H:%M:%S')\n",
    "weather_train_df = pd.read_csv('weather_train.csv')\n",
    "\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_df['timestamp'] = pd.to_datetime(test_df['timestamp'], format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "weather_test_df = pd.read_csv('weather_test.csv')\n",
    "building_meta_df = pd.read_csv('building_metadata.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20216100, 4)\n",
      "(139773, 9)\n",
      "(277243, 9)\n",
      "(1449, 6)\n",
      "(41697600, 4)\n"
     ]
    }
   ],
   "source": [
    "# Glimpse of Data\n",
    "print(train_df.shape)\n",
    "print(weather_train_df.shape)\n",
    "print(weather_test_df.shape)\n",
    "print(building_meta_df.shape)\n",
    "\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 289.19 Mb (53.1% reduction)\n",
      "Mem. usage decreased to 596.49 Mb (53.1% reduction)\n",
      "Mem. usage decreased to  3.07 Mb (68.1% reduction)\n",
      "Mem. usage decreased to  6.08 Mb (68.1% reduction)\n",
      "Mem. usage decreased to  0.03 Mb (60.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Reducing memory\n",
    "train_df = reduce_mem_usage(train_df)\n",
    "test_df = reduce_mem_usage(test_df)\n",
    "\n",
    "weather_train_df = reduce_mem_usage(weather_train_df)\n",
    "weather_test_df = reduce_mem_usage(weather_test_df)\n",
    "building_meta_df = reduce_mem_usage(building_meta_df)ㅏㅏ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_date_usage(train_df, meter=0, building_id=0):\n",
    "    train_temp_df = train_df[train_df['meter'] == meter]\n",
    "    train_temp_df = train_temp_df[train_temp_df['building_id'] == building_id]    \n",
    "    train_temp_df_meter = train_temp_df.groupby('date')['meter_reading_log1p'].sum()\n",
    "    train_temp_df_meter = train_temp_df_meter.to_frame().reset_index()\n",
    "    fig = px.line(train_temp_df_meter, x='date', y='meter_reading_log1p')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering \n",
    "  - There are 3 parts to make features <br>\n",
    "      train_df / weather_train_df / building_meta_df\n",
    "  - and then I will merge them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df -- timestamp : 월 , 주, 일\n",
    "\n",
    "train_df['meter_reading_log1p'] = np.log1p(train_df['meter_reading'])\n",
    "# train_df['meter_reading']\n",
    "# date / 월 / 주 /일 \n",
    "train_df['date'] = train_df['timestamp'].dt.date\n",
    "train_df['hour'] = train_df['timestamp'].dt.hour\n",
    "train_df['weekend'] = train_df['timestamp'].dt.weekday\n",
    "train_df['month'] = train_df['timestamp'].dt.month\n",
    "train_df['dayofweek'] = train_df['timestamp'].dt.dayofweek\n",
    "\n",
    "\n",
    "test_df['date'] = test_df['timestamp'].dt.date\n",
    "test_df['hour'] = test_df['timestamp'].dt.hour\n",
    "test_df['weekend'] = test_df['timestamp'].dt.weekday\n",
    "test_df['month'] = test_df['timestamp'].dt.month\n",
    "test_df['dayofweek'] = test_df['timestamp'].dt.dayofweek\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_id                   0\n",
       "timestamp                 0\n",
       "air_temperature          55\n",
       "cloud_coverage        69173\n",
       "dew_temperature         113\n",
       "precip_depth_1_hr     50289\n",
       "sea_level_pressure    10618\n",
       "wind_direction         6268\n",
       "wind_speed              304\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "weather_train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather - \n",
    "# weather data has a lot of nulls \n",
    "# I tried to fill these values by interpolating data\n",
    "# df.groupby('').apply(lambda group: group.interpolate~~)\n",
    "\n",
    "weather_train_df.head()\n",
    "weather_train_df = weather_train_df.groupby('site_id').apply\\\n",
    "                    (lambda group : group.interpolate(limit_direction='both'))\n",
    "weather_test_df = weather_test_df.groupby('site_id').apply\\\n",
    "                    (lambda group : group.interpolate(limit_direction='both'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_id                   0\n",
       "timestamp                 0\n",
       "air_temperature           0\n",
       "cloud_coverage        17228\n",
       "dew_temperature           0\n",
       "precip_depth_1_hr     26273\n",
       "sea_level_pressure     8755\n",
       "wind_direction            0\n",
       "wind_speed                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "weather_train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lags \n",
    "# site 별로 최근 3일간의 날씨를 rolling 하기\n",
    "def add_lag_feature(weather_df, window=3):\n",
    "    group_df = weather_df.groupby('site_id')\n",
    "    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "    rolled = group_df[cols].rolling(window=window, min_periods=0)\n",
    "    lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "    lag_max = rolled.max().reset_index().astype(np.float16)\n",
    "    lag_min = rolled.min().reset_index().astype(np.float16)\n",
    "    lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "    for col in cols:\n",
    "        weather_df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
    "        weather_df[f'{col}_max_lag{window}'] = lag_max[col]\n",
    "        weather_df[f'{col}_min_lag{window}'] = lag_min[col]\n",
    "        weather_df[f'{col}_std_lag{window}'] = lag_std[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_lag_feature(weather_train_df, window=3)\n",
    "add_lag_feature(weather_train_df, window=72)\n",
    "add_lag_feature(weather_test_df, window=3)\n",
    "add_lag_feature(weather_test_df, window=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # meter reading 값에 대한 aggregation\n",
    "# 과적합 문제를 야기할 수 있다.\n",
    "# df_group = train_df.groupby('building_id')['meter_reading_log1p']\n",
    "# building_mean = df_group.mean().astype(np.float16)\n",
    "# building_median = df_group.median().astype(np.float16)\n",
    "# building_min = df_group.min().astype(np.float16)\n",
    "# building_max = df_group.max().astype(np.float16)\n",
    "# building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "# train_df['building_mean'] = train_df['building_id'].map(building_mean)\n",
    "# train_df['building_median'] = train_df['building_id'].map(building_median)\n",
    "# train_df['building_min'] = train_df['building_id'].map(building_min)\n",
    "# train_df['building_max'] = train_df['building_id'].map(building_max)\n",
    "# train_df['building_std'] = train_df['building_id'].map(building_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing weired data on site_id =0  \n",
    "#https://www.kaggle.com/c/ashrae-energy-prediction/discussion/113054#656588\n",
    "# building_meta_df[building_meta_df.site_id == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나에 합치기\n",
    "\n",
    "# base + building_meta_df 합치기\n",
    "train_df = pd.merge(train_df,building_meta_df, on= ['building_id'],how='left')\n",
    "test_df = pd.merge(test_df,building_meta_df, on= ['building_id'],how='left')\n",
    "# del building_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base + weather_train_df 합치기\n",
    "weather_train_df['timestamp'] = pd.to_datetime(weather_train_df['timestamp'], format = '%Y-%m-%d %H:%M:%S')\n",
    "weather_test_df['timestamp'] = pd.to_datetime(weather_test_df['timestamp'], format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "train_df = pd.merge(train_df,weather_train_df, on= ['site_id','timestamp'],how='left')\n",
    "test_df = pd.merge(test_df,weather_test_df, on= ['site_id','timestamp'],how='left')\n",
    "# del weather_train_df, weather_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoidng variables\n",
    "le = LabelEncoder()\n",
    "# train_df['primary_use'] = train_df['primary_use'].astype(str)\n",
    "train_df['primary_use'] = le.fit_transform(train_df['primary_use']).astype(np.int8)\n",
    "\n",
    "# test_df['primary_use'] = test_df['primary_use'].astype(str)\n",
    "test_df['primary_use'] = le.fit_transform(test_df['primary_use']).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle 저장\n",
    "\n",
    "train_df.to_pickle('train_df.pkl')\n",
    "test_df.to_pickle('test_df.pkl')\n",
    "del train_df, test_df\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('train_df.pkl')\n",
    "test_df = pd.read_pickle('test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some feature enginnering\n",
    "\n",
    "train_df['age'] = train_df['year_built'].max()-train_df['year_built']+1\n",
    "test_df['age'] = test_df['year_built'].max() - test_df['year_built'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values\n",
    "# To streamline this though process it is useful to know the 3 categories in which missing data can be classified into:\n",
    "\n",
    "# Missing Completely at Random (MCAR)\n",
    "# Missing at Random (MAR)\n",
    "# Missing Not at Random (MNAR)\n",
    "\n",
    "train_df['floor_count'] = train_df['floor_count'].fillna(-999).astype(np.int16)\n",
    "test_df['floor_count'] = test_df['floor_count'].fillna(-999).astype(np.int16)\n",
    "\n",
    "train_df['year_built'] = train_df['year_built'].fillna(-999).astype(np.int16)\n",
    "test_df['year_built'] = test_df['year_built'].fillna(-999).astype(np.int16)\n",
    "\n",
    "train_df['age'] = train_df['age'].fillna(-999).astype(np.int16)\n",
    "test_df['age'] = test_df['age'].fillna(-999).astype(np.int16)\n",
    "\n",
    "train_df['cloud_coverage'] = train_df['cloud_coverage'].fillna(-999).astype(np.int16)\n",
    "test_df['cloud_coverage'] = test_df['cloud_coverage'].fillna(-999).astype(np.int16) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['date',\"precip_depth_1_hr\", \"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"timestamp\"]\n",
    "target = train_df[\"meter_reading_log1p\"]\n",
    "del train_df[\"meter_reading\"], train_df['meter_reading_log1p']\n",
    "train_df = train_df.drop(drop_cols, axis=1)\n",
    "drop_cols += [\"row_id\"]\n",
    "# drop_cols.remove('date')\n",
    "test_df = test_df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "# lightbgm\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'},\n",
    "    'subsample': 0.2,\n",
    "    'learning_rate': 0.08,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'alpha': 0.1,\n",
    "    'lambda': 0.1,\n",
    "#     'n_jobs' :2 \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's l2: 1.7285\tvalid_1's l2: 1.79002\n",
      "[200]\ttraining's l2: 1.4249\tvalid_1's l2: 1.51282\n",
      "[300]\ttraining's l2: 1.25619\tvalid_1's l2: 1.38777\n",
      "[400]\ttraining's l2: 1.14175\tvalid_1's l2: 1.32339\n",
      "[500]\ttraining's l2: 1.05464\tvalid_1's l2: 1.26608\n",
      "[600]\ttraining's l2: 0.985798\tvalid_1's l2: 1.22718\n",
      "[700]\ttraining's l2: 0.928841\tvalid_1's l2: 1.19618\n",
      "[800]\ttraining's l2: 0.879244\tvalid_1's l2: 1.16181\n",
      "[900]\ttraining's l2: 0.841594\tvalid_1's l2: 1.13917\n",
      "[1000]\ttraining's l2: 0.810244\tvalid_1's l2: 1.11513\n",
      "[1100]\ttraining's l2: 0.777291\tvalid_1's l2: 1.09244\n",
      "[1200]\ttraining's l2: 0.753447\tvalid_1's l2: 1.07734\n",
      "[1300]\ttraining's l2: 0.731369\tvalid_1's l2: 1.06069\n",
      "[1400]\ttraining's l2: 0.714583\tvalid_1's l2: 1.05059\n",
      "[1500]\ttraining's l2: 0.696367\tvalid_1's l2: 1.0338\n",
      "[1600]\ttraining's l2: 0.678759\tvalid_1's l2: 1.02048\n",
      "[1700]\ttraining's l2: 0.660927\tvalid_1's l2: 1.00647\n",
      "[1800]\ttraining's l2: 0.646317\tvalid_1's l2: 0.994278\n",
      "[1900]\ttraining's l2: 0.631277\tvalid_1's l2: 0.981434\n",
      "[2000]\ttraining's l2: 0.619259\tvalid_1's l2: 0.977852\n",
      "[2100]\ttraining's l2: 0.60941\tvalid_1's l2: 0.970886\n",
      "[2200]\ttraining's l2: 0.599294\tvalid_1's l2: 0.964703\n",
      "[2300]\ttraining's l2: 0.58904\tvalid_1's l2: 0.961077\n",
      "[2400]\ttraining's l2: 0.581521\tvalid_1's l2: 0.952142\n",
      "[2500]\ttraining's l2: 0.574642\tvalid_1's l2: 0.949396\n",
      "[2600]\ttraining's l2: 0.566042\tvalid_1's l2: 0.944569\n",
      "[2700]\ttraining's l2: 0.556694\tvalid_1's l2: 0.941309\n",
      "[2800]\ttraining's l2: 0.548941\tvalid_1's l2: 0.938109\n",
      "[2900]\ttraining's l2: 0.541714\tvalid_1's l2: 0.932597\n",
      "[3000]\ttraining's l2: 0.535545\tvalid_1's l2: 0.92903\n",
      "[3100]\ttraining's l2: 0.530102\tvalid_1's l2: 0.927056\n",
      "[3200]\ttraining's l2: 0.523247\tvalid_1's l2: 0.921086\n",
      "[3300]\ttraining's l2: 0.516099\tvalid_1's l2: 0.916871\n",
      "[3400]\ttraining's l2: 0.509662\tvalid_1's l2: 0.913138\n",
      "[3500]\ttraining's l2: 0.504343\tvalid_1's l2: 0.90992\n",
      "[3600]\ttraining's l2: 0.499982\tvalid_1's l2: 0.90768\n",
      "[3700]\ttraining's l2: 0.495085\tvalid_1's l2: 0.905141\n",
      "[3800]\ttraining's l2: 0.490995\tvalid_1's l2: 0.902724\n",
      "[3900]\ttraining's l2: 0.486895\tvalid_1's l2: 0.901382\n",
      "[4000]\ttraining's l2: 0.482946\tvalid_1's l2: 0.898529\n",
      "[4100]\ttraining's l2: 0.478208\tvalid_1's l2: 0.895376\n",
      "[4200]\ttraining's l2: 0.474532\tvalid_1's l2: 0.894128\n",
      "[4300]\ttraining's l2: 0.469158\tvalid_1's l2: 0.891751\n",
      "[4400]\ttraining's l2: 0.465015\tvalid_1's l2: 0.889756\n",
      "[4500]\ttraining's l2: 0.461143\tvalid_1's l2: 0.887623\n",
      "[4600]\ttraining's l2: 0.457789\tvalid_1's l2: 0.886659\n",
      "[4700]\ttraining's l2: 0.453734\tvalid_1's l2: 0.884761\n",
      "[4800]\ttraining's l2: 0.448818\tvalid_1's l2: 0.88346\n",
      "[4900]\ttraining's l2: 0.44507\tvalid_1's l2: 0.882129\n",
      "[5000]\ttraining's l2: 0.440862\tvalid_1's l2: 0.880213\n",
      "[5100]\ttraining's l2: 0.436924\tvalid_1's l2: 0.879298\n",
      "[5200]\ttraining's l2: 0.434188\tvalid_1's l2: 0.878955\n",
      "[5300]\ttraining's l2: 0.431003\tvalid_1's l2: 0.877907\n",
      "[5400]\ttraining's l2: 0.427784\tvalid_1's l2: 0.877525\n",
      "[5500]\ttraining's l2: 0.424443\tvalid_1's l2: 0.876789\n",
      "[5600]\ttraining's l2: 0.421715\tvalid_1's l2: 0.876225\n",
      "[5700]\ttraining's l2: 0.419287\tvalid_1's l2: 0.875663\n",
      "[5800]\ttraining's l2: 0.416686\tvalid_1's l2: 0.874382\n",
      "[5900]\ttraining's l2: 0.414258\tvalid_1's l2: 0.873098\n",
      "[6000]\ttraining's l2: 0.411794\tvalid_1's l2: 0.871828\n",
      "[6100]\ttraining's l2: 0.409411\tvalid_1's l2: 0.870659\n",
      "[6200]\ttraining's l2: 0.406744\tvalid_1's l2: 0.869793\n",
      "[6300]\ttraining's l2: 0.404495\tvalid_1's l2: 0.868734\n",
      "[6400]\ttraining's l2: 0.402255\tvalid_1's l2: 0.86815\n",
      "[6500]\ttraining's l2: 0.399865\tvalid_1's l2: 0.867786\n",
      "[6600]\ttraining's l2: 0.397369\tvalid_1's l2: 0.866963\n",
      "[6700]\ttraining's l2: 0.395015\tvalid_1's l2: 0.867134\n",
      "[6800]\ttraining's l2: 0.392861\tvalid_1's l2: 0.866573\n",
      "[6900]\ttraining's l2: 0.390544\tvalid_1's l2: 0.865572\n",
      "[7000]\ttraining's l2: 0.388718\tvalid_1's l2: 0.864616\n",
      "[7100]\ttraining's l2: 0.386802\tvalid_1's l2: 0.863078\n",
      "[7200]\ttraining's l2: 0.384126\tvalid_1's l2: 0.862402\n",
      "[7300]\ttraining's l2: 0.382311\tvalid_1's l2: 0.861365\n",
      "[7400]\ttraining's l2: 0.380153\tvalid_1's l2: 0.860157\n",
      "[7500]\ttraining's l2: 0.378017\tvalid_1's l2: 0.858684\n",
      "[7600]\ttraining's l2: 0.376077\tvalid_1's l2: 0.858181\n",
      "[7700]\ttraining's l2: 0.37432\tvalid_1's l2: 0.857335\n",
      "[7800]\ttraining's l2: 0.372581\tvalid_1's l2: 0.856765\n",
      "[7900]\ttraining's l2: 0.370822\tvalid_1's l2: 0.856323\n",
      "[8000]\ttraining's l2: 0.368873\tvalid_1's l2: 0.8558\n",
      "[8100]\ttraining's l2: 0.367209\tvalid_1's l2: 0.855321\n",
      "[8200]\ttraining's l2: 0.365685\tvalid_1's l2: 0.854547\n",
      "[8300]\ttraining's l2: 0.364052\tvalid_1's l2: 0.854087\n",
      "[8400]\ttraining's l2: 0.362521\tvalid_1's l2: 0.854039\n",
      "[8500]\ttraining's l2: 0.361218\tvalid_1's l2: 0.853913\n",
      "[8600]\ttraining's l2: 0.359975\tvalid_1's l2: 0.852905\n",
      "[8700]\ttraining's l2: 0.358594\tvalid_1's l2: 0.852486\n",
      "[8800]\ttraining's l2: 0.356936\tvalid_1's l2: 0.851631\n",
      "[8900]\ttraining's l2: 0.355427\tvalid_1's l2: 0.851072\n",
      "[9000]\ttraining's l2: 0.354358\tvalid_1's l2: 0.850544\n",
      "[9100]\ttraining's l2: 0.353262\tvalid_1's l2: 0.850411\n",
      "[9200]\ttraining's l2: 0.351825\tvalid_1's l2: 0.849853\n",
      "[9300]\ttraining's l2: 0.350077\tvalid_1's l2: 0.849576\n",
      "[9400]\ttraining's l2: 0.348518\tvalid_1's l2: 0.84914\n",
      "[9500]\ttraining's l2: 0.347196\tvalid_1's l2: 0.848421\n",
      "[9600]\ttraining's l2: 0.345725\tvalid_1's l2: 0.847662\n",
      "[9700]\ttraining's l2: 0.344202\tvalid_1's l2: 0.847258\n",
      "[9800]\ttraining's l2: 0.342947\tvalid_1's l2: 0.846741\n",
      "[9900]\ttraining's l2: 0.341823\tvalid_1's l2: 0.846565\n",
      "[10000]\ttraining's l2: 0.340473\tvalid_1's l2: 0.846367\n",
      "[10100]\ttraining's l2: 0.338898\tvalid_1's l2: 0.845955\n",
      "[10200]\ttraining's l2: 0.337576\tvalid_1's l2: 0.845449\n",
      "[10300]\ttraining's l2: 0.336091\tvalid_1's l2: 0.844956\n",
      "[10400]\ttraining's l2: 0.335078\tvalid_1's l2: 0.844513\n",
      "[10500]\ttraining's l2: 0.334106\tvalid_1's l2: 0.844317\n",
      "[10600]\ttraining's l2: 0.333131\tvalid_1's l2: 0.844126\n",
      "[10700]\ttraining's l2: 0.331895\tvalid_1's l2: 0.843661\n",
      "[10800]\ttraining's l2: 0.330621\tvalid_1's l2: 0.843496\n",
      "[10900]\ttraining's l2: 0.329488\tvalid_1's l2: 0.843225\n",
      "[11000]\ttraining's l2: 0.328579\tvalid_1's l2: 0.84298\n",
      "[11100]\ttraining's l2: 0.327315\tvalid_1's l2: 0.843063\n",
      "[11200]\ttraining's l2: 0.326306\tvalid_1's l2: 0.842795\n",
      "[11300]\ttraining's l2: 0.325223\tvalid_1's l2: 0.842651\n",
      "[11400]\ttraining's l2: 0.324368\tvalid_1's l2: 0.842968\n",
      "[11500]\ttraining's l2: 0.323553\tvalid_1's l2: 0.842779\n",
      "Early stopping, best iteration is:\n",
      "[11268]\ttraining's l2: 0.325484\tvalid_1's l2: 0.842527\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's l2: 1.74123\tvalid_1's l2: 1.8761\n",
      "[200]\ttraining's l2: 1.44281\tvalid_1's l2: 1.61833\n",
      "[300]\ttraining's l2: 1.27451\tvalid_1's l2: 1.47902\n",
      "[400]\ttraining's l2: 1.1486\tvalid_1's l2: 1.36904\n",
      "[500]\ttraining's l2: 1.05739\tvalid_1's l2: 1.30225\n",
      "[600]\ttraining's l2: 0.982925\tvalid_1's l2: 1.24143\n",
      "[700]\ttraining's l2: 0.930111\tvalid_1's l2: 1.20351\n",
      "[800]\ttraining's l2: 0.884661\tvalid_1's l2: 1.16692\n",
      "[900]\ttraining's l2: 0.842356\tvalid_1's l2: 1.12937\n",
      "[1000]\ttraining's l2: 0.811122\tvalid_1's l2: 1.10321\n",
      "[1100]\ttraining's l2: 0.779929\tvalid_1's l2: 1.07827\n",
      "[1200]\ttraining's l2: 0.754164\tvalid_1's l2: 1.05839\n",
      "[1300]\ttraining's l2: 0.730356\tvalid_1's l2: 1.04002\n",
      "[1400]\ttraining's l2: 0.709582\tvalid_1's l2: 1.0264\n",
      "[1500]\ttraining's l2: 0.691763\tvalid_1's l2: 1.01281\n",
      "[1600]\ttraining's l2: 0.673056\tvalid_1's l2: 0.999075\n",
      "[1700]\ttraining's l2: 0.659141\tvalid_1's l2: 0.986603\n",
      "[1800]\ttraining's l2: 0.642449\tvalid_1's l2: 0.971898\n",
      "[1900]\ttraining's l2: 0.626445\tvalid_1's l2: 0.959207\n",
      "[2000]\ttraining's l2: 0.617362\tvalid_1's l2: 0.951668\n",
      "[2100]\ttraining's l2: 0.606587\tvalid_1's l2: 0.944377\n",
      "[2200]\ttraining's l2: 0.595963\tvalid_1's l2: 0.93495\n",
      "[2300]\ttraining's l2: 0.584753\tvalid_1's l2: 0.925738\n",
      "[2400]\ttraining's l2: 0.575127\tvalid_1's l2: 0.918308\n",
      "[2500]\ttraining's l2: 0.566467\tvalid_1's l2: 0.914145\n",
      "[2600]\ttraining's l2: 0.558518\tvalid_1's l2: 0.909163\n",
      "[2700]\ttraining's l2: 0.550393\tvalid_1's l2: 0.90468\n",
      "[2800]\ttraining's l2: 0.543099\tvalid_1's l2: 0.901511\n",
      "[2900]\ttraining's l2: 0.535054\tvalid_1's l2: 0.896513\n",
      "[3000]\ttraining's l2: 0.527166\tvalid_1's l2: 0.891977\n",
      "[3100]\ttraining's l2: 0.518797\tvalid_1's l2: 0.885677\n",
      "[3200]\ttraining's l2: 0.511959\tvalid_1's l2: 0.881203\n",
      "[3300]\ttraining's l2: 0.506511\tvalid_1's l2: 0.877135\n",
      "[3400]\ttraining's l2: 0.501246\tvalid_1's l2: 0.874016\n",
      "[3500]\ttraining's l2: 0.495898\tvalid_1's l2: 0.869322\n",
      "[3600]\ttraining's l2: 0.491068\tvalid_1's l2: 0.866191\n",
      "[3700]\ttraining's l2: 0.486656\tvalid_1's l2: 0.863881\n",
      "[3800]\ttraining's l2: 0.482116\tvalid_1's l2: 0.861505\n",
      "[3900]\ttraining's l2: 0.476613\tvalid_1's l2: 0.858777\n",
      "[4000]\ttraining's l2: 0.471868\tvalid_1's l2: 0.856215\n",
      "[4100]\ttraining's l2: 0.467428\tvalid_1's l2: 0.854673\n",
      "[4200]\ttraining's l2: 0.463437\tvalid_1's l2: 0.852492\n",
      "[4300]\ttraining's l2: 0.459412\tvalid_1's l2: 0.85087\n",
      "[4400]\ttraining's l2: 0.455349\tvalid_1's l2: 0.848058\n",
      "[4500]\ttraining's l2: 0.451791\tvalid_1's l2: 0.846079\n",
      "[4600]\ttraining's l2: 0.447715\tvalid_1's l2: 0.843235\n",
      "[4700]\ttraining's l2: 0.443688\tvalid_1's l2: 0.841324\n",
      "[4800]\ttraining's l2: 0.440382\tvalid_1's l2: 0.839835\n",
      "[4900]\ttraining's l2: 0.436103\tvalid_1's l2: 0.836421\n",
      "[5000]\ttraining's l2: 0.431268\tvalid_1's l2: 0.832396\n",
      "[5100]\ttraining's l2: 0.428364\tvalid_1's l2: 0.830963\n",
      "[5200]\ttraining's l2: 0.424996\tvalid_1's l2: 0.829259\n",
      "[5300]\ttraining's l2: 0.42247\tvalid_1's l2: 0.828201\n",
      "[5400]\ttraining's l2: 0.419798\tvalid_1's l2: 0.826681\n",
      "[5500]\ttraining's l2: 0.417306\tvalid_1's l2: 0.825591\n",
      "[5600]\ttraining's l2: 0.414814\tvalid_1's l2: 0.824347\n",
      "[5700]\ttraining's l2: 0.41207\tvalid_1's l2: 0.823476\n",
      "[5800]\ttraining's l2: 0.408874\tvalid_1's l2: 0.821759\n",
      "[5900]\ttraining's l2: 0.406649\tvalid_1's l2: 0.821071\n",
      "[6000]\ttraining's l2: 0.404165\tvalid_1's l2: 0.8196\n",
      "[6100]\ttraining's l2: 0.401502\tvalid_1's l2: 0.818553\n",
      "[6200]\ttraining's l2: 0.399002\tvalid_1's l2: 0.816904\n",
      "[6300]\ttraining's l2: 0.395906\tvalid_1's l2: 0.815372\n",
      "[6400]\ttraining's l2: 0.39402\tvalid_1's l2: 0.813764\n",
      "[6500]\ttraining's l2: 0.391328\tvalid_1's l2: 0.812797\n",
      "[6600]\ttraining's l2: 0.388825\tvalid_1's l2: 0.811672\n",
      "[6700]\ttraining's l2: 0.386767\tvalid_1's l2: 0.810878\n",
      "[6800]\ttraining's l2: 0.383912\tvalid_1's l2: 0.809755\n",
      "[6900]\ttraining's l2: 0.381962\tvalid_1's l2: 0.809112\n",
      "[7000]\ttraining's l2: 0.379713\tvalid_1's l2: 0.808049\n",
      "[7100]\ttraining's l2: 0.377629\tvalid_1's l2: 0.807126\n",
      "[7200]\ttraining's l2: 0.375787\tvalid_1's l2: 0.806699\n",
      "[7300]\ttraining's l2: 0.373915\tvalid_1's l2: 0.805663\n",
      "[7400]\ttraining's l2: 0.371728\tvalid_1's l2: 0.804799\n",
      "[7500]\ttraining's l2: 0.368903\tvalid_1's l2: 0.803166\n",
      "[7600]\ttraining's l2: 0.366889\tvalid_1's l2: 0.8026\n",
      "[7700]\ttraining's l2: 0.364551\tvalid_1's l2: 0.800149\n",
      "[7800]\ttraining's l2: 0.362628\tvalid_1's l2: 0.798656\n",
      "[7900]\ttraining's l2: 0.360799\tvalid_1's l2: 0.797662\n",
      "[8000]\ttraining's l2: 0.359388\tvalid_1's l2: 0.796806\n",
      "[8100]\ttraining's l2: 0.35792\tvalid_1's l2: 0.796215\n",
      "[8200]\ttraining's l2: 0.356056\tvalid_1's l2: 0.794926\n",
      "[8300]\ttraining's l2: 0.354852\tvalid_1's l2: 0.794582\n",
      "[8400]\ttraining's l2: 0.35315\tvalid_1's l2: 0.793949\n",
      "[8500]\ttraining's l2: 0.351447\tvalid_1's l2: 0.793504\n",
      "[8600]\ttraining's l2: 0.349738\tvalid_1's l2: 0.792364\n",
      "[8700]\ttraining's l2: 0.348264\tvalid_1's l2: 0.791821\n",
      "[8800]\ttraining's l2: 0.346776\tvalid_1's l2: 0.791337\n",
      "[8900]\ttraining's l2: 0.345367\tvalid_1's l2: 0.791072\n",
      "[9000]\ttraining's l2: 0.344236\tvalid_1's l2: 0.790773\n",
      "[9100]\ttraining's l2: 0.343153\tvalid_1's l2: 0.790535\n",
      "[9200]\ttraining's l2: 0.341598\tvalid_1's l2: 0.789768\n",
      "[9300]\ttraining's l2: 0.339942\tvalid_1's l2: 0.789362\n",
      "[9400]\ttraining's l2: 0.338032\tvalid_1's l2: 0.788071\n",
      "[9500]\ttraining's l2: 0.336482\tvalid_1's l2: 0.787722\n",
      "[9600]\ttraining's l2: 0.33527\tvalid_1's l2: 0.787396\n",
      "[9700]\ttraining's l2: 0.333995\tvalid_1's l2: 0.786872\n",
      "[9800]\ttraining's l2: 0.332536\tvalid_1's l2: 0.786179\n",
      "[9900]\ttraining's l2: 0.331019\tvalid_1's l2: 0.785194\n",
      "[10000]\ttraining's l2: 0.329831\tvalid_1's l2: 0.78433\n",
      "[10100]\ttraining's l2: 0.328759\tvalid_1's l2: 0.783834\n",
      "[10200]\ttraining's l2: 0.327732\tvalid_1's l2: 0.783551\n",
      "[10300]\ttraining's l2: 0.326666\tvalid_1's l2: 0.783071\n",
      "[10400]\ttraining's l2: 0.325733\tvalid_1's l2: 0.782784\n",
      "[10500]\ttraining's l2: 0.324443\tvalid_1's l2: 0.781689\n",
      "[10600]\ttraining's l2: 0.323428\tvalid_1's l2: 0.781544\n",
      "[10700]\ttraining's l2: 0.322172\tvalid_1's l2: 0.780827\n",
      "[10800]\ttraining's l2: 0.321001\tvalid_1's l2: 0.780113\n",
      "[10900]\ttraining's l2: 0.319838\tvalid_1's l2: 0.779637\n",
      "[11000]\ttraining's l2: 0.318653\tvalid_1's l2: 0.779175\n",
      "[11100]\ttraining's l2: 0.317591\tvalid_1's l2: 0.778742\n",
      "[11200]\ttraining's l2: 0.316426\tvalid_1's l2: 0.778249\n",
      "[11300]\ttraining's l2: 0.315136\tvalid_1's l2: 0.77738\n",
      "[11400]\ttraining's l2: 0.314205\tvalid_1's l2: 0.777081\n",
      "[11500]\ttraining's l2: 0.313119\tvalid_1's l2: 0.776489\n",
      "[11600]\ttraining's l2: 0.312228\tvalid_1's l2: 0.776227\n",
      "[11700]\ttraining's l2: 0.311296\tvalid_1's l2: 0.775533\n",
      "[11800]\ttraining's l2: 0.31033\tvalid_1's l2: 0.775377\n",
      "[11900]\ttraining's l2: 0.309558\tvalid_1's l2: 0.775258\n",
      "[12000]\ttraining's l2: 0.308687\tvalid_1's l2: 0.774993\n",
      "[12100]\ttraining's l2: 0.307874\tvalid_1's l2: 0.774715\n",
      "[12200]\ttraining's l2: 0.307065\tvalid_1's l2: 0.774279\n",
      "[12300]\ttraining's l2: 0.306197\tvalid_1's l2: 0.773908\n",
      "[12400]\ttraining's l2: 0.305319\tvalid_1's l2: 0.773649\n",
      "[12500]\ttraining's l2: 0.304236\tvalid_1's l2: 0.773234\n",
      "[12600]\ttraining's l2: 0.30328\tvalid_1's l2: 0.772614\n",
      "[12700]\ttraining's l2: 0.302286\tvalid_1's l2: 0.772054\n",
      "[12800]\ttraining's l2: 0.301186\tvalid_1's l2: 0.77147\n",
      "[12900]\ttraining's l2: 0.300502\tvalid_1's l2: 0.771299\n",
      "[13000]\ttraining's l2: 0.299704\tvalid_1's l2: 0.770751\n",
      "[13100]\ttraining's l2: 0.298932\tvalid_1's l2: 0.770472\n",
      "[13200]\ttraining's l2: 0.298131\tvalid_1's l2: 0.770172\n",
      "[13300]\ttraining's l2: 0.297354\tvalid_1's l2: 0.769995\n",
      "[13400]\ttraining's l2: 0.296559\tvalid_1's l2: 0.769787\n",
      "[13500]\ttraining's l2: 0.295808\tvalid_1's l2: 0.769158\n",
      "[13600]\ttraining's l2: 0.294774\tvalid_1's l2: 0.768832\n",
      "[13700]\ttraining's l2: 0.293828\tvalid_1's l2: 0.768607\n",
      "[13800]\ttraining's l2: 0.292838\tvalid_1's l2: 0.768076\n",
      "[13900]\ttraining's l2: 0.291951\tvalid_1's l2: 0.767982\n",
      "[14000]\ttraining's l2: 0.29121\tvalid_1's l2: 0.767663\n",
      "[14100]\ttraining's l2: 0.290434\tvalid_1's l2: 0.767288\n",
      "[14200]\ttraining's l2: 0.289611\tvalid_1's l2: 0.767028\n",
      "[14300]\ttraining's l2: 0.288591\tvalid_1's l2: 0.76667\n",
      "[14400]\ttraining's l2: 0.288051\tvalid_1's l2: 0.766609\n",
      "[14500]\ttraining's l2: 0.287314\tvalid_1's l2: 0.76636\n",
      "[14600]\ttraining's l2: 0.286683\tvalid_1's l2: 0.766555\n",
      "[14700]\ttraining's l2: 0.286054\tvalid_1's l2: 0.766409\n",
      "[14800]\ttraining's l2: 0.285349\tvalid_1's l2: 0.765691\n",
      "[14900]\ttraining's l2: 0.284727\tvalid_1's l2: 0.765395\n",
      "[15000]\ttraining's l2: 0.283967\tvalid_1's l2: 0.765159\n",
      "[15100]\ttraining's l2: 0.283237\tvalid_1's l2: 0.764877\n",
      "[15200]\ttraining's l2: 0.282575\tvalid_1's l2: 0.76479\n",
      "[15300]\ttraining's l2: 0.281964\tvalid_1's l2: 0.764609\n",
      "[15400]\ttraining's l2: 0.281132\tvalid_1's l2: 0.764822\n",
      "[15500]\ttraining's l2: 0.280493\tvalid_1's l2: 0.764754\n",
      "[15600]\ttraining's l2: 0.279663\tvalid_1's l2: 0.764493\n",
      "[15700]\ttraining's l2: 0.278984\tvalid_1's l2: 0.764334\n",
      "[15800]\ttraining's l2: 0.278297\tvalid_1's l2: 0.764086\n",
      "[15900]\ttraining's l2: 0.277593\tvalid_1's l2: 0.763938\n",
      "[16000]\ttraining's l2: 0.277\tvalid_1's l2: 0.763795\n",
      "[16100]\ttraining's l2: 0.276452\tvalid_1's l2: 0.763683\n",
      "[16200]\ttraining's l2: 0.27582\tvalid_1's l2: 0.76337\n",
      "[16300]\ttraining's l2: 0.275278\tvalid_1's l2: 0.763274\n",
      "[16400]\ttraining's l2: 0.274826\tvalid_1's l2: 0.763247\n",
      "[16500]\ttraining's l2: 0.274195\tvalid_1's l2: 0.763097\n",
      "[16600]\ttraining's l2: 0.273533\tvalid_1's l2: 0.762789\n",
      "[16700]\ttraining's l2: 0.273034\tvalid_1's l2: 0.762732\n",
      "[16800]\ttraining's l2: 0.272512\tvalid_1's l2: 0.762468\n",
      "[16900]\ttraining's l2: 0.271974\tvalid_1's l2: 0.762116\n",
      "[17000]\ttraining's l2: 0.27138\tvalid_1's l2: 0.761812\n",
      "[17100]\ttraining's l2: 0.270855\tvalid_1's l2: 0.761632\n",
      "[17200]\ttraining's l2: 0.270332\tvalid_1's l2: 0.761551\n",
      "[17300]\ttraining's l2: 0.269806\tvalid_1's l2: 0.761481\n",
      "[17400]\ttraining's l2: 0.269368\tvalid_1's l2: 0.761352\n",
      "[17500]\ttraining's l2: 0.268662\tvalid_1's l2: 0.761036\n",
      "[17600]\ttraining's l2: 0.267847\tvalid_1's l2: 0.760747\n",
      "[17700]\ttraining's l2: 0.267048\tvalid_1's l2: 0.760403\n",
      "[17800]\ttraining's l2: 0.266365\tvalid_1's l2: 0.760104\n",
      "[17900]\ttraining's l2: 0.265678\tvalid_1's l2: 0.759926\n",
      "[18000]\ttraining's l2: 0.265184\tvalid_1's l2: 0.759862\n",
      "[18100]\ttraining's l2: 0.264733\tvalid_1's l2: 0.759699\n",
      "[18200]\ttraining's l2: 0.264228\tvalid_1's l2: 0.759588\n",
      "[18300]\ttraining's l2: 0.263613\tvalid_1's l2: 0.759457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18400]\ttraining's l2: 0.263119\tvalid_1's l2: 0.759441\n",
      "[18500]\ttraining's l2: 0.262613\tvalid_1's l2: 0.759273\n",
      "[18600]\ttraining's l2: 0.262043\tvalid_1's l2: 0.758876\n",
      "[18700]\ttraining's l2: 0.261573\tvalid_1's l2: 0.758746\n",
      "[18800]\ttraining's l2: 0.261066\tvalid_1's l2: 0.758505\n",
      "[18900]\ttraining's l2: 0.260536\tvalid_1's l2: 0.758343\n",
      "[19000]\ttraining's l2: 0.260093\tvalid_1's l2: 0.758146\n",
      "[19100]\ttraining's l2: 0.259612\tvalid_1's l2: 0.758174\n",
      "[19200]\ttraining's l2: 0.25908\tvalid_1's l2: 0.757965\n",
      "[19300]\ttraining's l2: 0.258542\tvalid_1's l2: 0.757776\n",
      "[19400]\ttraining's l2: 0.258011\tvalid_1's l2: 0.757583\n",
      "[19500]\ttraining's l2: 0.257541\tvalid_1's l2: 0.757579\n",
      "[19600]\ttraining's l2: 0.257004\tvalid_1's l2: 0.757432\n",
      "[19700]\ttraining's l2: 0.256481\tvalid_1's l2: 0.757207\n",
      "[19800]\ttraining's l2: 0.255874\tvalid_1's l2: 0.756676\n",
      "[19900]\ttraining's l2: 0.255457\tvalid_1's l2: 0.756408\n",
      "[20000]\ttraining's l2: 0.254971\tvalid_1's l2: 0.756373\n",
      "[20100]\ttraining's l2: 0.254587\tvalid_1's l2: 0.756155\n",
      "[20200]\ttraining's l2: 0.254207\tvalid_1's l2: 0.756145\n",
      "[20300]\ttraining's l2: 0.253733\tvalid_1's l2: 0.755658\n",
      "[20400]\ttraining's l2: 0.25335\tvalid_1's l2: 0.755717\n",
      "[20500]\ttraining's l2: 0.252818\tvalid_1's l2: 0.755671\n",
      "[20600]\ttraining's l2: 0.252391\tvalid_1's l2: 0.75564\n",
      "[20700]\ttraining's l2: 0.251884\tvalid_1's l2: 0.755815\n",
      "[20800]\ttraining's l2: 0.251409\tvalid_1's l2: 0.755687\n",
      "[20900]\ttraining's l2: 0.251003\tvalid_1's l2: 0.755765\n",
      "Early stopping, best iteration is:\n",
      "[20636]\ttraining's l2: 0.252231\tvalid_1's l2: 0.755533\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's l2: 1.72038\tvalid_1's l2: 1.96459\n",
      "[200]\ttraining's l2: 1.43026\tvalid_1's l2: 1.7472\n",
      "[300]\ttraining's l2: 1.26906\tvalid_1's l2: 1.61059\n",
      "[400]\ttraining's l2: 1.13741\tvalid_1's l2: 1.50308\n",
      "[500]\ttraining's l2: 1.05197\tvalid_1's l2: 1.44297\n",
      "[600]\ttraining's l2: 0.975904\tvalid_1's l2: 1.38244\n",
      "[700]\ttraining's l2: 0.91826\tvalid_1's l2: 1.34327\n",
      "[800]\ttraining's l2: 0.875672\tvalid_1's l2: 1.31676\n",
      "[900]\ttraining's l2: 0.831755\tvalid_1's l2: 1.28543\n",
      "[1000]\ttraining's l2: 0.798939\tvalid_1's l2: 1.26172\n",
      "[1100]\ttraining's l2: 0.773095\tvalid_1's l2: 1.24462\n",
      "[1200]\ttraining's l2: 0.748784\tvalid_1's l2: 1.22499\n",
      "[1300]\ttraining's l2: 0.72632\tvalid_1's l2: 1.21452\n",
      "[1400]\ttraining's l2: 0.703383\tvalid_1's l2: 1.19688\n",
      "[1500]\ttraining's l2: 0.687853\tvalid_1's l2: 1.18823\n",
      "[1600]\ttraining's l2: 0.67125\tvalid_1's l2: 1.17754\n",
      "[1700]\ttraining's l2: 0.652572\tvalid_1's l2: 1.16447\n",
      "[1800]\ttraining's l2: 0.638678\tvalid_1's l2: 1.15491\n",
      "[1900]\ttraining's l2: 0.626695\tvalid_1's l2: 1.14813\n",
      "[2000]\ttraining's l2: 0.611693\tvalid_1's l2: 1.13842\n",
      "[2100]\ttraining's l2: 0.599435\tvalid_1's l2: 1.13418\n",
      "[2200]\ttraining's l2: 0.58986\tvalid_1's l2: 1.12993\n",
      "[2300]\ttraining's l2: 0.579561\tvalid_1's l2: 1.12507\n",
      "[2400]\ttraining's l2: 0.570658\tvalid_1's l2: 1.12116\n",
      "[2500]\ttraining's l2: 0.56319\tvalid_1's l2: 1.11788\n",
      "[2600]\ttraining's l2: 0.556167\tvalid_1's l2: 1.11387\n",
      "[2700]\ttraining's l2: 0.54805\tvalid_1's l2: 1.11075\n",
      "[2800]\ttraining's l2: 0.53988\tvalid_1's l2: 1.10711\n",
      "[2900]\ttraining's l2: 0.532715\tvalid_1's l2: 1.10365\n",
      "[3000]\ttraining's l2: 0.525298\tvalid_1's l2: 1.09936\n",
      "[3100]\ttraining's l2: 0.517609\tvalid_1's l2: 1.09603\n",
      "[3200]\ttraining's l2: 0.510147\tvalid_1's l2: 1.09184\n",
      "[3300]\ttraining's l2: 0.504871\tvalid_1's l2: 1.08912\n",
      "[3400]\ttraining's l2: 0.499483\tvalid_1's l2: 1.08694\n",
      "[3500]\ttraining's l2: 0.493543\tvalid_1's l2: 1.08402\n",
      "[3600]\ttraining's l2: 0.487152\tvalid_1's l2: 1.08132\n",
      "[3700]\ttraining's l2: 0.482128\tvalid_1's l2: 1.07966\n",
      "[3800]\ttraining's l2: 0.477298\tvalid_1's l2: 1.07619\n",
      "[3900]\ttraining's l2: 0.47235\tvalid_1's l2: 1.07365\n",
      "[4000]\ttraining's l2: 0.468017\tvalid_1's l2: 1.07278\n",
      "[4100]\ttraining's l2: 0.463203\tvalid_1's l2: 1.07012\n",
      "[4200]\ttraining's l2: 0.45803\tvalid_1's l2: 1.06717\n",
      "[4300]\ttraining's l2: 0.452996\tvalid_1's l2: 1.06444\n",
      "[4400]\ttraining's l2: 0.448423\tvalid_1's l2: 1.06161\n",
      "[4500]\ttraining's l2: 0.445196\tvalid_1's l2: 1.06044\n",
      "[4600]\ttraining's l2: 0.441806\tvalid_1's l2: 1.05974\n",
      "[4700]\ttraining's l2: 0.438675\tvalid_1's l2: 1.05844\n",
      "[4800]\ttraining's l2: 0.43527\tvalid_1's l2: 1.05689\n",
      "[4900]\ttraining's l2: 0.432198\tvalid_1's l2: 1.05577\n",
      "[5000]\ttraining's l2: 0.428526\tvalid_1's l2: 1.05344\n",
      "[5100]\ttraining's l2: 0.424497\tvalid_1's l2: 1.05057\n",
      "[5200]\ttraining's l2: 0.420689\tvalid_1's l2: 1.0486\n",
      "[5300]\ttraining's l2: 0.416857\tvalid_1's l2: 1.0482\n",
      "[5400]\ttraining's l2: 0.413856\tvalid_1's l2: 1.04629\n",
      "[5500]\ttraining's l2: 0.411301\tvalid_1's l2: 1.04559\n",
      "[5600]\ttraining's l2: 0.408707\tvalid_1's l2: 1.04474\n",
      "[5700]\ttraining's l2: 0.406385\tvalid_1's l2: 1.04369\n",
      "[5800]\ttraining's l2: 0.403441\tvalid_1's l2: 1.04314\n",
      "[5900]\ttraining's l2: 0.400743\tvalid_1's l2: 1.04175\n",
      "[6000]\ttraining's l2: 0.398689\tvalid_1's l2: 1.04101\n",
      "[6100]\ttraining's l2: 0.395591\tvalid_1's l2: 1.04043\n",
      "[6200]\ttraining's l2: 0.393065\tvalid_1's l2: 1.03928\n",
      "[6300]\ttraining's l2: 0.390667\tvalid_1's l2: 1.03804\n",
      "[6400]\ttraining's l2: 0.388466\tvalid_1's l2: 1.03662\n",
      "[6500]\ttraining's l2: 0.385736\tvalid_1's l2: 1.03505\n",
      "[6600]\ttraining's l2: 0.383504\tvalid_1's l2: 1.03397\n",
      "[6700]\ttraining's l2: 0.381337\tvalid_1's l2: 1.03317\n",
      "[6800]\ttraining's l2: 0.379258\tvalid_1's l2: 1.03248\n",
      "[6900]\ttraining's l2: 0.377027\tvalid_1's l2: 1.03182\n",
      "[7000]\ttraining's l2: 0.374924\tvalid_1's l2: 1.03145\n",
      "[7100]\ttraining's l2: 0.372812\tvalid_1's l2: 1.03076\n",
      "[7200]\ttraining's l2: 0.37138\tvalid_1's l2: 1.03049\n",
      "[7300]\ttraining's l2: 0.369744\tvalid_1's l2: 1.03009\n",
      "[7400]\ttraining's l2: 0.367683\tvalid_1's l2: 1.02903\n",
      "[7500]\ttraining's l2: 0.365424\tvalid_1's l2: 1.02838\n",
      "[7600]\ttraining's l2: 0.363694\tvalid_1's l2: 1.02828\n",
      "[7700]\ttraining's l2: 0.361865\tvalid_1's l2: 1.02778\n",
      "[7800]\ttraining's l2: 0.360159\tvalid_1's l2: 1.02779\n",
      "[7900]\ttraining's l2: 0.358514\tvalid_1's l2: 1.02689\n",
      "[8000]\ttraining's l2: 0.35676\tvalid_1's l2: 1.02628\n",
      "[8100]\ttraining's l2: 0.354877\tvalid_1's l2: 1.0257\n",
      "[8200]\ttraining's l2: 0.353321\tvalid_1's l2: 1.02507\n",
      "[8300]\ttraining's l2: 0.351787\tvalid_1's l2: 1.02451\n",
      "[8400]\ttraining's l2: 0.350472\tvalid_1's l2: 1.02421\n",
      "[8500]\ttraining's l2: 0.348781\tvalid_1's l2: 1.02379\n",
      "[8600]\ttraining's l2: 0.347048\tvalid_1's l2: 1.02332\n",
      "[8700]\ttraining's l2: 0.345945\tvalid_1's l2: 1.02299\n",
      "[8800]\ttraining's l2: 0.344444\tvalid_1's l2: 1.02243\n",
      "[8900]\ttraining's l2: 0.342864\tvalid_1's l2: 1.02183\n",
      "[9000]\ttraining's l2: 0.341491\tvalid_1's l2: 1.02168\n",
      "[9100]\ttraining's l2: 0.340246\tvalid_1's l2: 1.02122\n",
      "[9200]\ttraining's l2: 0.339113\tvalid_1's l2: 1.02087\n",
      "[9300]\ttraining's l2: 0.337966\tvalid_1's l2: 1.02049\n",
      "[9400]\ttraining's l2: 0.336446\tvalid_1's l2: 1.01953\n",
      "[9500]\ttraining's l2: 0.335291\tvalid_1's l2: 1.01926\n",
      "[9600]\ttraining's l2: 0.334091\tvalid_1's l2: 1.01874\n",
      "[9700]\ttraining's l2: 0.332479\tvalid_1's l2: 1.01811\n",
      "[9800]\ttraining's l2: 0.330869\tvalid_1's l2: 1.01737\n",
      "[9900]\ttraining's l2: 0.329889\tvalid_1's l2: 1.01707\n",
      "[10000]\ttraining's l2: 0.328879\tvalid_1's l2: 1.01699\n",
      "[10100]\ttraining's l2: 0.327438\tvalid_1's l2: 1.01632\n",
      "[10200]\ttraining's l2: 0.326091\tvalid_1's l2: 1.01577\n",
      "[10300]\ttraining's l2: 0.32462\tvalid_1's l2: 1.01513\n",
      "[10400]\ttraining's l2: 0.323649\tvalid_1's l2: 1.01485\n",
      "[10500]\ttraining's l2: 0.322636\tvalid_1's l2: 1.01441\n",
      "[10600]\ttraining's l2: 0.321729\tvalid_1's l2: 1.01456\n",
      "[10700]\ttraining's l2: 0.320177\tvalid_1's l2: 1.01383\n",
      "[10800]\ttraining's l2: 0.318919\tvalid_1's l2: 1.01333\n",
      "[10900]\ttraining's l2: 0.317882\tvalid_1's l2: 1.01308\n",
      "[11000]\ttraining's l2: 0.316753\tvalid_1's l2: 1.01262\n",
      "[11100]\ttraining's l2: 0.315713\tvalid_1's l2: 1.0124\n",
      "[11200]\ttraining's l2: 0.314561\tvalid_1's l2: 1.012\n",
      "[11300]\ttraining's l2: 0.313461\tvalid_1's l2: 1.01164\n",
      "[11400]\ttraining's l2: 0.312536\tvalid_1's l2: 1.01153\n",
      "[11500]\ttraining's l2: 0.311459\tvalid_1's l2: 1.01144\n",
      "[11600]\ttraining's l2: 0.310369\tvalid_1's l2: 1.01105\n",
      "[11700]\ttraining's l2: 0.309126\tvalid_1's l2: 1.01109\n",
      "[11800]\ttraining's l2: 0.308291\tvalid_1's l2: 1.01078\n",
      "[11900]\ttraining's l2: 0.306977\tvalid_1's l2: 1.00961\n",
      "[12000]\ttraining's l2: 0.305873\tvalid_1's l2: 1.00908\n",
      "[12100]\ttraining's l2: 0.304701\tvalid_1's l2: 1.00872\n",
      "[12200]\ttraining's l2: 0.303722\tvalid_1's l2: 1.00828\n",
      "[12300]\ttraining's l2: 0.302733\tvalid_1's l2: 1.00825\n",
      "[12400]\ttraining's l2: 0.301775\tvalid_1's l2: 1.00796\n",
      "[12500]\ttraining's l2: 0.300881\tvalid_1's l2: 1.00762\n",
      "[12600]\ttraining's l2: 0.29996\tvalid_1's l2: 1.0073\n",
      "[12700]\ttraining's l2: 0.299096\tvalid_1's l2: 1.0069\n",
      "[12800]\ttraining's l2: 0.298033\tvalid_1's l2: 1.00671\n",
      "[12900]\ttraining's l2: 0.296752\tvalid_1's l2: 1.00576\n",
      "[13000]\ttraining's l2: 0.295868\tvalid_1's l2: 1.00511\n",
      "[13100]\ttraining's l2: 0.294849\tvalid_1's l2: 1.00442\n",
      "[13200]\ttraining's l2: 0.294084\tvalid_1's l2: 1.00417\n",
      "[13300]\ttraining's l2: 0.293276\tvalid_1's l2: 1.0039\n",
      "[13400]\ttraining's l2: 0.292629\tvalid_1's l2: 1.00394\n",
      "[13500]\ttraining's l2: 0.291825\tvalid_1's l2: 1.00375\n",
      "[13600]\ttraining's l2: 0.291069\tvalid_1's l2: 1.00375\n",
      "[13700]\ttraining's l2: 0.290446\tvalid_1's l2: 1.00381\n",
      "[13800]\ttraining's l2: 0.289873\tvalid_1's l2: 1.00389\n",
      "Early stopping, best iteration is:\n",
      "[13570]\ttraining's l2: 0.291277\tvalid_1's l2: 1.00366\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's l2: 1.71871\tvalid_1's l2: 2.01429\n",
      "[200]\ttraining's l2: 1.43359\tvalid_1's l2: 1.72326\n",
      "[300]\ttraining's l2: 1.24353\tvalid_1's l2: 1.52968\n",
      "[400]\ttraining's l2: 1.13921\tvalid_1's l2: 1.41326\n",
      "[500]\ttraining's l2: 1.06483\tvalid_1's l2: 1.34592\n",
      "[600]\ttraining's l2: 0.991821\tvalid_1's l2: 1.28229\n",
      "[700]\ttraining's l2: 0.932889\tvalid_1's l2: 1.23643\n",
      "[800]\ttraining's l2: 0.885617\tvalid_1's l2: 1.19891\n",
      "[900]\ttraining's l2: 0.847062\tvalid_1's l2: 1.16764\n",
      "[1000]\ttraining's l2: 0.81434\tvalid_1's l2: 1.14228\n",
      "[1100]\ttraining's l2: 0.784261\tvalid_1's l2: 1.11767\n",
      "[1200]\ttraining's l2: 0.76183\tvalid_1's l2: 1.10087\n",
      "[1300]\ttraining's l2: 0.739874\tvalid_1's l2: 1.08762\n",
      "[1400]\ttraining's l2: 0.716821\tvalid_1's l2: 1.07248\n",
      "[1500]\ttraining's l2: 0.697212\tvalid_1's l2: 1.05907\n",
      "[1600]\ttraining's l2: 0.678839\tvalid_1's l2: 1.04355\n",
      "[1700]\ttraining's l2: 0.662596\tvalid_1's l2: 1.03338\n",
      "[1800]\ttraining's l2: 0.649747\tvalid_1's l2: 1.02371\n",
      "[1900]\ttraining's l2: 0.636417\tvalid_1's l2: 1.01504\n",
      "[2000]\ttraining's l2: 0.626478\tvalid_1's l2: 1.00564\n",
      "[2100]\ttraining's l2: 0.614802\tvalid_1's l2: 0.999184\n",
      "[2200]\ttraining's l2: 0.602242\tvalid_1's l2: 0.991579\n",
      "[2300]\ttraining's l2: 0.592335\tvalid_1's l2: 0.984361\n",
      "[2400]\ttraining's l2: 0.582203\tvalid_1's l2: 0.980782\n",
      "[2500]\ttraining's l2: 0.572892\tvalid_1's l2: 0.974107\n",
      "[2600]\ttraining's l2: 0.564735\tvalid_1's l2: 0.969873\n",
      "[2700]\ttraining's l2: 0.555907\tvalid_1's l2: 0.965455\n",
      "[2800]\ttraining's l2: 0.547586\tvalid_1's l2: 0.960347\n",
      "[2900]\ttraining's l2: 0.539468\tvalid_1's l2: 0.956555\n",
      "[3000]\ttraining's l2: 0.533508\tvalid_1's l2: 0.953586\n",
      "[3100]\ttraining's l2: 0.52616\tvalid_1's l2: 0.949506\n",
      "[3200]\ttraining's l2: 0.518851\tvalid_1's l2: 0.945155\n",
      "[3300]\ttraining's l2: 0.512408\tvalid_1's l2: 0.942045\n",
      "[3400]\ttraining's l2: 0.506292\tvalid_1's l2: 0.938621\n",
      "[3500]\ttraining's l2: 0.49969\tvalid_1's l2: 0.935632\n",
      "[3600]\ttraining's l2: 0.494242\tvalid_1's l2: 0.932929\n",
      "[3700]\ttraining's l2: 0.489414\tvalid_1's l2: 0.931926\n",
      "[3800]\ttraining's l2: 0.483843\tvalid_1's l2: 0.930228\n",
      "[3900]\ttraining's l2: 0.479155\tvalid_1's l2: 0.92873\n",
      "[4000]\ttraining's l2: 0.473883\tvalid_1's l2: 0.926765\n",
      "[4100]\ttraining's l2: 0.469212\tvalid_1's l2: 0.925424\n",
      "[4200]\ttraining's l2: 0.464939\tvalid_1's l2: 0.923775\n",
      "[4300]\ttraining's l2: 0.460216\tvalid_1's l2: 0.921364\n",
      "[4400]\ttraining's l2: 0.455881\tvalid_1's l2: 0.919551\n",
      "[4500]\ttraining's l2: 0.451374\tvalid_1's l2: 0.916087\n",
      "[4600]\ttraining's l2: 0.447504\tvalid_1's l2: 0.914426\n",
      "[4700]\ttraining's l2: 0.443825\tvalid_1's l2: 0.913356\n",
      "[4800]\ttraining's l2: 0.439687\tvalid_1's l2: 0.911568\n",
      "[4900]\ttraining's l2: 0.435311\tvalid_1's l2: 0.908572\n",
      "[5000]\ttraining's l2: 0.431683\tvalid_1's l2: 0.907469\n",
      "[5100]\ttraining's l2: 0.427575\tvalid_1's l2: 0.905255\n",
      "[5200]\ttraining's l2: 0.424386\tvalid_1's l2: 0.903753\n",
      "[5300]\ttraining's l2: 0.421358\tvalid_1's l2: 0.902969\n",
      "[5400]\ttraining's l2: 0.418716\tvalid_1's l2: 0.902025\n",
      "[5500]\ttraining's l2: 0.415989\tvalid_1's l2: 0.901108\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "folds = 7\n",
    "seed = 99 #666\n",
    "# shuffle = False\n",
    "kf = KFold(n_splits=folds, shuffle=False, random_state=seed)\n",
    "\n",
    "models = []\n",
    "for train_index, val_index in kf.split(train_df):\n",
    "    train_X = train_df.iloc[train_index]\n",
    "    val_X = train_df.iloc[val_index]\n",
    "    train_y = target.iloc[train_index]\n",
    "    val_y = target.iloc[val_index]\n",
    "    lgb_train = lgb.Dataset(train_X, train_y)\n",
    "    lgb_eval = lgb.Dataset(val_X, val_y)\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=10000, #300,\n",
    "                    valid_sets=(lgb_train, lgb_eval),\n",
    "#                     feval=rmsle,\n",
    "                    early_stopping_rounds= 100,#100,\n",
    "                    verbose_eval=100) #100)\n",
    "    models.append(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "feature_imp = pd.DataFrame(sorted(zip(gbm.feature_importance(), gbm.feature_name()),reverse = True), columns=['Value','Feature'])\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM FEATURES')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i = 0\n",
    "res = []\n",
    "step_size = 50000\n",
    "for j in tqdm(range(int(np.ceil(test_df.shape[0] / 50000)))):\n",
    "    res.append(np.expm1(sum([model.predict(test_df.iloc[i:i + step_size]) for model in models]) / folds))\n",
    "    i += step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from datetime import datetime\n",
    "\n",
    "res = np.concatenate(res)\n",
    "sample_submission[\"meter_reading\"] = res\n",
    "sample_submission.loc[sample_submission['meter_reading'] < 0, 'meter_reading'] = 0\n",
    "sample_submission.to_csv('sub_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
