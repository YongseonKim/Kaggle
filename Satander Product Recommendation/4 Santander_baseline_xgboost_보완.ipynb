{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['prod', 'full', 'datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "%pylab inline\n",
    "color = sns.color_palette()\n",
    "#https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-v3-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "  \n",
    "    cols = [x for x in list(df.columns) ]\n",
    "    \n",
    "    for col in tqdm(cols):\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type not in [object]:\n",
    "\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러와서 메모리 최적화 시킨 후 객체 저장하기\n",
    "\n",
    "df= pd.read_csv('train_ver2.csv')\n",
    "df = reduce_mem_usage(df)\n",
    "df[\"fecha_dato\"] = pd.to_datetime(df[\"fecha_dato\"],format=\"%Y-%m-%d\")\n",
    "df[\"fecha_alta\"] = pd.to_datetime(df[\"fecha_alta\"],format=\"%Y-%m-%d\")\n",
    "df.to_pickle('train_pkl.pkl')\n",
    "\n",
    "tst= pd.read_csv('test_ver2.csv')\n",
    "tst= reduce_mem_usage(tst)\n",
    "tst[\"fecha_dato\"] = pd.to_datetime(tst[\"fecha_dato\"],format=\"%Y-%m-%d\")\n",
    "tst[\"fecha_alta\"] = pd.to_datetime(tst[\"fecha_alta\"],format=\"%Y-%m-%d\")\n",
    "tst.to_pickle('test_pkl.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('train_pkl.pkl')\n",
    "# tst= pd.read_pickle('test_pkl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[24:]\n",
    "for col in df.columns[24:]:\n",
    "    tst[col] = 0\n",
    "df = pd.concat([df,tst],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24개 금융 제품에 대한 '신규 구매 데이터 생성하기'\n",
    "prods = df.columns[24:].tolist()\n",
    "\n",
    "# 날짜를 숫자로 변환  : \n",
    "def date_to_int(str_date):\n",
    "    Y,M,D = [int(a) for a in str_date.strip().split(\"-\")]\n",
    "    int_date = (int(Y)- 2015)* 12 + int(M)\n",
    "    return int_date\n",
    "\n",
    "df['int_date'] = df['fecha_dato'].astype('str').map(date_to_int).astype(np.int8)\n",
    "\n",
    "# int_date를 기반으로 lag를 생성한다. 데이터를 복사해서\n",
    "df_lag = df.copy()\n",
    "df_lag['int_date'] +=1\n",
    "df_lag.columns = [col+'_prev' if col not in ['ncodpers','int_date'] else col for col in df.columns] ## 컬럼 이름 바꿔주기\n",
    "\n",
    "# 원본데이터와 lag 데이터 합치기 : ncodpers, int_date 기준으로\n",
    "df = pd.merge(df,df_lag, on= ['ncodpers','int_date'], how = 'left')\n",
    "\n",
    "del df_lag\n",
    "gc.collect()\n",
    "#저번달의 제품 정보가 없으면 0으로 대체\n",
    "for prod in prods:\n",
    "    prev = prod+'_prev'\n",
    "    df[prev].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "#     tst[prev].fillna(0, inplace =True)\n",
    "    \n",
    "# #신규 구매 변수 padd\n",
    "# for prod in prods : \n",
    "#     padd = prod + '_add'\n",
    "#     prev = prod + '_prev'\n",
    "#     df[padd] = ((df[prod] ==1)& (df[prev]==0)).astype(np.int8) # 이전에는 0이었는데 이번에 1이된 상품에 1\n",
    "    \n",
    "# # 신규 구매 변수만 추출 \n",
    "# add_cols = [prod + '_add' for prod in prods]\n",
    "# labels = df[add_cols].copy()\n",
    "# labels.columns = prods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[prev].fillna(-999, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 제거가 아니라 신규 구매한 row만 가지고 학습 \n",
    "X, Y = [],[]\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = df[(df[prod]==1)& (df[prev]==0)] # 이전 0인데 이번에 신규로 구매한 row들 찾기\n",
    "    prY = np.zeros(prX.shape[0], dtype = np.int8) +i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)\n",
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = XY.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1778875, 97)\n",
      "(929615, 48)\n"
     ]
    }
   ],
   "source": [
    "# Target Columns 이 총 24개 이다. \n",
    "\n",
    "# http://alanpryorjr.com/2016-12-19-Kaggle-Competition-Santander-Solution/ \n",
    "print(df.shape)\n",
    "print(tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualization\n",
    "# # Month\n",
    "# df['month'] = pd.DatetimeIndex(df['fecha_dato']).month\n",
    "# df['year'] = pd.DatetimeIndex(df['fecha_dato']).year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 및 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing, modelling and evaluating\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "# import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "# null 값이 많은 것만 제거하기\n",
    "# df.isnull().sum()\n",
    "# df = df[~df['ind_empleado'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_cols = ['ind_cco_fin_ult1', 'ind_cder_fin_ult1',\n",
    "#                              'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "#                              'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n",
    "#                              'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1',\n",
    "#                              'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "#                              'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n",
    "#                              'ind_hip_fin_ult1', 'ind_plan_fin_ult1',\n",
    "#                              'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "#                              'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n",
    "#                              'ind_viv_fin_ult1', 'ind_nomina_ult1',\n",
    "#                              'ind_nom_pens_ult1', 'ind_recibo_ult1',\n",
    "#                              'ind_ahor_fin_ult1', 'ind_aval_fin_ult1' ]\n",
    "# cols = [col for col in XY.columns if col[-4:] =='prev'] \n",
    "# target_cols = target_cols + cols  +['y']\n",
    "# x_train = XY.drop(['y'], axis =1)\n",
    "# y_train = XY['y']\n",
    "# # y_train = y_train.drop(['ind_ahor_fin_ult1', 'ind_aval_fin_ult1'],axis =1)\n",
    "# x_test = tst.copy()\n",
    "\n",
    "x_train = XY[XY['fecha_dato']!='2016-05-28']\n",
    "y_train = x_train['y']\n",
    "x_train = x_train.drop(['y'],axis =1)\n",
    "x_test = XY[XY['fecha_dato']=='2016-05-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x_train['age'] = x_train['age'].astype('str').map(str.strip).replace(['NA'],value=-999).astype(float)\n",
    "x_test['age'] = x_test['age'].astype('str').map(str.strip).replace(['NA'],value=-999).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# antiguedad 전처리\n",
    "\n",
    "x_train['antiguedad'] = x_train['antiguedad'].astype('str').map(str.strip)\n",
    "x_train['antiguedad'] = x_train['antiguedad'].replace(['NA'],value=-999).astype('float')\n",
    "x_test['antiguedad'] = x_test['antiguedad'].astype('str').map(str.strip)\n",
    "x_test['antiguedad'] = x_test['antiguedad'].replace(['NA'],value=-999).astype('float')\n",
    "    \n",
    "# x_train['antiguedad'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# indrel_1mes 전처리\n",
    "x_train['indrel_1mes'] = x_train['indrel_1mes'].astype('str').map(str.strip)\n",
    "x_train['indrel_1mes'] = x_train['indrel_1mes'].replace(['P'],value=999)\n",
    "x_train['indrel_1mes'] = x_train['indrel_1mes'].replace(['NA'],value=-999).astype('float')\n",
    "x_test['indrel_1mes'] = x_test['indrel_1mes'].astype('str').map(str.strip)\n",
    "x_test['indrel_1mes'] = x_test['indrel_1mes'].replace(['P'],value=999)\n",
    "x_test['indrel_1mes'] = x_test['indrel_1mes'].replace(['NA'],value=-999).astype('float')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# test renta value 처리\n",
    "\n",
    "x_train['renta']= x_train['renta'].astype('str').map(str.strip).replace(['NA'],value = np.nan).astype(float64)\n",
    "x_test['renta']= x_test['renta'].astype('str').map(str.strip).replace(['NA'],value = np.nan).astype(float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고객 별 방문 건수 \n",
    "# x_train['n_counts'] = x_train['ncodpers'].map(lambda x : x_train['ncodpers'].value_counts())\n",
    "# x_test['n_counts'] = x_train['ncodpers'].map(lambda x : x_train['ncodpers'].value_counts())\n",
    "tmp = x_train['ncodpers'].value_counts().reset_index().rename(columns = {'ncodpers':'n_counts'})\n",
    "x_train = pd.merge(x_train,tmp, how = 'left', left_on =['ncodpers'], right_on =['index'] )\n",
    "x_test = pd.merge(x_test,tmp, how = 'left', left_on =['ncodpers'], right_on =['index'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1740978,)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 중복 row 제거\n",
    "# distinct = list(pd.concat([x_train.drop(['fecha_dato','age'],axis = 1),y_train], axis =1 ).drop_duplicates().index)\n",
    "# x_train = x_train.loc[distinct]\n",
    "# y_train = y_train.loc[distinct]\n",
    "# print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " Index([        -999, '2015-07-02', '2015-07-23', '2015-07-06', '2015-07-30',\n",
       "        '2015-07-20', '2015-07-08', '2015-07-22', '2015-07-17', '2015-07-09',\n",
       "        ...\n",
       "        '2016-02-22', '2016-03-30', '2016-03-07', '2016-04-05', '2016-04-18',\n",
       "        '2016-04-04', '2016-04-26', '2016-04-20', '2016-04-22', '2016-04-15'],\n",
       "       dtype='object', length=113))"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "x_train['month'] = pd.DatetimeIndex(x_train['fecha_dato']).month\n",
    "x_test['month'] = pd.DatetimeIndex(x_test['fecha_dato']).month\n",
    "\n",
    "x_train['year'] = pd.DatetimeIndex(x_train['fecha_dato']).year\n",
    "x_test['year'] = pd.DatetimeIndex(x_test['fecha_dato']).year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fecha_ alta 로 월 주 \n",
    "# \n",
    "x_train['start_month'] = pd.DatetimeIndex(x_train['fecha_alta']).month\n",
    "x_test['start_month'] = pd.DatetimeIndex(x_test['fecha_alta']).month\n",
    "\n",
    "x_train['start_year'] = pd.DatetimeIndex(x_train['fecha_alta']).year\n",
    "x_test['start_year'] = pd.DatetimeIndex(x_test['fecha_alta']).year\n",
    "\n",
    "#추가하기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tipodom /  cod_prov /fecha_dato\n",
    "x_train = x_train.drop(['fecha_dato','fecha_alta','tipodom','cod_prov'],axis =1)\n",
    "x_test = x_test.drop(['fecha_dato','fecha_alta','tipodom','cod_prov'],axis =1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[x_train['indfall']==2]#.value_counts(dropna = False)\n",
    "# x_test[x_test['ncodpers']==1054155].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.fillna(-999)\n",
    "x_test = x_test.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Label encoding , oneho   ->> factorize로 변경해보자\n",
    "cat_cols= x_train.select_dtypes(include=['category']).columns #+ x_train.select_dtypes(include=['object']).columns\n",
    "for col in tqdm(cat_cols) :\n",
    "#     print(col)\n",
    "    try :         \n",
    "        x_train[col] = x_train[col].fillna(-999)\n",
    "        x_test[col] = x_test[col].fillna(-999)\n",
    "    except :\n",
    "#         print(1)\n",
    "        x_train[col] = x_train[col].cat.add_categories(-999).fillna(-999)\n",
    "        x_test[col] = x_test[col].cat.add_categories(-999).fillna(-999)\n",
    "#     print(df[col].isnull().sum())\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(list(x_train[col].values) + list(x_test[col].values))\n",
    "    \n",
    "    x_train[col] = le.transform(list(x_train[col].values))\n",
    "    x_test[col] = le.transform(list(x_test[col].values))\n",
    "    \n",
    "#     print(le.transform(df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = x_train.dtypes[x_train.dtypes =='object'].index.tolist() \n",
    "for col in cols:\n",
    "    x_train[col],_ = x_train[col].factorize()\n",
    "    x_test[col],_ = x_test[col].factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test =x_test.drop(['y'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:3.10646\tvalid-mlogloss:3.10651\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
      "[30]\ttrain-mlogloss:2.11291\tvalid-mlogloss:2.11411\n",
      "[60]\ttrain-mlogloss:1.68238\tvalid-mlogloss:1.68445\n",
      "[90]\ttrain-mlogloss:1.41656\tvalid-mlogloss:1.41933\n",
      "[120]\ttrain-mlogloss:1.23321\tvalid-mlogloss:1.2366\n",
      "[150]\ttrain-mlogloss:1.09971\tvalid-mlogloss:1.10367\n",
      "[180]\ttrain-mlogloss:1.00041\tvalid-mlogloss:1.00488\n",
      "[210]\ttrain-mlogloss:0.926161\tvalid-mlogloss:0.931096\n",
      "[240]\ttrain-mlogloss:0.868993\tvalid-mlogloss:0.874377\n",
      "[270]\ttrain-mlogloss:0.824353\tvalid-mlogloss:0.830187\n",
      "[300]\ttrain-mlogloss:0.789463\tvalid-mlogloss:0.795724\n",
      "[330]\ttrain-mlogloss:0.762112\tvalid-mlogloss:0.768811\n",
      "[360]\ttrain-mlogloss:0.740278\tvalid-mlogloss:0.747408\n",
      "[390]\ttrain-mlogloss:0.722754\tvalid-mlogloss:0.730337\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_fold = 3\n",
    "folds = KFold(n_splits=n_fold, shuffle =True)\n",
    "rounds =  5000\n",
    "# seed = 99\n",
    "params = {'booster' : 'gbtree',\n",
    "          'n_estimators' : 500,\n",
    "          'max_depth':8,\n",
    "          'objective' : 'multi:softprob',\n",
    "          'learning_rate':0.01,\n",
    "          'subsample':0.85,\n",
    "          'colsample_bytree':0.85,\n",
    "          'missing':-999,\n",
    "          'eval_metric' : 'mlogloss',\n",
    "        'tree_method':'gpu_hist',  # THE MAGICAL PARAMETER\n",
    "          'reg_alpha':0.15,\n",
    "          'reg_lamdba':0.85,\n",
    "          'n_jobs' :12 ,\n",
    "          'seed' : 99,\n",
    "          'num_class' :24,\n",
    "          'verbosity' : 1\n",
    "         }\n",
    "preds_list = []\n",
    "for fold, (train_idx,valid_idx) in enumerate(folds.split(x_train)):\n",
    "#     print(fold)\n",
    "#     clf= xgb.XGBClassifier(params)\n",
    "    x_train_,x_valid_ = x_train.iloc[train_idx], x_train.iloc[valid_idx]\n",
    "    y_train_,y_valid_ = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "#     print(y_train_)\n",
    "    xgtrain = xgb.DMatrix(x_train_, label=y_train_.values)\n",
    "    xgvalid = xgb.DMatrix(x_valid_, label=y_valid_.values)\n",
    "    model= xgb.train(params, xgtrain, rounds,evals = [(xgtrain,'train'),(xgvalid,'valid')]\n",
    "                     , verbose_eval = 30\n",
    "                     , early_stopping_rounds = 50)#x_train_,y_train_.values)\n",
    "#     print(\"GPU Training Time: %s seconds\" % (str(time.time() - tmp)))\n",
    "    del xgtrain, xgvalid\n",
    "    xgtest = xgb.DMatrix(x_test)\n",
    "    preds = model.predict(xgtest)\n",
    "    model.__del__() \n",
    "#     del model , xgtest\n",
    "    gc.collect()\n",
    "    preds_list.append(preds)\n",
    "#     clf.predict(x_valid)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 원래 보유하던 상품 찾기\n",
    "cols =  [ 'ncodpers']+[prod +'_prev' for prod in prods] \n",
    "# test에 붙이는 것\n",
    "tmp = pd.merge(x_test['ncodpers'],df[cols].groupby(['ncodpers']).max(), how = 'left', on =['ncodpers'])\n",
    "tmp = tmp.fillna(0)\n",
    "tmp = tmp.as_matrix(columns = [prod +'_prev' for prod in prods] )\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "target_cols = np.array(target_cols)\n",
    "prob_list = np.mean(preds_list, axis =0)\n",
    "prob_list -= tmp  # 원래 보유하던거 제거 / 확률에서 빼기\n",
    "preds = np.argsort(prob_list, axis =1)\n",
    "\n",
    "preds = np.fliplr(preds)[:,:7] #좌우 방향 변경 , 상위 7개 선정\n",
    "test_id = np.array(pd.read_csv(\"test_ver2.csv\", usecols=['ncodpers'])['ncodpers'])\n",
    "f_preds =  [\" \".join(list(target_cols[pred])) for pred in preds]\n",
    "sub_df = pd.DataFrame({'ncodpers':test_id, 'added_products':f_preds})\n",
    "sub_df.to_csv('submission_baseline_XGBOOST_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "seed = 99\n",
    "folds = 3\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class' :24,\n",
    "    'metric': 'multi_logloss',\n",
    "    \n",
    "    \"num_leaves\": 1280,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"reg_lambda\": 2,\n",
    "#     \"num_threads\" : 10,\n",
    "    \"max_bin\" : 255,\n",
    "    'seed' : seed\n",
    "    \n",
    "}\n",
    "\n",
    "categorical_features = [\"ncodpers\",\"ind_empleado\",\"pais_residencia\",\"sexo\",\"ind_nuevo\",\"antiguedad\",\"indrel\",\"indrel_1mes\"\n",
    "                         ,\"tiprel_1mes\",\"indresi\",\"indext\",\"conyuemp\",\"canal_entrada\",\"indfall\",\"nomprov\",\"ind_actividad_cliente\"\n",
    "                        ,\"segmento\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds_list = []\n",
    "# shuffle = False\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=False, random_state=seed)\n",
    "scores = [] \n",
    "models = []\n",
    "for train_index, val_index in kf.split(x_train):\n",
    "    train_X = x_train.iloc[train_index]\n",
    "    val_X = x_train.iloc[val_index]\n",
    "    train_y = y_train.iloc[train_index]\n",
    "    val_y = y_train.iloc[val_index]\n",
    "    print(train_X.shape , train_y.shape)\n",
    "    print(val_X.shape , val_y.shape)\n",
    "    lgb_train = lgb.Dataset(train_X, label = train_y.values,categorical_feature=categorical_features)\n",
    "    lgb_eval = lgb.Dataset(val_X, label = val_y.values,categorical_feature=categorical_features)\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=2000, #300,\n",
    "                    valid_sets=(lgb_train, lgb_eval),\n",
    "#                     feval=rmsle,\n",
    "                    early_stopping_rounds= 50,#100,\n",
    "                    verbose_eval=30) #100)\n",
    "\n",
    "    preds = model.predict(x_test)\n",
    "    gc.collect()\n",
    "    preds_list.append(preds)\n",
    "    \n",
    "    del gbm\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "target_cols = np.array(target_cols)\n",
    "preds = np.argsort(np.mean(preds_list, axis =0), axis =1)# 작은 순서대로 Index를 Return\n",
    "preds = np.fliplr(preds)[:,:7] #좌우 방향 변경 , 상위 7개 선정\n",
    "test_id = np.array(pd.read_csv(\"test_ver2.csv\", usecols=['ncodpers'])['ncodpers'])\n",
    "f_preds =  [\" \".join(list(target_cols[pred])) for pred in preds]\n",
    "sub_df = pd.DataFrame({'ncodpers':test_id, 'added_products':f_preds})\n",
    "sub_df.to_csv('submission_baseline_lightgbm_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
