{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('m5-forecasting-accuracy/sales_train_validation.csv')\n",
    "calendar = pd.read_csv('m5-forecasting-accuracy/calendar.csv')\n",
    "price = pd.read_csv('m5-forecasting-accuracy/sell_prices.csv')\n",
    "# df_test = pd.read_csv('m5-forecasting-accuracy/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 30490/30490 [00:36<00:00, 834.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# # startpoints 찾아서 이전 데이터 지우기\n",
    "startpoints = np.zeros(df_train.shape[0])\n",
    "for idx in tqdm(range(df_train.shape[0])):\n",
    "    startpoints[idx]= np.where(df_train.iloc[idx,6:].values>0)[0].min().astype(int)\n",
    "start_dict = dict(zip(df_train['id'], startpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = []\n",
    "cat_cols = []\n",
    "drop_cols += ['date','d','id']\n",
    "tr_last = 1913\n",
    "# F_1~28 만들기  1914~1941 까지 \n",
    "for i in range(tr_last+1, tr_last+1+28):   df_train['d_%s'%i] = 0\n",
    "\n",
    "# # Unpivot\n",
    "df_train = pd.melt(df_train, id_vars=df_train.columns[:6], value_vars=df_train.columns[6:],\n",
    "       var_name = 'day', value_name = 'volume')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, calendar, left_on = 'day', right_on ='d')\n",
    "# snap 합치기\n",
    "snap = np.zeros(df_train.shape[0])\n",
    "snap[df_train[(df_train['state_id']=='CA')&(df_train['snap_CA']==1)].index] +=1\n",
    "snap[df_train[(df_train['state_id']=='TX')&(df_train['snap_TX']==1)].index] +=1\n",
    "snap[df_train[(df_train['state_id']=='WI')&(df_train['snap_WI']==1)].index] +=1\n",
    "df_train['snap'] = snap\n",
    "drop_cols += ['snap_CA','snap_TX','snap_WI']\n",
    "\n",
    "\n",
    "cat_cols += [ 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n",
    "#               'wday', 'month', 'year', # 이게 크리티컬?\n",
    "            'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap']\n",
    "\n",
    "\n",
    "# ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     46816555\n",
      "False       65122\n",
      "Name: startpoints, dtype: int64\n",
      "(46816555, 26)\n"
     ]
    }
   ],
   "source": [
    "# Sell price\n",
    "df_train.head()\n",
    "df_train = pd.merge(df_train, price)\n",
    "\n",
    "# # Start point 찾기 ::  0.1% 데이터를 날릴  수 있다. \n",
    "\n",
    "df_train['startpoint'] = df_train['id'].map(start_dict).astype(int)#.astype(str)\n",
    "df_train['startpoints'] = df_train['day'].str.slice(start=2).astype(int) >=df_train['startpoint']\n",
    "print(df_train['startpoints'].value_counts())\n",
    "df_train = df_train[df_train['startpoints']]\n",
    "print(df_train.shape)\n",
    "df_train.drop(['startpoint','startpoints'],axis =1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 왜 Shift를 해야할까?\n",
    "# Shift 28을 하지 않으면 예측값이 뒤로 가면갈 수록  F1->F28 예측 할 수 있는 변수가 줄어든게 된다.\n",
    "# 28일은 한달을 의미한다. 최근 한달간의 경향성을 보는 것으로 보면 되겠다.\n",
    "# 28일을 56일로 늘리면 안되나? - 최근 한달간의 경향성이 반영이 안되는 것이낙?\n",
    "# https://www.kaggle.com/kneroma/m5-first-public-notebook-under-0-50\n",
    "\n",
    "df_train['volume_7'] = df_train[['id','volume']].groupby(\"id\")['volume'].shift(7)\n",
    "df_train['volume_28'] = df_train[['id','volume']].groupby(\"id\")['volume'].shift(28)\n",
    "\n",
    "print(\"mean\")\n",
    "\n",
    "df_train['rmean_7_7'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).mean())\n",
    "df_train['rmean_7_28'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).mean())\n",
    "df_train['rmean_7_50'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).mean())\n",
    "\n",
    "df_train['rmean_28_7'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).mean())\n",
    "df_train['rmean_28_28'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).mean())\n",
    "df_train['rmean_28_50'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).mean())\n",
    "\n",
    "# # print(\"std\")\n",
    "# # full_df['rstd_7'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(7 ,min_periods=1).std())\n",
    "# # full_df['rstd_28'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(28 ,min_periods=1).std())\n",
    "# # full_df['rstd_50'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(50 ,min_periods=1).std())\n",
    "\n",
    "# # print(\"max\")\n",
    "# # full_df['rmax_7'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(7 ,min_periods=1).max())\n",
    "# # full_df['rmax_28'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(28 ,min_periods=1).max())\n",
    "# # full_df['rmax_50'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(50 ,min_periods=1).max())\n",
    "\n",
    "# # print(\"min\")\n",
    "# # full_df['rmin_7'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(7 ,min_periods=1).min())\n",
    "# # full_df['rmin_28'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(28 ,min_periods=1).min())\n",
    "# # full_df['rmin_50'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(50 ,min_periods=1).min())\n",
    "\n",
    "# # print(\"count\")\n",
    "# # full_df['rcnt_7'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(7).count() if x>0).fllna(0)\n",
    "# # full_df['rcnt_28'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(28).count() if x>0).fllna(0)\n",
    "# # full_df['rcnt_50'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(28).count() if x>0).fllna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['date'] =  pd.to_datetime(df_train[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['week'] = getattr(df_train[\"date\"].dt, \"weekofyear\").astype(\"int16\")\n",
    "df_train['quarter'] = getattr(df_train[\"date\"].dt,\"quarter\").astype(\"int16\")\n",
    "df_train['mday'] = getattr(df_train[\"date\"].dt, \"day\").astype(\"int16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46816555, 35)\n"
     ]
    }
   ],
   "source": [
    "cols =['event_name_1','event_type_1','event_name_2','event_type_2']\n",
    "df_train[cols]= df_train[cols].fillna('NaN')\n",
    "print(df_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44468825, 35)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date', 'd', 'id', 'snap_CA', 'snap_TX', 'snap_WI', 'wm_yr_wk', 'weekday']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"wm_yr_wk\", \"weekday\"]  ## 이게 문제?\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()\n",
    "tr_last = 1913\n",
    "testday = ['d_%s'% x for x in range(tr_last+1, tr_last+1+28)]\n",
    "train_id = df_train['id']\n",
    "df_test_id = df_train[df_train['day'].isin(testday)]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= df_train.drop(drop_cols,axis =1 )\n",
    "# df_test =df_test.drop(drop_cols,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_28</th>\n",
       "      <th>rmean_7_7</th>\n",
       "      <th>rmean_7_28</th>\n",
       "      <th>rmean_7_50</th>\n",
       "      <th>rmean_28_7</th>\n",
       "      <th>rmean_28_28</th>\n",
       "      <th>rmean_28_50</th>\n",
       "      <th>week</th>\n",
       "      <th>quarter</th>\n",
       "      <th>mday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010975</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.90</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010976</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.66</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010977</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010978</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_81</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010979</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_82</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id    dept_id   cat_id store_id state_id   day  volume  \\\n",
       "1010975  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA  d_78       0   \n",
       "1010976  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA  d_79       0   \n",
       "1010977  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA  d_80       0   \n",
       "1010978  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA  d_81       5   \n",
       "1010979  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA  d_82      23   \n",
       "\n",
       "         wday  month  year  ... volume_28 rmean_7_7 rmean_7_28 rmean_7_50  \\\n",
       "1010975     1      4  2011  ...       0.0  6.857143   1.785714       1.88   \n",
       "1010976     2      4  2011  ...       0.0  4.000000   1.714286       1.68   \n",
       "1010977     3      4  2011  ...       0.0  5.142857   2.000000       1.76   \n",
       "1010978     4      4  2011  ...       0.0  5.714286   2.214286       1.80   \n",
       "1010979     5      4  2011  ...       0.0  4.714286   2.428571       1.88   \n",
       "\n",
       "         rmean_28_7  rmean_28_28  rmean_28_50  week  quarter  mday  \n",
       "1010975    0.285714     1.285714         2.90    15        2    16  \n",
       "1010976    0.000000     1.142857         2.66    15        2    17  \n",
       "1010977    0.000000     1.000000         2.36    16        2    18  \n",
       "1010978    0.000000     0.928571         2.36    16        2    19  \n",
       "1010979    0.000000     0.714286         2.36    16        2    20  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:03<00:00,  6.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Encoding\n",
    "for col in tqdm(cat_cols) :  # encoding -1이 문제?\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col]).astype(np.int8)\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 분리하기\n",
    "testday = ['d_%s'% x for x in range(tr_last+1, tr_last+1+28)]\n",
    "df_test = df_train.copy()\n",
    "df_train = df_train[~df_train['day'].isin(testday)]\n",
    "# train_col = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'day', 'volume', 'wday', 'month', 'year',\n",
    "#  'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap', 'sell_price', 'volume_7', 'volume_28',\n",
    "#  'rmean_7_7', 'rmean_7_28', 'rmean_7_50', 'rmean_28_7', 'rmean_28_28', 'rmean_28_50', 'week', 'quarter', 'mday']\n",
    "# df_train = df_train.loc[:,train_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_28</th>\n",
       "      <th>rmean_7_7</th>\n",
       "      <th>rmean_7_28</th>\n",
       "      <th>rmean_7_50</th>\n",
       "      <th>rmean_28_7</th>\n",
       "      <th>rmean_28_28</th>\n",
       "      <th>rmean_28_50</th>\n",
       "      <th>week</th>\n",
       "      <th>quarter</th>\n",
       "      <th>mday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010975</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.90</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010976</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.66</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010977</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010978</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_81</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010979</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_82</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  dept_id  cat_id  store_id  state_id   day  volume  wday  \\\n",
       "1010975      -92        3       1         0         0  d_78       0     1   \n",
       "1010976      -92        3       1         0         0  d_79       0     2   \n",
       "1010977      -92        3       1         0         0  d_80       0     3   \n",
       "1010978      -92        3       1         0         0  d_81       5     4   \n",
       "1010979      -92        3       1         0         0  d_82      23     5   \n",
       "\n",
       "         month  year  ...  volume_28  rmean_7_7  rmean_7_28  rmean_7_50  \\\n",
       "1010975      4  2011  ...        0.0   6.857143    1.785714        1.88   \n",
       "1010976      4  2011  ...        0.0   4.000000    1.714286        1.68   \n",
       "1010977      4  2011  ...        0.0   5.142857    2.000000        1.76   \n",
       "1010978      4  2011  ...        0.0   5.714286    2.214286        1.80   \n",
       "1010979      4  2011  ...        0.0   4.714286    2.428571        1.88   \n",
       "\n",
       "         rmean_28_7  rmean_28_28  rmean_28_50  week  quarter  mday  \n",
       "1010975    0.285714     1.285714         2.90    15        2    16  \n",
       "1010976    0.000000     1.142857         2.66    15        2    17  \n",
       "1010977    0.000000     1.000000         2.36    16        2    18  \n",
       "1010978    0.000000     0.928571         2.36    16        2    19  \n",
       "1010979    0.000000     0.714286         2.36    16        2    20  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x_train , x_valid = train_test_split(df_train, test_size =0.15, random_state = 99)\n",
    "# y_train, y_valid = x_train['volume'], x_valid['volume']\n",
    "\n",
    "# x_train = x_train.drop(['day','volume'], axis =1)\n",
    "# x_valid = x_valid.drop(['day','volume'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_28</th>\n",
       "      <th>rmean_7_7</th>\n",
       "      <th>rmean_7_28</th>\n",
       "      <th>rmean_7_50</th>\n",
       "      <th>rmean_28_7</th>\n",
       "      <th>rmean_28_28</th>\n",
       "      <th>rmean_28_50</th>\n",
       "      <th>week</th>\n",
       "      <th>quarter</th>\n",
       "      <th>mday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010975</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.90</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010976</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.66</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010977</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010978</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_81</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010979</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_82</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  dept_id  cat_id  store_id  state_id   day  volume  wday  \\\n",
       "1010975      -92        3       1         0         0  d_78       0     1   \n",
       "1010976      -92        3       1         0         0  d_79       0     2   \n",
       "1010977      -92        3       1         0         0  d_80       0     3   \n",
       "1010978      -92        3       1         0         0  d_81       5     4   \n",
       "1010979      -92        3       1         0         0  d_82      23     5   \n",
       "\n",
       "         month  year  ...  volume_28  rmean_7_7  rmean_7_28  rmean_7_50  \\\n",
       "1010975      4  2011  ...        0.0   6.857143    1.785714        1.88   \n",
       "1010976      4  2011  ...        0.0   4.000000    1.714286        1.68   \n",
       "1010977      4  2011  ...        0.0   5.142857    2.000000        1.76   \n",
       "1010978      4  2011  ...        0.0   5.714286    2.214286        1.80   \n",
       "1010979      4  2011  ...        0.0   4.714286    2.428571        1.88   \n",
       "\n",
       "         rmean_28_7  rmean_28_28  rmean_28_50  week  quarter  mday  \n",
       "1010975    0.285714     1.285714         2.90    15        2    16  \n",
       "1010976    0.000000     1.142857         2.66    15        2    17  \n",
       "1010977    0.000000     1.000000         2.36    16        2    18  \n",
       "1010978    0.000000     0.928571         2.36    16        2    19  \n",
       "1010979    0.000000     0.714286         2.36    16        2    20  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"objective\" : \"poisson\",\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.075,\n",
    "#         \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.75,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "#         \"nthread\" : 4\n",
    "        \"metric\": [\"rmse\"],\n",
    "    'verbosity': 1,\n",
    "    'num_iterations' : 5000,\n",
    "    'num_leaves': 128,\n",
    "    \"min_data_in_leaf\": 100,\n",
    "        'n_jobs' :10 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 2.57574\tvalid_1's rmse: 2.58164\n",
      "[100]\ttraining's rmse: 2.50161\tvalid_1's rmse: 2.51345\n",
      "[150]\ttraining's rmse: 2.47887\tvalid_1's rmse: 2.49546\n",
      "[200]\ttraining's rmse: 2.45605\tvalid_1's rmse: 2.47881\n",
      "[250]\ttraining's rmse: 2.43903\tvalid_1's rmse: 2.46735\n",
      "[300]\ttraining's rmse: 2.42382\tvalid_1's rmse: 2.45784\n",
      "[350]\ttraining's rmse: 2.40864\tvalid_1's rmse: 2.44943\n",
      "[400]\ttraining's rmse: 2.39642\tvalid_1's rmse: 2.44268\n",
      "[450]\ttraining's rmse: 2.3859\tvalid_1's rmse: 2.43705\n",
      "[500]\ttraining's rmse: 2.37495\tvalid_1's rmse: 2.43217\n",
      "[550]\ttraining's rmse: 2.36711\tvalid_1's rmse: 2.42888\n",
      "[600]\ttraining's rmse: 2.35945\tvalid_1's rmse: 2.42577\n",
      "[650]\ttraining's rmse: 2.35138\tvalid_1's rmse: 2.4226\n",
      "[700]\ttraining's rmse: 2.34458\tvalid_1's rmse: 2.42012\n",
      "[750]\ttraining's rmse: 2.33707\tvalid_1's rmse: 2.41741\n",
      "[800]\ttraining's rmse: 2.32908\tvalid_1's rmse: 2.41409\n",
      "[850]\ttraining's rmse: 2.32198\tvalid_1's rmse: 2.41101\n",
      "[900]\ttraining's rmse: 2.31621\tvalid_1's rmse: 2.40902\n",
      "[950]\ttraining's rmse: 2.30922\tvalid_1's rmse: 2.4068\n",
      "[1000]\ttraining's rmse: 2.30296\tvalid_1's rmse: 2.40499\n",
      "[1050]\ttraining's rmse: 2.29761\tvalid_1's rmse: 2.40338\n",
      "[1100]\ttraining's rmse: 2.29316\tvalid_1's rmse: 2.40185\n",
      "[1150]\ttraining's rmse: 2.28916\tvalid_1's rmse: 2.40066\n",
      "[1200]\ttraining's rmse: 2.28479\tvalid_1's rmse: 2.39928\n",
      "[1250]\ttraining's rmse: 2.2798\tvalid_1's rmse: 2.39728\n",
      "[1300]\ttraining's rmse: 2.27515\tvalid_1's rmse: 2.39597\n",
      "[1350]\ttraining's rmse: 2.27117\tvalid_1's rmse: 2.39475\n",
      "[1400]\ttraining's rmse: 2.2671\tvalid_1's rmse: 2.39357\n",
      "[1450]\ttraining's rmse: 2.26293\tvalid_1's rmse: 2.39246\n",
      "[1500]\ttraining's rmse: 2.25919\tvalid_1's rmse: 2.39146\n",
      "[1550]\ttraining's rmse: 2.25548\tvalid_1's rmse: 2.39036\n",
      "[1600]\ttraining's rmse: 2.25266\tvalid_1's rmse: 2.3898\n",
      "[1650]\ttraining's rmse: 2.24895\tvalid_1's rmse: 2.38879\n",
      "[1700]\ttraining's rmse: 2.24474\tvalid_1's rmse: 2.3878\n",
      "[1750]\ttraining's rmse: 2.24112\tvalid_1's rmse: 2.38699\n",
      "[1800]\ttraining's rmse: 2.23758\tvalid_1's rmse: 2.38602\n",
      "[1850]\ttraining's rmse: 2.23399\tvalid_1's rmse: 2.38511\n",
      "[1900]\ttraining's rmse: 2.23043\tvalid_1's rmse: 2.38387\n",
      "[1950]\ttraining's rmse: 2.22708\tvalid_1's rmse: 2.38301\n",
      "[2000]\ttraining's rmse: 2.22367\tvalid_1's rmse: 2.38208\n",
      "[2050]\ttraining's rmse: 2.22054\tvalid_1's rmse: 2.38121\n",
      "[2100]\ttraining's rmse: 2.21699\tvalid_1's rmse: 2.38007\n",
      "[2150]\ttraining's rmse: 2.21393\tvalid_1's rmse: 2.37931\n",
      "[2200]\ttraining's rmse: 2.2107\tvalid_1's rmse: 2.37844\n",
      "[2250]\ttraining's rmse: 2.20699\tvalid_1's rmse: 2.37761\n",
      "[2300]\ttraining's rmse: 2.20343\tvalid_1's rmse: 2.37657\n",
      "[2350]\ttraining's rmse: 2.20036\tvalid_1's rmse: 2.37586\n",
      "[2400]\ttraining's rmse: 2.19721\tvalid_1's rmse: 2.37498\n",
      "[2450]\ttraining's rmse: 2.19435\tvalid_1's rmse: 2.37439\n",
      "[2500]\ttraining's rmse: 2.19155\tvalid_1's rmse: 2.37354\n",
      "[2550]\ttraining's rmse: 2.18902\tvalid_1's rmse: 2.37297\n",
      "[2600]\ttraining's rmse: 2.18647\tvalid_1's rmse: 2.37257\n",
      "[2650]\ttraining's rmse: 2.18332\tvalid_1's rmse: 2.3715\n",
      "[2700]\ttraining's rmse: 2.18046\tvalid_1's rmse: 2.37083\n",
      "[2750]\ttraining's rmse: 2.17766\tvalid_1's rmse: 2.37024\n",
      "[2800]\ttraining's rmse: 2.17494\tvalid_1's rmse: 2.36965\n",
      "[2850]\ttraining's rmse: 2.17194\tvalid_1's rmse: 2.36891\n",
      "[2900]\ttraining's rmse: 2.16914\tvalid_1's rmse: 2.36834\n",
      "[2950]\ttraining's rmse: 2.16692\tvalid_1's rmse: 2.36797\n",
      "[3000]\ttraining's rmse: 2.16437\tvalid_1's rmse: 2.36725\n",
      "[3050]\ttraining's rmse: 2.16179\tvalid_1's rmse: 2.36673\n",
      "[3100]\ttraining's rmse: 2.15941\tvalid_1's rmse: 2.36645\n",
      "[3150]\ttraining's rmse: 2.15714\tvalid_1's rmse: 2.36578\n",
      "[3200]\ttraining's rmse: 2.15503\tvalid_1's rmse: 2.36544\n",
      "[3250]\ttraining's rmse: 2.15299\tvalid_1's rmse: 2.36494\n",
      "[3300]\ttraining's rmse: 2.15097\tvalid_1's rmse: 2.36468\n",
      "[3350]\ttraining's rmse: 2.14853\tvalid_1's rmse: 2.36433\n",
      "[3400]\ttraining's rmse: 2.14635\tvalid_1's rmse: 2.36383\n",
      "[3450]\ttraining's rmse: 2.14435\tvalid_1's rmse: 2.36348\n",
      "[3500]\ttraining's rmse: 2.1421\tvalid_1's rmse: 2.36304\n",
      "[3550]\ttraining's rmse: 2.13994\tvalid_1's rmse: 2.3627\n",
      "[3600]\ttraining's rmse: 2.13749\tvalid_1's rmse: 2.36206\n",
      "[3650]\ttraining's rmse: 2.13523\tvalid_1's rmse: 2.36158\n",
      "[3700]\ttraining's rmse: 2.13308\tvalid_1's rmse: 2.36117\n",
      "[3750]\ttraining's rmse: 2.13124\tvalid_1's rmse: 2.36081\n",
      "[3800]\ttraining's rmse: 2.12932\tvalid_1's rmse: 2.36051\n",
      "[3850]\ttraining's rmse: 2.12727\tvalid_1's rmse: 2.36029\n",
      "[3900]\ttraining's rmse: 2.12503\tvalid_1's rmse: 2.35984\n",
      "[3950]\ttraining's rmse: 2.12348\tvalid_1's rmse: 2.35958\n",
      "[4000]\ttraining's rmse: 2.12173\tvalid_1's rmse: 2.35921\n",
      "[4050]\ttraining's rmse: 2.11996\tvalid_1's rmse: 2.35885\n",
      "[4100]\ttraining's rmse: 2.11807\tvalid_1's rmse: 2.35845\n",
      "[4150]\ttraining's rmse: 2.11605\tvalid_1's rmse: 2.35794\n",
      "[4200]\ttraining's rmse: 2.11404\tvalid_1's rmse: 2.35756\n",
      "[4250]\ttraining's rmse: 2.11231\tvalid_1's rmse: 2.35734\n",
      "[4300]\ttraining's rmse: 2.11083\tvalid_1's rmse: 2.35719\n",
      "[4350]\ttraining's rmse: 2.10896\tvalid_1's rmse: 2.3569\n",
      "[4400]\ttraining's rmse: 2.1068\tvalid_1's rmse: 2.35639\n",
      "[4450]\ttraining's rmse: 2.1049\tvalid_1's rmse: 2.35619\n",
      "[4500]\ttraining's rmse: 2.10314\tvalid_1's rmse: 2.35587\n",
      "[4550]\ttraining's rmse: 2.10145\tvalid_1's rmse: 2.35552\n",
      "[4600]\ttraining's rmse: 2.09976\tvalid_1's rmse: 2.35529\n",
      "[4650]\ttraining's rmse: 2.09755\tvalid_1's rmse: 2.35471\n",
      "[4700]\ttraining's rmse: 2.09576\tvalid_1's rmse: 2.3544\n",
      "[4750]\ttraining's rmse: 2.09426\tvalid_1's rmse: 2.3541\n",
      "[4800]\ttraining's rmse: 2.09271\tvalid_1's rmse: 2.35391\n",
      "[4850]\ttraining's rmse: 2.09089\tvalid_1's rmse: 2.35349\n",
      "[4900]\ttraining's rmse: 2.0892\tvalid_1's rmse: 2.35311\n",
      "[4950]\ttraining's rmse: 2.08723\tvalid_1's rmse: 2.35281\n",
      "[5000]\ttraining's rmse: 2.08573\tvalid_1's rmse: 2.35253\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's rmse: 2.08573\tvalid_1's rmse: 2.35253\n",
      "1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 2.57003\tvalid_1's rmse: 2.60042\n",
      "[100]\ttraining's rmse: 2.48889\tvalid_1's rmse: 2.52682\n",
      "[150]\ttraining's rmse: 2.46571\tvalid_1's rmse: 2.50928\n",
      "[200]\ttraining's rmse: 2.44289\tvalid_1's rmse: 2.49238\n",
      "[250]\ttraining's rmse: 2.42385\tvalid_1's rmse: 2.47845\n",
      "[300]\ttraining's rmse: 2.40746\tvalid_1's rmse: 2.46739\n",
      "[350]\ttraining's rmse: 2.39601\tvalid_1's rmse: 2.46055\n",
      "[400]\ttraining's rmse: 2.38433\tvalid_1's rmse: 2.45469\n",
      "[450]\ttraining's rmse: 2.37352\tvalid_1's rmse: 2.44896\n",
      "[500]\ttraining's rmse: 2.36331\tvalid_1's rmse: 2.44439\n",
      "[550]\ttraining's rmse: 2.35481\tvalid_1's rmse: 2.44036\n",
      "[600]\ttraining's rmse: 2.34643\tvalid_1's rmse: 2.43679\n",
      "[650]\ttraining's rmse: 2.33911\tvalid_1's rmse: 2.4337\n",
      "[700]\ttraining's rmse: 2.33226\tvalid_1's rmse: 2.43123\n",
      "[750]\ttraining's rmse: 2.32629\tvalid_1's rmse: 2.42901\n",
      "[800]\ttraining's rmse: 2.32019\tvalid_1's rmse: 2.42665\n",
      "[850]\ttraining's rmse: 2.31425\tvalid_1's rmse: 2.42421\n",
      "[900]\ttraining's rmse: 2.30878\tvalid_1's rmse: 2.42203\n",
      "[950]\ttraining's rmse: 2.30311\tvalid_1's rmse: 2.42011\n",
      "[1000]\ttraining's rmse: 2.29753\tvalid_1's rmse: 2.41812\n",
      "[1050]\ttraining's rmse: 2.29349\tvalid_1's rmse: 2.41697\n",
      "[1100]\ttraining's rmse: 2.28862\tvalid_1's rmse: 2.41535\n",
      "[1150]\ttraining's rmse: 2.28362\tvalid_1's rmse: 2.41371\n",
      "[1200]\ttraining's rmse: 2.27922\tvalid_1's rmse: 2.4124\n",
      "[1250]\ttraining's rmse: 2.2749\tvalid_1's rmse: 2.41121\n",
      "[1300]\ttraining's rmse: 2.27099\tvalid_1's rmse: 2.40997\n",
      "[1350]\ttraining's rmse: 2.26686\tvalid_1's rmse: 2.40876\n",
      "[1400]\ttraining's rmse: 2.26274\tvalid_1's rmse: 2.40734\n",
      "[1450]\ttraining's rmse: 2.2584\tvalid_1's rmse: 2.40625\n",
      "[1500]\ttraining's rmse: 2.25469\tvalid_1's rmse: 2.40524\n",
      "[1550]\ttraining's rmse: 2.25067\tvalid_1's rmse: 2.40404\n",
      "[1600]\ttraining's rmse: 2.24682\tvalid_1's rmse: 2.40325\n",
      "[1650]\ttraining's rmse: 2.24319\tvalid_1's rmse: 2.40224\n",
      "[1700]\ttraining's rmse: 2.23944\tvalid_1's rmse: 2.4009\n",
      "[1750]\ttraining's rmse: 2.23601\tvalid_1's rmse: 2.39993\n",
      "[1800]\ttraining's rmse: 2.23238\tvalid_1's rmse: 2.3989\n",
      "[1850]\ttraining's rmse: 2.22942\tvalid_1's rmse: 2.39819\n",
      "[1900]\ttraining's rmse: 2.22557\tvalid_1's rmse: 2.39716\n",
      "[1950]\ttraining's rmse: 2.22222\tvalid_1's rmse: 2.39622\n",
      "[2000]\ttraining's rmse: 2.21844\tvalid_1's rmse: 2.39513\n",
      "[2050]\ttraining's rmse: 2.2154\tvalid_1's rmse: 2.39428\n",
      "[2100]\ttraining's rmse: 2.21247\tvalid_1's rmse: 2.39358\n",
      "[2150]\ttraining's rmse: 2.20959\tvalid_1's rmse: 2.39286\n",
      "[2200]\ttraining's rmse: 2.2071\tvalid_1's rmse: 2.39238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2250]\ttraining's rmse: 2.20447\tvalid_1's rmse: 2.39179\n",
      "[2300]\ttraining's rmse: 2.20158\tvalid_1's rmse: 2.39103\n",
      "[2350]\ttraining's rmse: 2.19867\tvalid_1's rmse: 2.39038\n",
      "[2400]\ttraining's rmse: 2.19594\tvalid_1's rmse: 2.38974\n",
      "[2450]\ttraining's rmse: 2.19355\tvalid_1's rmse: 2.3892\n",
      "[2500]\ttraining's rmse: 2.19081\tvalid_1's rmse: 2.38861\n",
      "[2550]\ttraining's rmse: 2.18838\tvalid_1's rmse: 2.388\n",
      "[2600]\ttraining's rmse: 2.18582\tvalid_1's rmse: 2.38743\n",
      "[2650]\ttraining's rmse: 2.18369\tvalid_1's rmse: 2.38698\n",
      "[2700]\ttraining's rmse: 2.18154\tvalid_1's rmse: 2.38636\n",
      "[2750]\ttraining's rmse: 2.17924\tvalid_1's rmse: 2.38608\n",
      "[2800]\ttraining's rmse: 2.17701\tvalid_1's rmse: 2.3855\n",
      "[2850]\ttraining's rmse: 2.17421\tvalid_1's rmse: 2.38477\n",
      "[2900]\ttraining's rmse: 2.17146\tvalid_1's rmse: 2.38404\n",
      "[2950]\ttraining's rmse: 2.16907\tvalid_1's rmse: 2.38355\n",
      "[3000]\ttraining's rmse: 2.16681\tvalid_1's rmse: 2.38301\n",
      "[3050]\ttraining's rmse: 2.16453\tvalid_1's rmse: 2.38267\n",
      "[3100]\ttraining's rmse: 2.1622\tvalid_1's rmse: 2.38237\n",
      "[3150]\ttraining's rmse: 2.16008\tvalid_1's rmse: 2.38172\n",
      "[3200]\ttraining's rmse: 2.15761\tvalid_1's rmse: 2.38122\n",
      "[3250]\ttraining's rmse: 2.15533\tvalid_1's rmse: 2.38061\n",
      "[3300]\ttraining's rmse: 2.15307\tvalid_1's rmse: 2.38018\n",
      "[3350]\ttraining's rmse: 2.15091\tvalid_1's rmse: 2.37973\n",
      "[3400]\ttraining's rmse: 2.14901\tvalid_1's rmse: 2.37943\n",
      "[3450]\ttraining's rmse: 2.14671\tvalid_1's rmse: 2.37918\n",
      "[3500]\ttraining's rmse: 2.14421\tvalid_1's rmse: 2.37864\n",
      "[3550]\ttraining's rmse: 2.14205\tvalid_1's rmse: 2.37822\n",
      "[3600]\ttraining's rmse: 2.13999\tvalid_1's rmse: 2.37784\n",
      "[3650]\ttraining's rmse: 2.13821\tvalid_1's rmse: 2.37744\n",
      "[3700]\ttraining's rmse: 2.13627\tvalid_1's rmse: 2.37696\n",
      "[3750]\ttraining's rmse: 2.1344\tvalid_1's rmse: 2.37663\n",
      "[3800]\ttraining's rmse: 2.13233\tvalid_1's rmse: 2.37637\n",
      "[3850]\ttraining's rmse: 2.13095\tvalid_1's rmse: 2.37609\n",
      "[3900]\ttraining's rmse: 2.12833\tvalid_1's rmse: 2.37545\n",
      "[3950]\ttraining's rmse: 2.12614\tvalid_1's rmse: 2.37484\n",
      "[4000]\ttraining's rmse: 2.12448\tvalid_1's rmse: 2.37458\n",
      "[4050]\ttraining's rmse: 2.12267\tvalid_1's rmse: 2.37426\n",
      "[4100]\ttraining's rmse: 2.12085\tvalid_1's rmse: 2.37399\n",
      "[4150]\ttraining's rmse: 2.1186\tvalid_1's rmse: 2.37356\n",
      "[4200]\ttraining's rmse: 2.11692\tvalid_1's rmse: 2.37344\n",
      "[4250]\ttraining's rmse: 2.11495\tvalid_1's rmse: 2.3731\n",
      "[4300]\ttraining's rmse: 2.11296\tvalid_1's rmse: 2.37269\n",
      "[4350]\ttraining's rmse: 2.11156\tvalid_1's rmse: 2.3724\n",
      "[4400]\ttraining's rmse: 2.10956\tvalid_1's rmse: 2.37205\n",
      "[4450]\ttraining's rmse: 2.10755\tvalid_1's rmse: 2.37167\n",
      "[4500]\ttraining's rmse: 2.10597\tvalid_1's rmse: 2.37126\n",
      "[4550]\ttraining's rmse: 2.10409\tvalid_1's rmse: 2.37088\n",
      "[4600]\ttraining's rmse: 2.10245\tvalid_1's rmse: 2.37049\n",
      "[4650]\ttraining's rmse: 2.10053\tvalid_1's rmse: 2.3702\n",
      "[4700]\ttraining's rmse: 2.09895\tvalid_1's rmse: 2.36984\n",
      "[4750]\ttraining's rmse: 2.09717\tvalid_1's rmse: 2.36958\n",
      "[4800]\ttraining's rmse: 2.09542\tvalid_1's rmse: 2.3694\n",
      "[4850]\ttraining's rmse: 2.09408\tvalid_1's rmse: 2.36914\n",
      "[4900]\ttraining's rmse: 2.09278\tvalid_1's rmse: 2.36885\n",
      "[4950]\ttraining's rmse: 2.09123\tvalid_1's rmse: 2.36861\n",
      "[5000]\ttraining's rmse: 2.0897\tvalid_1's rmse: 2.36834\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's rmse: 2.0897\tvalid_1's rmse: 2.36834\n",
      "2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 2.57459\tvalid_1's rmse: 2.56618\n",
      "[100]\ttraining's rmse: 2.50218\tvalid_1's rmse: 2.50107\n",
      "[150]\ttraining's rmse: 2.47999\tvalid_1's rmse: 2.48351\n",
      "[200]\ttraining's rmse: 2.46024\tvalid_1's rmse: 2.469\n",
      "[250]\ttraining's rmse: 2.44231\tvalid_1's rmse: 2.45625\n",
      "[300]\ttraining's rmse: 2.4253\tvalid_1's rmse: 2.44506\n",
      "[350]\ttraining's rmse: 2.41274\tvalid_1's rmse: 2.43807\n",
      "[400]\ttraining's rmse: 2.39974\tvalid_1's rmse: 2.43035\n",
      "[450]\ttraining's rmse: 2.38778\tvalid_1's rmse: 2.42352\n",
      "[500]\ttraining's rmse: 2.37793\tvalid_1's rmse: 2.41813\n",
      "[550]\ttraining's rmse: 2.36765\tvalid_1's rmse: 2.41388\n",
      "[600]\ttraining's rmse: 2.35917\tvalid_1's rmse: 2.41048\n",
      "[650]\ttraining's rmse: 2.35244\tvalid_1's rmse: 2.40784\n",
      "[700]\ttraining's rmse: 2.34536\tvalid_1's rmse: 2.40499\n",
      "[750]\ttraining's rmse: 2.33873\tvalid_1's rmse: 2.40282\n",
      "[800]\ttraining's rmse: 2.33198\tvalid_1's rmse: 2.40001\n",
      "[850]\ttraining's rmse: 2.32586\tvalid_1's rmse: 2.39783\n",
      "[900]\ttraining's rmse: 2.32024\tvalid_1's rmse: 2.3959\n",
      "[950]\ttraining's rmse: 2.31394\tvalid_1's rmse: 2.39383\n",
      "[1000]\ttraining's rmse: 2.30887\tvalid_1's rmse: 2.39199\n",
      "[1050]\ttraining's rmse: 2.30368\tvalid_1's rmse: 2.39029\n",
      "[1100]\ttraining's rmse: 2.29853\tvalid_1's rmse: 2.38857\n",
      "[1150]\ttraining's rmse: 2.29349\tvalid_1's rmse: 2.38673\n",
      "[1200]\ttraining's rmse: 2.28837\tvalid_1's rmse: 2.38528\n",
      "[1250]\ttraining's rmse: 2.28317\tvalid_1's rmse: 2.38343\n",
      "[1300]\ttraining's rmse: 2.27853\tvalid_1's rmse: 2.38193\n",
      "[1350]\ttraining's rmse: 2.2744\tvalid_1's rmse: 2.38094\n",
      "[1400]\ttraining's rmse: 2.26912\tvalid_1's rmse: 2.37943\n",
      "[1450]\ttraining's rmse: 2.26493\tvalid_1's rmse: 2.37832\n",
      "[1500]\ttraining's rmse: 2.26143\tvalid_1's rmse: 2.37742\n",
      "[1550]\ttraining's rmse: 2.25767\tvalid_1's rmse: 2.37663\n",
      "[1600]\ttraining's rmse: 2.25399\tvalid_1's rmse: 2.3757\n",
      "[1650]\ttraining's rmse: 2.25017\tvalid_1's rmse: 2.37462\n",
      "[1700]\ttraining's rmse: 2.24576\tvalid_1's rmse: 2.37351\n",
      "[1750]\ttraining's rmse: 2.24184\tvalid_1's rmse: 2.37255\n",
      "[1800]\ttraining's rmse: 2.23865\tvalid_1's rmse: 2.37174\n",
      "[1850]\ttraining's rmse: 2.23504\tvalid_1's rmse: 2.37094\n",
      "[1900]\ttraining's rmse: 2.2317\tvalid_1's rmse: 2.36995\n",
      "[1950]\ttraining's rmse: 2.22825\tvalid_1's rmse: 2.36914\n",
      "[2000]\ttraining's rmse: 2.22506\tvalid_1's rmse: 2.36833\n",
      "[2050]\ttraining's rmse: 2.22152\tvalid_1's rmse: 2.36741\n",
      "[2100]\ttraining's rmse: 2.21849\tvalid_1's rmse: 2.36654\n",
      "[2150]\ttraining's rmse: 2.21555\tvalid_1's rmse: 2.36577\n",
      "[2200]\ttraining's rmse: 2.21225\tvalid_1's rmse: 2.36495\n",
      "[2250]\ttraining's rmse: 2.20917\tvalid_1's rmse: 2.36406\n",
      "[2300]\ttraining's rmse: 2.20597\tvalid_1's rmse: 2.36336\n",
      "[2350]\ttraining's rmse: 2.20293\tvalid_1's rmse: 2.36255\n",
      "[2400]\ttraining's rmse: 2.1999\tvalid_1's rmse: 2.36179\n",
      "[2450]\ttraining's rmse: 2.19733\tvalid_1's rmse: 2.3613\n",
      "[2500]\ttraining's rmse: 2.1948\tvalid_1's rmse: 2.36075\n",
      "[2550]\ttraining's rmse: 2.19249\tvalid_1's rmse: 2.36025\n",
      "[2600]\ttraining's rmse: 2.18984\tvalid_1's rmse: 2.35976\n",
      "[2650]\ttraining's rmse: 2.18735\tvalid_1's rmse: 2.35909\n",
      "[2700]\ttraining's rmse: 2.18482\tvalid_1's rmse: 2.35857\n",
      "[2750]\ttraining's rmse: 2.18156\tvalid_1's rmse: 2.35773\n",
      "[2800]\ttraining's rmse: 2.17904\tvalid_1's rmse: 2.35723\n",
      "[2850]\ttraining's rmse: 2.17703\tvalid_1's rmse: 2.35685\n",
      "[2900]\ttraining's rmse: 2.17463\tvalid_1's rmse: 2.35632\n",
      "[2950]\ttraining's rmse: 2.17222\tvalid_1's rmse: 2.35575\n",
      "[3000]\ttraining's rmse: 2.17002\tvalid_1's rmse: 2.35561\n",
      "[3050]\ttraining's rmse: 2.16738\tvalid_1's rmse: 2.35512\n",
      "[3100]\ttraining's rmse: 2.16537\tvalid_1's rmse: 2.3546\n",
      "[3150]\ttraining's rmse: 2.16271\tvalid_1's rmse: 2.35407\n",
      "[3200]\ttraining's rmse: 2.16033\tvalid_1's rmse: 2.35362\n",
      "[3250]\ttraining's rmse: 2.15799\tvalid_1's rmse: 2.35313\n",
      "[3300]\ttraining's rmse: 2.156\tvalid_1's rmse: 2.35275\n",
      "[3350]\ttraining's rmse: 2.15369\tvalid_1's rmse: 2.3525\n",
      "[3400]\ttraining's rmse: 2.15149\tvalid_1's rmse: 2.35208\n",
      "[3450]\ttraining's rmse: 2.14951\tvalid_1's rmse: 2.35154\n",
      "[3500]\ttraining's rmse: 2.14763\tvalid_1's rmse: 2.35106\n",
      "[3550]\ttraining's rmse: 2.14579\tvalid_1's rmse: 2.35076\n",
      "[3600]\ttraining's rmse: 2.14387\tvalid_1's rmse: 2.35052\n",
      "[3650]\ttraining's rmse: 2.1417\tvalid_1's rmse: 2.35007\n",
      "[3700]\ttraining's rmse: 2.13979\tvalid_1's rmse: 2.34959\n",
      "[3750]\ttraining's rmse: 2.13776\tvalid_1's rmse: 2.34916\n",
      "[3800]\ttraining's rmse: 2.13584\tvalid_1's rmse: 2.34876\n",
      "[3850]\ttraining's rmse: 2.13383\tvalid_1's rmse: 2.34827\n",
      "[3900]\ttraining's rmse: 2.13179\tvalid_1's rmse: 2.34786\n",
      "[3950]\ttraining's rmse: 2.12968\tvalid_1's rmse: 2.34748\n",
      "[4000]\ttraining's rmse: 2.1276\tvalid_1's rmse: 2.34726\n",
      "[4050]\ttraining's rmse: 2.12567\tvalid_1's rmse: 2.3471\n",
      "[4100]\ttraining's rmse: 2.1236\tvalid_1's rmse: 2.34678\n",
      "[4150]\ttraining's rmse: 2.12192\tvalid_1's rmse: 2.34647\n",
      "[4200]\ttraining's rmse: 2.12001\tvalid_1's rmse: 2.34602\n",
      "[4250]\ttraining's rmse: 2.11797\tvalid_1's rmse: 2.34582\n",
      "[4300]\ttraining's rmse: 2.11607\tvalid_1's rmse: 2.3455\n",
      "[4350]\ttraining's rmse: 2.11394\tvalid_1's rmse: 2.34512\n",
      "[4400]\ttraining's rmse: 2.11172\tvalid_1's rmse: 2.34482\n",
      "[4450]\ttraining's rmse: 2.10973\tvalid_1's rmse: 2.34453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4500]\ttraining's rmse: 2.10771\tvalid_1's rmse: 2.34405\n",
      "[4550]\ttraining's rmse: 2.1056\tvalid_1's rmse: 2.34367\n",
      "[4600]\ttraining's rmse: 2.10377\tvalid_1's rmse: 2.34342\n",
      "[4650]\ttraining's rmse: 2.10196\tvalid_1's rmse: 2.3431\n",
      "[4700]\ttraining's rmse: 2.09998\tvalid_1's rmse: 2.34281\n",
      "[4750]\ttraining's rmse: 2.09814\tvalid_1's rmse: 2.34246\n",
      "[4800]\ttraining's rmse: 2.09684\tvalid_1's rmse: 2.34252\n",
      "Early stopping, best iteration is:\n",
      "[4763]\ttraining's rmse: 2.09788\tvalid_1's rmse: 2.34243\n",
      "Wall time: 3h 30min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed = 99\n",
    "folds = 3\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import pickle\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, random_state=seed, shuffle=True)\n",
    "\n",
    "for idx, (train_index, test_index) in enumerate(skf.split(df_train.index,df_train['volume'])):\n",
    "    print(idx)\n",
    "    x_train = df_train.iloc[train_index].drop(['day','volume'], axis =1)\n",
    "    y_train = df_train.iloc[train_index]['volume']\n",
    "    x_valid = df_train.iloc[test_index].drop(['day','volume'], axis =1)\n",
    "    y_valid = df_train.iloc[test_index]['volume'] \n",
    "    \n",
    "    # Modeling\n",
    "    lgb_train = lgb.Dataset(x_train, y_train,categorical_feature=cat_cols)\n",
    "    lgb_eval = lgb.Dataset(x_valid, y_valid,categorical_feature=cat_cols)\n",
    "    gbm = lgb.train(params, lgb_train,\n",
    "#                     num_boost_round=1000, \n",
    "                    valid_sets=(lgb_train, lgb_eval),\n",
    "                    early_stopping_rounds= 50,#100,\n",
    "                    verbose_eval=50) #100)\n",
    "\n",
    "    pickle.dump(gbm,open( \"20200430_model_%s.pkl\"%idx, \"wb\" ))\n",
    "        \n",
    "    del gbm\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1914\n",
      "rolling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1915\n",
      "rolling\n",
      "mean\n",
      "1916\n",
      "rolling\n",
      "mean\n",
      "1917\n",
      "rolling\n",
      "mean\n",
      "1918\n",
      "rolling\n",
      "mean\n",
      "1919\n",
      "rolling\n",
      "mean\n",
      "1920\n",
      "rolling\n",
      "mean\n",
      "1921\n",
      "rolling\n",
      "mean\n",
      "1922\n",
      "rolling\n",
      "mean\n",
      "1923\n",
      "rolling\n",
      "mean\n",
      "1924\n",
      "rolling\n",
      "mean\n",
      "1925\n",
      "rolling\n",
      "mean\n",
      "1926\n",
      "rolling\n",
      "mean\n",
      "1927\n",
      "rolling\n",
      "mean\n",
      "1928\n",
      "rolling\n",
      "mean\n",
      "1929\n",
      "rolling\n",
      "mean\n",
      "1930\n",
      "rolling\n",
      "mean\n",
      "1931\n",
      "rolling\n",
      "mean\n",
      "1932\n",
      "rolling\n",
      "mean\n",
      "1933\n",
      "rolling\n",
      "mean\n",
      "1934\n",
      "rolling\n",
      "mean\n",
      "1935\n",
      "rolling\n",
      "mean\n",
      "1936\n",
      "rolling\n",
      "mean\n",
      "1937\n",
      "rolling\n",
      "mean\n",
      "1938\n",
      "rolling\n",
      "mean\n",
      "1939\n",
      "rolling\n",
      "mean\n",
      "1940\n",
      "rolling\n",
      "mean\n",
      "1941\n",
      "rolling\n",
      "mean\n",
      "Wall time: 42min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test['id'] = train_id\n",
    "max_lag  = 120\n",
    "trn_lst = 1913\n",
    "for tdelta in range(1, 29):\n",
    "    f_day = trn_lst+tdelta\n",
    "    print(f_day)\n",
    "    days = [f\"d_{i}\" for i in range(trn_lst-max_lag+tdelta,f_day+1)]\n",
    "    tst = df_test[df_test['day'].isin(days)]\n",
    "\n",
    "    print(\"rolling\")\n",
    "    tst['volume_7'] = tst[['id','volume']].groupby(\"id\")['volume'].shift(7)\n",
    "    tst['volume_28'] = tst[['id','volume']].groupby(\"id\")['volume'].shift(28)\n",
    "    \n",
    "    print(\"mean\")\n",
    "    tst['rmean_7_7'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).mean())\n",
    "    tst['rmean_7_28'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).mean())\n",
    "    tst['rmean_7_50'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).mean())\n",
    "\n",
    "    tst['rmean_28_7'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).mean())\n",
    "    tst['rmean_28_28'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).mean())\n",
    "    tst['rmean_28_50'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).mean())\n",
    "    \n",
    "    \n",
    "    tst = tst[tst['day'] == \"d_%s\"%(f_day)]\n",
    "    t_id,t_volume,t_day = tst['id'],tst['volume'],tst['day']\n",
    "    tst = tst.drop(['id','volume','day'], axis =1)\n",
    "    \n",
    "    # Crossvalidation \n",
    "    for idx in range(folds):\n",
    "        gbm = pickle.load(open( \"20200430_model_%s.pkl\"%idx, \"rb\" ))\n",
    "        df_test.loc[df_test.day==\"d_%s\"%(f_day),'volume'] += 1.028*gbm.predict(tst) / folds\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f\"d_{i}\" for i in range(1914,1942)]\n",
    "\n",
    "sub = df_test[df_test['day'].isin(cols)].loc[:,['id','volume']]\n",
    "sub['F']= [f\"F{rank}\" for rank in sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "sub = sub.set_index([\"id\", \"F\" ]).unstack()[\"volume\"].reset_index()\n",
    "sub.sort_values(\"id\", inplace = True)\n",
    "sub.reset_index(drop=True, inplace = True)                                                   \n",
    "sub =sub[['id']+[\"F%s\"% x for x in range(1,29)]]\n",
    "\n",
    "sub = sub.fillna(0)\n",
    "\n",
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "sub.to_csv(\"submission_20200430_5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F\n",
       "id     0\n",
       "F1     0\n",
       "F2     0\n",
       "F3     0\n",
       "F4     0\n",
       "F5     0\n",
       "F6     0\n",
       "F7     0\n",
       "F8     0\n",
       "F9     0\n",
       "F10    0\n",
       "F11    0\n",
       "F12    0\n",
       "F13    0\n",
       "F14    0\n",
       "F15    0\n",
       "F16    0\n",
       "F17    0\n",
       "F18    0\n",
       "F19    0\n",
       "F20    0\n",
       "F21    0\n",
       "F22    0\n",
       "F23    0\n",
       "F24    0\n",
       "F25    0\n",
       "F26    0\n",
       "F27    0\n",
       "F28    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
