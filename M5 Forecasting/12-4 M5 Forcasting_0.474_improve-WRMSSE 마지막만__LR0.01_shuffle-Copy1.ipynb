{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('m5-forecasting-accuracy/sales_train_validation.csv')\n",
    "calendar = pd.read_csv('m5-forecasting-accuracy/calendar.csv')\n",
    "price = pd.read_csv('m5-forecasting-accuracy/sell_prices.csv')\n",
    "# df_test = pd.read_csv('m5-forecasting-accuracy/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "class WRMSSEEvaluator(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame, tst):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "#         train_id = train_id\n",
    "        train_df['all_id'] = 0  # for lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "        self.tst = tst\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'state_id',\n",
    "            'store_id',\n",
    "            'cat_id',\n",
    "            'dept_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            'item_id',\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value']\n",
    "        weight_df = weight_df.loc[zip(self.train_df.item_id, self.train_df.store_id), :].reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        scale = np.where(scale != 0 , scale, 1)\n",
    "        return (score / scale).map(np.sqrt)\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n",
    "\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n",
    "            all_scores.append(lv_scores.sum())\n",
    "\n",
    "        return np.mean(all_scores)\n",
    "    \n",
    "    \n",
    "class WRMSSEForLightGBM(WRMSSEEvaluator):\n",
    "\n",
    "    def feval(self, preds, dtrain):\n",
    "#         print(preds.shape, self.tst.shape)\n",
    "#         tst= self.df[self.df['day'].isin(valid_target_columns)]\n",
    "#         tst['id'] = train_id.loc[tst.index]\n",
    "        tmp = self.tst.copy()\n",
    "        tmp['preds'] = preds\n",
    "        tmp=  tmp.set_index(['id',\"day\"]).unstack()[\"preds\"].reset_index()\n",
    "        tmp =  tmp.fillna(0)\n",
    "\n",
    "        val = pd.DataFrame()\n",
    "        val['id'] = self.train_df['id']\n",
    "        pred = pd.merge(val, tmp, how = 'left')\n",
    "        pred = pred.fillna(0)\n",
    "#         print(pred.columns)\n",
    "#         print(self.valid_target_columns)\n",
    "        pred = pred.loc[:,self.valid_target_columns ]\n",
    "#         cv_scores.append(evaluator.score(pred))\n",
    "#         preds = preds.reshape(self.valid_df[self.valid_target_columns].shape)\n",
    "        score = self.score(pred)\n",
    "        return 'WRMSSE', score, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst = pd.read_csv('m5-forecasting-accuracy/sales_train_validation.csv')\n",
    "# np.where(tst.iloc[0,6:].values>0)[0].max()\n",
    "# tst.iloc[0,6:].values>0\n",
    "# tst[tst['id']=='HOBBIES_1_210_CA_1_validation']\n",
    "# for i, val in last_dict.items():\n",
    "#     if val<1750 : print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e64356ea7214ce683e951632aaf25c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30490.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # startpoints 찾아서 이전 데이터 지우기 + last sales를 찾기\n",
    "startpoints = np.zeros(df_train.shape[0])\n",
    "# lastpoints = np.zeros(df_train.shape[0])\n",
    "for idx in tqdm(range(df_train.shape[0])):\n",
    "    startpoints[idx]= np.where(df_train.iloc[idx,6:].values>0)[0].min().astype(int)\n",
    "#     lastpoints[idx]= np.where(df_train.iloc[idx,6:].values>0)[0].max().astype(int)\n",
    "start_dict = dict(zip(df_train['id'], startpoints))\n",
    "# last_dict = dict(zip(df_train['id'], lastpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = []\n",
    "cat_cols = []\n",
    "drop_cols += ['date','d','id']\n",
    "tr_last = 1913\n",
    "# F_1~28 만들기  1914~1941 까지 \n",
    "for i in range(tr_last+1, tr_last+1+28):   df_train['d_%s'%i] = 0\n",
    "\n",
    "# # Unpivot\n",
    "df_train = pd.melt(df_train, id_vars=df_train.columns[:6], value_vars=df_train.columns[6:],\n",
    "       var_name = 'day', value_name = 'volume')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, calendar, left_on = 'day', right_on ='d')\n",
    "# snap 합치기\n",
    "snap = np.zeros(df_train.shape[0])\n",
    "snap[df_train[(df_train['state_id']=='CA')&(df_train['snap_CA']==1)].index] +=1\n",
    "snap[df_train[(df_train['state_id']=='TX')&(df_train['snap_TX']==1)].index] +=1\n",
    "snap[df_train[(df_train['state_id']=='WI')&(df_train['snap_WI']==1)].index] +=1\n",
    "df_train['snap'] = snap\n",
    "drop_cols += ['snap_CA','snap_TX','snap_WI']\n",
    "\n",
    "\n",
    "cat_cols += [ 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n",
    "#               'wday', 'month', 'year', # 이게 크리티컬?\n",
    "            'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap']\n",
    "\n",
    "\n",
    "# ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     46816555\n",
      "False       65122\n",
      "Name: startpoints, dtype: int64\n",
      "(46816555, 26)\n"
     ]
    }
   ],
   "source": [
    "# Sell price\n",
    "df_train.head()\n",
    "df_train = pd.merge(df_train, price)\n",
    "\n",
    "# # Start point 찾기 ::  0.1% 데이터를 날릴  수 있다. \n",
    "\n",
    "df_train['startpoint'] = df_train['id'].map(start_dict).astype(int)#.astype(str)\n",
    "df_train['startpoints'] = df_train['day'].str.slice(start=2).astype(int) >=df_train['startpoint']\n",
    "print(df_train['startpoints'].value_counts())\n",
    "df_train = df_train[df_train['startpoints']]\n",
    "print(df_train.shape)\n",
    "df_train.drop(['startpoint','startpoints'],axis =1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['lastpoint'] = df_train['id'].map(last_dict).astype(int)#.astype(str)\n",
    "#df_train['from_lastpoint'] = df_train['day'].str.slice(start=2).astype(int) - df_train['lastpoint']\n",
    "\n",
    "#df_train.drop(['lastpoint'],axis =1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>snap</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_2</td>\n",
       "      <td>15</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>d_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>d_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>d_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  day  volume        date  wm_yr_wk  ...    d  event_name_1  \\\n",
       "0       CA  d_1      12  2011-01-29     11101  ...  d_1           NaN   \n",
       "1       CA  d_2      15  2011-01-30     11101  ...  d_2           NaN   \n",
       "2       CA  d_3       0  2011-01-31     11101  ...  d_3           NaN   \n",
       "3       CA  d_4       0  2011-02-01     11101  ...  d_4           NaN   \n",
       "4       CA  d_5       0  2011-02-02     11101  ...  d_5           NaN   \n",
       "\n",
       "   event_type_1  event_name_2 event_type_2 snap_CA snap_TX snap_WI snap  \\\n",
       "0           NaN           NaN          NaN       0       0       0  0.0   \n",
       "1           NaN           NaN          NaN       0       0       0  0.0   \n",
       "2           NaN           NaN          NaN       0       0       0  0.0   \n",
       "3           NaN           NaN          NaN       1       1       0  1.0   \n",
       "4           NaN           NaN          NaN       1       0       1  1.0   \n",
       "\n",
       "   sell_price  \n",
       "0        0.46  \n",
       "1        0.46  \n",
       "2        0.46  \n",
       "3        0.46  \n",
       "4        0.46  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>snap</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_2</td>\n",
       "      <td>15</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>d_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>d_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>d_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46881672</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46881673</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1940</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>d_1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46881674</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46881675</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1940</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-21</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>d_1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46881676</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46816555 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        item_id    dept_id   cat_id  \\\n",
       "0         HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n",
       "1         HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n",
       "2         HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n",
       "3         HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n",
       "4         HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n",
       "...                                 ...            ...        ...      ...   \n",
       "46881672    FOODS_3_825_WI_3_validation    FOODS_3_825    FOODS_3    FOODS   \n",
       "46881673    FOODS_3_826_WI_3_validation    FOODS_3_826    FOODS_3    FOODS   \n",
       "46881674    FOODS_3_826_WI_3_validation    FOODS_3_826    FOODS_3    FOODS   \n",
       "46881675    FOODS_3_827_WI_3_validation    FOODS_3_827    FOODS_3    FOODS   \n",
       "46881676    FOODS_3_827_WI_3_validation    FOODS_3_827    FOODS_3    FOODS   \n",
       "\n",
       "         store_id state_id     day  volume        date  wm_yr_wk  ...       d  \\\n",
       "0            CA_1       CA     d_1      12  2011-01-29     11101  ...     d_1   \n",
       "1            CA_1       CA     d_2      15  2011-01-30     11101  ...     d_2   \n",
       "2            CA_1       CA     d_3       0  2011-01-31     11101  ...     d_3   \n",
       "3            CA_1       CA     d_4       0  2011-02-01     11101  ...     d_4   \n",
       "4            CA_1       CA     d_5       0  2011-02-02     11101  ...     d_5   \n",
       "...           ...      ...     ...     ...         ...       ...  ...     ...   \n",
       "46881672     WI_3       WI  d_1941       0  2016-05-22     11617  ...  d_1941   \n",
       "46881673     WI_3       WI  d_1940       0  2016-05-21     11617  ...  d_1940   \n",
       "46881674     WI_3       WI  d_1941       0  2016-05-22     11617  ...  d_1941   \n",
       "46881675     WI_3       WI  d_1940       0  2016-05-21     11617  ...  d_1940   \n",
       "46881676     WI_3       WI  d_1941       0  2016-05-22     11617  ...  d_1941   \n",
       "\n",
       "          event_name_1  event_type_1  event_name_2 event_type_2 snap_CA  \\\n",
       "0                  NaN           NaN           NaN          NaN       0   \n",
       "1                  NaN           NaN           NaN          NaN       0   \n",
       "2                  NaN           NaN           NaN          NaN       0   \n",
       "3                  NaN           NaN           NaN          NaN       1   \n",
       "4                  NaN           NaN           NaN          NaN       1   \n",
       "...                ...           ...           ...          ...     ...   \n",
       "46881672           NaN           NaN           NaN          NaN       0   \n",
       "46881673           NaN           NaN           NaN          NaN       0   \n",
       "46881674           NaN           NaN           NaN          NaN       0   \n",
       "46881675           NaN           NaN           NaN          NaN       0   \n",
       "46881676           NaN           NaN           NaN          NaN       0   \n",
       "\n",
       "         snap_TX snap_WI snap  sell_price  \n",
       "0              0       0  0.0        0.46  \n",
       "1              0       0  0.0        0.46  \n",
       "2              0       0  0.0        0.46  \n",
       "3              1       0  1.0        0.46  \n",
       "4              0       1  1.0        0.46  \n",
       "...          ...     ...  ...         ...  \n",
       "46881672       0       0  0.0        3.98  \n",
       "46881673       0       0  0.0        1.28  \n",
       "46881674       0       0  0.0        1.28  \n",
       "46881675       0       0  0.0        1.00  \n",
       "46881676       0       0  0.0        1.00  \n",
       "\n",
       "[46816555 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['rcount_7_7'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).count() if x>0).fllna(0)\n",
    "# df_train[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(7).count() if x>0 else 0 )#.fllna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 왜 Shift를 해야할까?\n",
    "# Shift 28을 하지 않으면 예측값이 뒤로 가면갈 수록  F1->F28 예측 할 수 있는 변수가 줄어든게 된다.\n",
    "# 28일은 한달을 의미한다. 최근 한달간의 경향성을 보는 것으로 보면 되겠다.\n",
    "# 28일을 56일로 늘리면 안되나? - 최근 한달간의 경향성이 반영이 안되는 것이낙?\n",
    "# https://www.kaggle.com/kneroma/m5-first-public-notebook-under-0-50\n",
    "\n",
    "#df_train['volume_1'] = df_train[['id','volume']].groupby(\"id\")['volume'].shift(1)\n",
    "#df_train['volume_2'] = df_train[['id','volume']].groupby(\"id\")['volume'].shift(2)\n",
    "#df_train['volume_3'] = df_train[['id','volume']].groupby(\"id\")['volume'].shift(3)\n",
    "\n",
    "df_train['volume_7'] = df_train[['id','volume']].groupby(\"id\")['volume'].shift(7)\n",
    "df_train['volume_28'] = df_train[['id','volume']].groupby(\"id\")['volume'].shift(28)\n",
    "\n",
    "print(\"mean\")\n",
    "\n",
    "df_train['rmean_7_7'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).mean())\n",
    "df_train['rmean_7_28'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).mean())\n",
    "df_train['rmean_7_50'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).mean())\n",
    "\n",
    "df_train['rmean_28_7'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).mean())\n",
    "df_train['rmean_28_28'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).mean())\n",
    "df_train['rmean_28_50'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).mean())\n",
    "\n",
    "# print(\"std\")\n",
    "# df_train['rstd_7_7'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).std())\n",
    "# df_train['rstd_7_28'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).std())\n",
    "# df_train['rstd_7_50'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).std())\n",
    "\n",
    "# df_train['rstd_28_7'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).std())\n",
    "# df_train['rstd_28_28'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).std())\n",
    "# df_train['rstd_28_50'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).std())\n",
    "\n",
    "# print(\"max\")\n",
    "# df_train['rmax_7_7'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).max())\n",
    "# df_train['rmax_7_28'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).max())\n",
    "# df_train['rmax_7_50'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).max())\n",
    "\n",
    "# df_train['rmax_28_7'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).max())\n",
    "# df_train['rmax_28_28'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).max())\n",
    "# df_train['rmax_28_50'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).max())\n",
    "\n",
    "# print(\"min\")\n",
    "# df_train['rmin_7_7'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).min())\n",
    "# df_train['rmin_7_28'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).min())\n",
    "# df_train['rmin_7_50'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).min())\n",
    "\n",
    "# df_train['rmin_28_7'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).min())\n",
    "# df_train['rmin_28_28'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).min())\n",
    "# df_train['rmin_28_50'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).min())\n",
    "\n",
    "# print(\"count\")\n",
    "# df_train['rcount_7_7'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).count() if x>0).fllna(0)\n",
    "# df_train['rcount_7_28'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).count() if x>0).fllna(0)\n",
    "# df_train['rcount_7_50'] = df_train[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).count() if x>0).fllna(0)\n",
    "\n",
    "# df_train['rcount_28_7'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).count() if x>0 else 0).fllna(0)\n",
    "# df_train['rcount_28_28'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).count() if x>0 else 0).fllna(0)\n",
    "# df_train['rcount_28_50'] = df_train[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).count() if x>0 else 0).fllna(0)\n",
    "\n",
    "# full_df['rcnt_7'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(7).count() if x>0).fllna(0)\n",
    "# full_df['rcnt_28'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(28).count() if x>0).fllna(0)\n",
    "# full_df['rcnt_50'] = full_df[['id','volume']].groupby(\"id\")['volume'].transform(lambda x: x.rolling(28).count() if x>0).fllna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['date'] =  pd.to_datetime(df_train[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['week'] = getattr(df_train[\"date\"].dt, \"weekofyear\").astype(\"int16\")\n",
    "# df_train['quarter'] = getattr(df_train[\"date\"].dt,\"quarter\").astype(\"int16\")\n",
    "df_train['mday'] = getattr(df_train[\"date\"].dt, \"day\").astype(\"int16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46816555, 34)\n"
     ]
    }
   ],
   "source": [
    "cols =['event_name_1','event_type_1','event_name_2','event_type_2']\n",
    "df_train[cols]= df_train[cols].fillna('NaN')\n",
    "print(df_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46816555, 34)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[~df_train['rmean_28_50'].isna()]\n",
    "# dropna 하면 뻥난다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 0\n",
      "item_id 0\n",
      "dept_id 0\n",
      "cat_id 0\n",
      "store_id 0\n",
      "state_id 0\n",
      "day 0\n",
      "volume 0\n",
      "date 0\n",
      "wm_yr_wk 0\n",
      "weekday 0\n",
      "wday 0\n",
      "month 0\n",
      "year 0\n",
      "d 0\n",
      "event_name_1 0\n",
      "event_type_1 0\n",
      "event_name_2 0\n",
      "event_type_2 0\n",
      "snap_CA 0\n",
      "snap_TX 0\n",
      "snap_WI 0\n",
      "snap 0\n",
      "sell_price 0\n",
      "volume_7 0\n",
      "volume_28 0\n",
      "rmean_7_7 0\n",
      "rmean_7_28 0\n",
      "rmean_7_50 0\n",
      "rmean_28_7 0\n",
      "rmean_28_28 0\n",
      "rmean_28_50 0\n",
      "week 0\n",
      "mday 0\n"
     ]
    }
   ],
   "source": [
    "for col in df_train.columns:\n",
    "    print(col, df_train[col].isnull().sum())\n",
    "# df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.dropna()#inplace =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44468825, 34)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date', 'd', 'id', 'snap_CA', 'snap_TX', 'snap_WI', 'wm_yr_wk', 'weekday']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"wm_yr_wk\", \"weekday\"]  ## 이게 문제?\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()\n",
    "tr_last = 1913\n",
    "testday = ['d_%s'% x for x in range(tr_last+1, tr_last+1+28)]\n",
    "train_id = df_train['id']\n",
    "df_test_id = df_train[df_train['day'].isin(testday)]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= df_train.drop(drop_cols,axis =1 )\n",
    "# df_test =df_test.drop(drop_cols,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_7</th>\n",
       "      <th>volume_28</th>\n",
       "      <th>rmean_7_7</th>\n",
       "      <th>rmean_7_28</th>\n",
       "      <th>rmean_7_50</th>\n",
       "      <th>rmean_28_7</th>\n",
       "      <th>rmean_28_28</th>\n",
       "      <th>rmean_28_50</th>\n",
       "      <th>week</th>\n",
       "      <th>mday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010975</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.90</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010976</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.66</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010977</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010978</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_81</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010979</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_82</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id    dept_id   cat_id store_id state_id   day  volume  \\\n",
       "1010975  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA  d_78       0   \n",
       "1010976  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA  d_79       0   \n",
       "1010977  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA  d_80       0   \n",
       "1010978  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA  d_81       5   \n",
       "1010979  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA  d_82      23   \n",
       "\n",
       "         wday  month  year  ... volume_7 volume_28 rmean_7_7 rmean_7_28  \\\n",
       "1010975     1      4  2011  ...      0.0       0.0  6.857143   1.785714   \n",
       "1010976     2      4  2011  ...      0.0       0.0  4.000000   1.714286   \n",
       "1010977     3      4  2011  ...      8.0       0.0  5.142857   2.000000   \n",
       "1010978     4      4  2011  ...      6.0       0.0  5.714286   2.214286   \n",
       "1010979     5      4  2011  ...      6.0       0.0  4.714286   2.428571   \n",
       "\n",
       "         rmean_7_50  rmean_28_7  rmean_28_28  rmean_28_50  week  mday  \n",
       "1010975        1.88    0.285714     1.285714         2.90    15    16  \n",
       "1010976        1.68    0.000000     1.142857         2.66    15    17  \n",
       "1010977        1.76    0.000000     1.000000         2.36    16    18  \n",
       "1010978        1.80    0.000000     0.928571         2.36    16    19  \n",
       "1010979        1.88    0.000000     0.714286         2.36    16    20  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dbb41bc4d44947b4588ac2bf84d850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Encoding\n",
    "for col in tqdm(cat_cols) :  # encoding -1이 문제?\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col]).astype(np.int8)\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 분리하기\n",
    "testday = ['d_%s'% x for x in range(tr_last+1, tr_last+1+28)]\n",
    "df_test = df_train.copy()\n",
    "df_train = df_train[~df_train['day'].isin(testday)]\n",
    "# train_col = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'day', 'volume', 'wday', 'month', 'year',\n",
    "#  'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap', 'sell_price', 'volume_7', 'volume_28',\n",
    "#  'rmean_7_7', 'rmean_7_28', 'rmean_7_50', 'rmean_28_7', 'rmean_28_28', 'rmean_28_50', 'week', 'quarter', 'mday']\n",
    "# df_train = df_train.loc[:,train_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_7</th>\n",
       "      <th>volume_28</th>\n",
       "      <th>rmean_7_7</th>\n",
       "      <th>rmean_7_28</th>\n",
       "      <th>rmean_7_50</th>\n",
       "      <th>rmean_28_7</th>\n",
       "      <th>rmean_28_28</th>\n",
       "      <th>rmean_28_50</th>\n",
       "      <th>week</th>\n",
       "      <th>mday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010975</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.90</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010976</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.66</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010977</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010978</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_81</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010979</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_82</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  dept_id  cat_id  store_id  state_id   day  volume  wday  \\\n",
       "1010975      -92        3       1         0         0  d_78       0     1   \n",
       "1010976      -92        3       1         0         0  d_79       0     2   \n",
       "1010977      -92        3       1         0         0  d_80       0     3   \n",
       "1010978      -92        3       1         0         0  d_81       5     4   \n",
       "1010979      -92        3       1         0         0  d_82      23     5   \n",
       "\n",
       "         month  year  ...  volume_7  volume_28  rmean_7_7  rmean_7_28  \\\n",
       "1010975      4  2011  ...       0.0        0.0   6.857143    1.785714   \n",
       "1010976      4  2011  ...       0.0        0.0   4.000000    1.714286   \n",
       "1010977      4  2011  ...       8.0        0.0   5.142857    2.000000   \n",
       "1010978      4  2011  ...       6.0        0.0   5.714286    2.214286   \n",
       "1010979      4  2011  ...       6.0        0.0   4.714286    2.428571   \n",
       "\n",
       "         rmean_7_50  rmean_28_7  rmean_28_28  rmean_28_50  week  mday  \n",
       "1010975        1.88    0.285714     1.285714         2.90    15    16  \n",
       "1010976        1.68    0.000000     1.142857         2.66    15    17  \n",
       "1010977        1.76    0.000000     1.000000         2.36    16    18  \n",
       "1010978        1.80    0.000000     0.928571         2.36    16    19  \n",
       "1010979        1.88    0.000000     0.714286         2.36    16    20  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x_train , x_valid = train_test_split(df_train, test_size =0.15, random_state = 99)\n",
    "# y_train, y_valid = x_train['volume'], x_valid['volume']\n",
    "\n",
    "# x_train = x_train.drop(['day','volume'], axis =1)\n",
    "# x_valid = x_valid.drop(['day','volume'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_7</th>\n",
       "      <th>volume_28</th>\n",
       "      <th>rmean_7_7</th>\n",
       "      <th>rmean_7_28</th>\n",
       "      <th>rmean_7_50</th>\n",
       "      <th>rmean_28_7</th>\n",
       "      <th>rmean_28_28</th>\n",
       "      <th>rmean_28_50</th>\n",
       "      <th>week</th>\n",
       "      <th>mday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010975</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.90</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010976</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.66</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010977</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010978</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_81</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010979</th>\n",
       "      <td>-92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_82</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  dept_id  cat_id  store_id  state_id   day  volume  wday  \\\n",
       "1010975      -92        3       1         0         0  d_78       0     1   \n",
       "1010976      -92        3       1         0         0  d_79       0     2   \n",
       "1010977      -92        3       1         0         0  d_80       0     3   \n",
       "1010978      -92        3       1         0         0  d_81       5     4   \n",
       "1010979      -92        3       1         0         0  d_82      23     5   \n",
       "\n",
       "         month  year  ...  volume_7  volume_28  rmean_7_7  rmean_7_28  \\\n",
       "1010975      4  2011  ...       0.0        0.0   6.857143    1.785714   \n",
       "1010976      4  2011  ...       0.0        0.0   4.000000    1.714286   \n",
       "1010977      4  2011  ...       8.0        0.0   5.142857    2.000000   \n",
       "1010978      4  2011  ...       6.0        0.0   5.714286    2.214286   \n",
       "1010979      4  2011  ...       6.0        0.0   4.714286    2.428571   \n",
       "\n",
       "         rmean_7_50  rmean_28_7  rmean_28_28  rmean_28_50  week  mday  \n",
       "1010975        1.88    0.285714     1.285714         2.90    15    16  \n",
       "1010976        1.68    0.000000     1.142857         2.66    15    17  \n",
       "1010977        1.76    0.000000     1.000000         2.36    16    18  \n",
       "1010978        1.80    0.000000     0.928571         2.36    16    19  \n",
       "1010979        1.88    0.000000     0.714286         2.36    16    20  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train=df_train[df_train['day'].isin(list(df_train.day.unique())[450:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#         \"objective\" : \"poisson\",\n",
    "#         \"metric\" :\"rmse\",\n",
    "#         \"force_row_wise\" : True,\n",
    "#         \"learning_rate\" : 0.075,\n",
    "# #         \"sub_feature\" : 0.8,\n",
    "#         \"sub_row\" : 0.75,\n",
    "#         \"bagging_freq\" : 1,\n",
    "#         \"lambda_l2\" : 0.1,\n",
    "# #         \"nthread\" : 4\n",
    "#         \"metric\": [\"rmse\"],\n",
    "#     'verbosity': 1,\n",
    "#     'num_iterations' : 3000,\n",
    "#     'num_leaves': 128,\n",
    "#     \"min_data_in_leaf\": 100,\n",
    "#         'n_jobs' :10 \n",
    "# }\n",
    "\n",
    "\n",
    "params = {\n",
    "        \"objective\" : \"poisson\",\n",
    "#         \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.01,#0.075,\n",
    "#         \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.75,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "#         \"nthread\" : 4\n",
    "        \"metric\":[\"rmse\"],#\"None\",#\n",
    "    'verbosity': 1,\n",
    "    'num_iterations' : 10000,\n",
    "    'num_leaves': 128,\n",
    "    \"min_data_in_leaf\": 100,\n",
    "        'n_jobs' :10 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set train, valid\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.31567\tvalid_1's rmse: 3.27543\n",
      "[200]\ttraining's rmse: 2.83881\tvalid_1's rmse: 2.80859\n",
      "[300]\ttraining's rmse: 2.6305\tvalid_1's rmse: 2.60695\n",
      "[400]\ttraining's rmse: 2.54218\tvalid_1's rmse: 2.52311\n",
      "[500]\ttraining's rmse: 2.50269\tvalid_1's rmse: 2.48716\n",
      "[600]\ttraining's rmse: 2.48277\tvalid_1's rmse: 2.47014\n",
      "[700]\ttraining's rmse: 2.47083\tvalid_1's rmse: 2.46085\n",
      "[800]\ttraining's rmse: 2.46191\tvalid_1's rmse: 2.45499\n",
      "[900]\ttraining's rmse: 2.45492\tvalid_1's rmse: 2.45067\n",
      "[1000]\ttraining's rmse: 2.44946\tvalid_1's rmse: 2.44759\n",
      "[1100]\ttraining's rmse: 2.44462\tvalid_1's rmse: 2.44504\n",
      "[1200]\ttraining's rmse: 2.43958\tvalid_1's rmse: 2.44225\n",
      "[1300]\ttraining's rmse: 2.43479\tvalid_1's rmse: 2.43969\n",
      "[1400]\ttraining's rmse: 2.43005\tvalid_1's rmse: 2.43747\n",
      "[1500]\ttraining's rmse: 2.42564\tvalid_1's rmse: 2.43542\n",
      "[1600]\ttraining's rmse: 2.42167\tvalid_1's rmse: 2.43366\n",
      "[1700]\ttraining's rmse: 2.41788\tvalid_1's rmse: 2.43192\n",
      "[1800]\ttraining's rmse: 2.41458\tvalid_1's rmse: 2.43024\n",
      "[1900]\ttraining's rmse: 2.41097\tvalid_1's rmse: 2.4286\n",
      "[2000]\ttraining's rmse: 2.40766\tvalid_1's rmse: 2.42708\n",
      "[2100]\ttraining's rmse: 2.40467\tvalid_1's rmse: 2.42582\n",
      "[2200]\ttraining's rmse: 2.40165\tvalid_1's rmse: 2.42444\n",
      "[2300]\ttraining's rmse: 2.39852\tvalid_1's rmse: 2.42306\n",
      "[2400]\ttraining's rmse: 2.39546\tvalid_1's rmse: 2.42178\n",
      "[2500]\ttraining's rmse: 2.39249\tvalid_1's rmse: 2.42049\n",
      "[2600]\ttraining's rmse: 2.38936\tvalid_1's rmse: 2.41919\n",
      "[2700]\ttraining's rmse: 2.38637\tvalid_1's rmse: 2.41798\n",
      "[2800]\ttraining's rmse: 2.38334\tvalid_1's rmse: 2.41671\n",
      "[2900]\ttraining's rmse: 2.38064\tvalid_1's rmse: 2.41559\n",
      "[3000]\ttraining's rmse: 2.37765\tvalid_1's rmse: 2.41442\n",
      "[3100]\ttraining's rmse: 2.37495\tvalid_1's rmse: 2.41342\n",
      "[3200]\ttraining's rmse: 2.37254\tvalid_1's rmse: 2.41253\n",
      "[3300]\ttraining's rmse: 2.37\tvalid_1's rmse: 2.41156\n",
      "[3400]\ttraining's rmse: 2.36768\tvalid_1's rmse: 2.41067\n",
      "[3500]\ttraining's rmse: 2.36501\tvalid_1's rmse: 2.40976\n",
      "[3600]\ttraining's rmse: 2.36298\tvalid_1's rmse: 2.40907\n",
      "[3700]\ttraining's rmse: 2.36066\tvalid_1's rmse: 2.40821\n",
      "[3800]\ttraining's rmse: 2.35856\tvalid_1's rmse: 2.40752\n",
      "[3900]\ttraining's rmse: 2.35626\tvalid_1's rmse: 2.40668\n",
      "[4000]\ttraining's rmse: 2.35412\tvalid_1's rmse: 2.40596\n",
      "[4100]\ttraining's rmse: 2.35206\tvalid_1's rmse: 2.40521\n",
      "[4200]\ttraining's rmse: 2.35024\tvalid_1's rmse: 2.40461\n",
      "[4300]\ttraining's rmse: 2.34843\tvalid_1's rmse: 2.40396\n",
      "[4400]\ttraining's rmse: 2.34648\tvalid_1's rmse: 2.40338\n",
      "[4500]\ttraining's rmse: 2.34465\tvalid_1's rmse: 2.40285\n",
      "[4600]\ttraining's rmse: 2.34285\tvalid_1's rmse: 2.40224\n",
      "[4700]\ttraining's rmse: 2.34109\tvalid_1's rmse: 2.40167\n",
      "[4800]\ttraining's rmse: 2.33938\tvalid_1's rmse: 2.40114\n",
      "[4900]\ttraining's rmse: 2.33783\tvalid_1's rmse: 2.40063\n",
      "[5000]\ttraining's rmse: 2.33596\tvalid_1's rmse: 2.40004\n",
      "[5100]\ttraining's rmse: 2.3344\tvalid_1's rmse: 2.39955\n",
      "[5200]\ttraining's rmse: 2.33286\tvalid_1's rmse: 2.39909\n",
      "[5300]\ttraining's rmse: 2.33151\tvalid_1's rmse: 2.39872\n",
      "[5400]\ttraining's rmse: 2.32994\tvalid_1's rmse: 2.39828\n",
      "[5500]\ttraining's rmse: 2.32849\tvalid_1's rmse: 2.39783\n",
      "[5600]\ttraining's rmse: 2.32689\tvalid_1's rmse: 2.39737\n",
      "[5700]\ttraining's rmse: 2.3255\tvalid_1's rmse: 2.39699\n",
      "[5800]\ttraining's rmse: 2.324\tvalid_1's rmse: 2.39653\n",
      "[5900]\ttraining's rmse: 2.32275\tvalid_1's rmse: 2.39618\n",
      "[6000]\ttraining's rmse: 2.32134\tvalid_1's rmse: 2.39579\n",
      "[6100]\ttraining's rmse: 2.32004\tvalid_1's rmse: 2.39544\n",
      "[6200]\ttraining's rmse: 2.31855\tvalid_1's rmse: 2.39508\n",
      "[6300]\ttraining's rmse: 2.31725\tvalid_1's rmse: 2.39476\n",
      "[6400]\ttraining's rmse: 2.31585\tvalid_1's rmse: 2.39437\n",
      "[6500]\ttraining's rmse: 2.31463\tvalid_1's rmse: 2.39402\n",
      "[6600]\ttraining's rmse: 2.3133\tvalid_1's rmse: 2.39367\n",
      "[6700]\ttraining's rmse: 2.31199\tvalid_1's rmse: 2.39331\n",
      "[6800]\ttraining's rmse: 2.3108\tvalid_1's rmse: 2.39294\n",
      "[6900]\ttraining's rmse: 2.30961\tvalid_1's rmse: 2.39267\n",
      "[7000]\ttraining's rmse: 2.30846\tvalid_1's rmse: 2.39236\n",
      "[7100]\ttraining's rmse: 2.30737\tvalid_1's rmse: 2.39209\n",
      "[7200]\ttraining's rmse: 2.3062\tvalid_1's rmse: 2.39179\n",
      "[7300]\ttraining's rmse: 2.30518\tvalid_1's rmse: 2.39153\n",
      "[7400]\ttraining's rmse: 2.30403\tvalid_1's rmse: 2.39125\n",
      "[7500]\ttraining's rmse: 2.30291\tvalid_1's rmse: 2.39094\n",
      "[7600]\ttraining's rmse: 2.30191\tvalid_1's rmse: 2.39069\n",
      "[7700]\ttraining's rmse: 2.30071\tvalid_1's rmse: 2.39042\n",
      "[7800]\ttraining's rmse: 2.29963\tvalid_1's rmse: 2.39014\n",
      "[7900]\ttraining's rmse: 2.29852\tvalid_1's rmse: 2.38993\n",
      "[8000]\ttraining's rmse: 2.29742\tvalid_1's rmse: 2.38964\n",
      "[8100]\ttraining's rmse: 2.29643\tvalid_1's rmse: 2.3894\n",
      "[8200]\ttraining's rmse: 2.2954\tvalid_1's rmse: 2.38914\n",
      "[8300]\ttraining's rmse: 2.29431\tvalid_1's rmse: 2.38888\n",
      "[8400]\ttraining's rmse: 2.2934\tvalid_1's rmse: 2.38864\n",
      "[8500]\ttraining's rmse: 2.29241\tvalid_1's rmse: 2.38837\n",
      "[8600]\ttraining's rmse: 2.29135\tvalid_1's rmse: 2.3881\n",
      "[8700]\ttraining's rmse: 2.29038\tvalid_1's rmse: 2.38783\n",
      "[8800]\ttraining's rmse: 2.28935\tvalid_1's rmse: 2.38761\n",
      "[8900]\ttraining's rmse: 2.2883\tvalid_1's rmse: 2.38741\n",
      "[9000]\ttraining's rmse: 2.28734\tvalid_1's rmse: 2.38724\n",
      "[9100]\ttraining's rmse: 2.2865\tvalid_1's rmse: 2.38706\n",
      "[9200]\ttraining's rmse: 2.28555\tvalid_1's rmse: 2.38681\n",
      "[9300]\ttraining's rmse: 2.28458\tvalid_1's rmse: 2.38659\n",
      "[9400]\ttraining's rmse: 2.28363\tvalid_1's rmse: 2.38639\n",
      "[9500]\ttraining's rmse: 2.2828\tvalid_1's rmse: 2.3862\n",
      "[9600]\ttraining's rmse: 2.28197\tvalid_1's rmse: 2.38598\n",
      "[9700]\ttraining's rmse: 2.28098\tvalid_1's rmse: 2.38578\n",
      "[9800]\ttraining's rmse: 2.28009\tvalid_1's rmse: 2.38556\n",
      "[9900]\ttraining's rmse: 2.27929\tvalid_1's rmse: 2.38536\n",
      "[10000]\ttraining's rmse: 2.27839\tvalid_1's rmse: 2.38514\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's rmse: 2.27839\tvalid_1's rmse: 2.38514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d2a460d8134d0a9d68a222e20adf50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx WRMSSE : 0.32302039937081645\n",
      "1\n",
      "set train, valid\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.30086\tvalid_1's rmse: 3.30308\n",
      "[200]\ttraining's rmse: 2.82564\tvalid_1's rmse: 2.83814\n",
      "[300]\ttraining's rmse: 2.61812\tvalid_1's rmse: 2.63926\n",
      "[400]\ttraining's rmse: 2.53021\tvalid_1's rmse: 2.55723\n",
      "[500]\ttraining's rmse: 2.49158\tvalid_1's rmse: 2.52243\n",
      "[600]\ttraining's rmse: 2.47185\tvalid_1's rmse: 2.50582\n",
      "[700]\ttraining's rmse: 2.46017\tvalid_1's rmse: 2.49666\n",
      "[800]\ttraining's rmse: 2.45223\tvalid_1's rmse: 2.49066\n",
      "[900]\ttraining's rmse: 2.4463\tvalid_1's rmse: 2.48647\n",
      "[1000]\ttraining's rmse: 2.44107\tvalid_1's rmse: 2.48295\n",
      "[1100]\ttraining's rmse: 2.43677\tvalid_1's rmse: 2.48029\n",
      "[1200]\ttraining's rmse: 2.43227\tvalid_1's rmse: 2.47752\n",
      "[1300]\ttraining's rmse: 2.42791\tvalid_1's rmse: 2.47506\n",
      "[1400]\ttraining's rmse: 2.42374\tvalid_1's rmse: 2.4728\n",
      "[1500]\ttraining's rmse: 2.41947\tvalid_1's rmse: 2.47041\n",
      "[1600]\ttraining's rmse: 2.4154\tvalid_1's rmse: 2.46831\n",
      "[1700]\ttraining's rmse: 2.41179\tvalid_1's rmse: 2.46651\n",
      "[1800]\ttraining's rmse: 2.40831\tvalid_1's rmse: 2.46475\n",
      "[1900]\ttraining's rmse: 2.40501\tvalid_1's rmse: 2.463\n",
      "[2000]\ttraining's rmse: 2.40198\tvalid_1's rmse: 2.46133\n",
      "[2100]\ttraining's rmse: 2.39892\tvalid_1's rmse: 2.45974\n",
      "[2200]\ttraining's rmse: 2.39648\tvalid_1's rmse: 2.45845\n",
      "[2300]\ttraining's rmse: 2.39388\tvalid_1's rmse: 2.45716\n",
      "[2400]\ttraining's rmse: 2.39074\tvalid_1's rmse: 2.45552\n",
      "[2500]\ttraining's rmse: 2.38768\tvalid_1's rmse: 2.45399\n",
      "[2600]\ttraining's rmse: 2.38477\tvalid_1's rmse: 2.45258\n",
      "[2700]\ttraining's rmse: 2.38186\tvalid_1's rmse: 2.45121\n",
      "[2800]\ttraining's rmse: 2.37925\tvalid_1's rmse: 2.44995\n",
      "[2900]\ttraining's rmse: 2.37687\tvalid_1's rmse: 2.44891\n",
      "[3000]\ttraining's rmse: 2.37419\tvalid_1's rmse: 2.4477\n",
      "[3100]\ttraining's rmse: 2.37155\tvalid_1's rmse: 2.44653\n",
      "[3200]\ttraining's rmse: 2.36937\tvalid_1's rmse: 2.44555\n",
      "[3300]\ttraining's rmse: 2.36706\tvalid_1's rmse: 2.44458\n",
      "[3400]\ttraining's rmse: 2.36465\tvalid_1's rmse: 2.44352\n",
      "[3500]\ttraining's rmse: 2.36257\tvalid_1's rmse: 2.44259\n",
      "[3600]\ttraining's rmse: 2.36051\tvalid_1's rmse: 2.44167\n",
      "[3700]\ttraining's rmse: 2.35848\tvalid_1's rmse: 2.44082\n",
      "[3800]\ttraining's rmse: 2.3563\tvalid_1's rmse: 2.43988\n",
      "[3900]\ttraining's rmse: 2.35442\tvalid_1's rmse: 2.43915\n",
      "[4000]\ttraining's rmse: 2.35266\tvalid_1's rmse: 2.43843\n",
      "[4100]\ttraining's rmse: 2.35084\tvalid_1's rmse: 2.43767\n",
      "[4200]\ttraining's rmse: 2.34903\tvalid_1's rmse: 2.43701\n",
      "[4300]\ttraining's rmse: 2.34729\tvalid_1's rmse: 2.43637\n",
      "[4400]\ttraining's rmse: 2.34545\tvalid_1's rmse: 2.43572\n",
      "[4500]\ttraining's rmse: 2.34368\tvalid_1's rmse: 2.43505\n",
      "[4600]\ttraining's rmse: 2.34212\tvalid_1's rmse: 2.43446\n",
      "[4700]\ttraining's rmse: 2.34052\tvalid_1's rmse: 2.43391\n",
      "[4800]\ttraining's rmse: 2.33864\tvalid_1's rmse: 2.4332\n",
      "[4900]\ttraining's rmse: 2.33703\tvalid_1's rmse: 2.43262\n",
      "[5000]\ttraining's rmse: 2.33537\tvalid_1's rmse: 2.43205\n",
      "[5100]\ttraining's rmse: 2.33397\tvalid_1's rmse: 2.43158\n",
      "[5200]\ttraining's rmse: 2.33257\tvalid_1's rmse: 2.43113\n",
      "[5300]\ttraining's rmse: 2.33103\tvalid_1's rmse: 2.43061\n",
      "[5400]\ttraining's rmse: 2.3297\tvalid_1's rmse: 2.43012\n",
      "[5500]\ttraining's rmse: 2.32831\tvalid_1's rmse: 2.42966\n",
      "[5600]\ttraining's rmse: 2.3269\tvalid_1's rmse: 2.42919\n",
      "[5700]\ttraining's rmse: 2.32545\tvalid_1's rmse: 2.42862\n",
      "[5800]\ttraining's rmse: 2.3241\tvalid_1's rmse: 2.42818\n",
      "[5900]\ttraining's rmse: 2.32276\tvalid_1's rmse: 2.42774\n",
      "[6000]\ttraining's rmse: 2.32144\tvalid_1's rmse: 2.42726\n",
      "[6100]\ttraining's rmse: 2.32018\tvalid_1's rmse: 2.42679\n",
      "[6200]\ttraining's rmse: 2.31898\tvalid_1's rmse: 2.42645\n",
      "[6300]\ttraining's rmse: 2.31782\tvalid_1's rmse: 2.42602\n",
      "[6400]\ttraining's rmse: 2.31654\tvalid_1's rmse: 2.42562\n",
      "[6500]\ttraining's rmse: 2.31522\tvalid_1's rmse: 2.42526\n",
      "[6600]\ttraining's rmse: 2.31393\tvalid_1's rmse: 2.42485\n",
      "[6700]\ttraining's rmse: 2.31284\tvalid_1's rmse: 2.42452\n",
      "[6800]\ttraining's rmse: 2.3116\tvalid_1's rmse: 2.42408\n",
      "[6900]\ttraining's rmse: 2.31033\tvalid_1's rmse: 2.42369\n",
      "[7000]\ttraining's rmse: 2.30915\tvalid_1's rmse: 2.42332\n",
      "[7100]\ttraining's rmse: 2.30809\tvalid_1's rmse: 2.42297\n",
      "[7200]\ttraining's rmse: 2.30694\tvalid_1's rmse: 2.42264\n",
      "[7300]\ttraining's rmse: 2.30589\tvalid_1's rmse: 2.42237\n",
      "[7400]\ttraining's rmse: 2.30481\tvalid_1's rmse: 2.42209\n",
      "[7500]\ttraining's rmse: 2.30357\tvalid_1's rmse: 2.42175\n",
      "[7600]\ttraining's rmse: 2.30247\tvalid_1's rmse: 2.42141\n",
      "[7700]\ttraining's rmse: 2.30133\tvalid_1's rmse: 2.42108\n",
      "[7800]\ttraining's rmse: 2.30016\tvalid_1's rmse: 2.42072\n",
      "[7900]\ttraining's rmse: 2.29913\tvalid_1's rmse: 2.4204\n",
      "[8000]\ttraining's rmse: 2.29811\tvalid_1's rmse: 2.42015\n",
      "[8100]\ttraining's rmse: 2.29714\tvalid_1's rmse: 2.41988\n",
      "[8200]\ttraining's rmse: 2.29612\tvalid_1's rmse: 2.41957\n",
      "[8300]\ttraining's rmse: 2.29516\tvalid_1's rmse: 2.4193\n",
      "[8400]\ttraining's rmse: 2.29408\tvalid_1's rmse: 2.41896\n",
      "[8500]\ttraining's rmse: 2.29317\tvalid_1's rmse: 2.41873\n",
      "[8600]\ttraining's rmse: 2.29215\tvalid_1's rmse: 2.41844\n",
      "[8700]\ttraining's rmse: 2.29123\tvalid_1's rmse: 2.41818\n",
      "[8800]\ttraining's rmse: 2.29029\tvalid_1's rmse: 2.41795\n",
      "[8900]\ttraining's rmse: 2.28931\tvalid_1's rmse: 2.41764\n",
      "[9000]\ttraining's rmse: 2.28834\tvalid_1's rmse: 2.41736\n",
      "[9100]\ttraining's rmse: 2.28741\tvalid_1's rmse: 2.41712\n",
      "[9200]\ttraining's rmse: 2.28657\tvalid_1's rmse: 2.41687\n",
      "[9300]\ttraining's rmse: 2.28565\tvalid_1's rmse: 2.41662\n",
      "[9400]\ttraining's rmse: 2.28464\tvalid_1's rmse: 2.41638\n",
      "[9500]\ttraining's rmse: 2.28381\tvalid_1's rmse: 2.41616\n",
      "[9600]\ttraining's rmse: 2.28295\tvalid_1's rmse: 2.41595\n",
      "[9700]\ttraining's rmse: 2.28213\tvalid_1's rmse: 2.41576\n",
      "[9800]\ttraining's rmse: 2.28118\tvalid_1's rmse: 2.41553\n",
      "[9900]\ttraining's rmse: 2.28021\tvalid_1's rmse: 2.41525\n",
      "[10000]\ttraining's rmse: 2.27946\tvalid_1's rmse: 2.41504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's rmse: 2.27946\tvalid_1's rmse: 2.41504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b98eddbb734d3a82f2ae9c3e12f8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "idx WRMSSE : 0.33497541459684643\n",
      "2\n",
      "set train, valid\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 3.28686\tvalid_1's rmse: 3.34232\n",
      "[200]\ttraining's rmse: 2.81491\tvalid_1's rmse: 2.86974\n",
      "[300]\ttraining's rmse: 2.60865\tvalid_1's rmse: 2.66275\n",
      "[400]\ttraining's rmse: 2.52115\tvalid_1's rmse: 2.57537\n",
      "[500]\ttraining's rmse: 2.48204\tvalid_1's rmse: 2.53713\n",
      "[600]\ttraining's rmse: 2.46192\tvalid_1's rmse: 2.51859\n",
      "[700]\ttraining's rmse: 2.44987\tvalid_1's rmse: 2.5083\n",
      "[800]\ttraining's rmse: 2.44124\tvalid_1's rmse: 2.50146\n",
      "[900]\ttraining's rmse: 2.43468\tvalid_1's rmse: 2.49654\n",
      "[1000]\ttraining's rmse: 2.42907\tvalid_1's rmse: 2.49238\n",
      "[1100]\ttraining's rmse: 2.42416\tvalid_1's rmse: 2.48899\n",
      "[1200]\ttraining's rmse: 2.41975\tvalid_1's rmse: 2.48622\n",
      "[1300]\ttraining's rmse: 2.41506\tvalid_1's rmse: 2.48311\n",
      "[1400]\ttraining's rmse: 2.4114\tvalid_1's rmse: 2.48066\n",
      "[1500]\ttraining's rmse: 2.40773\tvalid_1's rmse: 2.47846\n",
      "[1600]\ttraining's rmse: 2.40407\tvalid_1's rmse: 2.47636\n",
      "[1700]\ttraining's rmse: 2.40057\tvalid_1's rmse: 2.47433\n",
      "[1800]\ttraining's rmse: 2.39723\tvalid_1's rmse: 2.47231\n",
      "[1900]\ttraining's rmse: 2.39413\tvalid_1's rmse: 2.47064\n",
      "[2000]\ttraining's rmse: 2.39121\tvalid_1's rmse: 2.46901\n",
      "[2100]\ttraining's rmse: 2.38827\tvalid_1's rmse: 2.46745\n",
      "[2200]\ttraining's rmse: 2.38541\tvalid_1's rmse: 2.46592\n",
      "[2300]\ttraining's rmse: 2.38277\tvalid_1's rmse: 2.46458\n",
      "[2400]\ttraining's rmse: 2.38\tvalid_1's rmse: 2.46326\n",
      "[2500]\ttraining's rmse: 2.37706\tvalid_1's rmse: 2.46179\n",
      "[2600]\ttraining's rmse: 2.37472\tvalid_1's rmse: 2.46064\n",
      "[2700]\ttraining's rmse: 2.37187\tvalid_1's rmse: 2.45924\n",
      "[2800]\ttraining's rmse: 2.36915\tvalid_1's rmse: 2.458\n",
      "[2900]\ttraining's rmse: 2.36647\tvalid_1's rmse: 2.45673\n",
      "[3000]\ttraining's rmse: 2.36368\tvalid_1's rmse: 2.45547\n",
      "[3100]\ttraining's rmse: 2.36134\tvalid_1's rmse: 2.45449\n",
      "[3200]\ttraining's rmse: 2.35915\tvalid_1's rmse: 2.45359\n",
      "[3300]\ttraining's rmse: 2.35692\tvalid_1's rmse: 2.45259\n",
      "[3400]\ttraining's rmse: 2.35464\tvalid_1's rmse: 2.45165\n",
      "[3500]\ttraining's rmse: 2.35225\tvalid_1's rmse: 2.45064\n",
      "[3600]\ttraining's rmse: 2.3499\tvalid_1's rmse: 2.4497\n",
      "[3700]\ttraining's rmse: 2.34762\tvalid_1's rmse: 2.4488\n",
      "[3800]\ttraining's rmse: 2.34578\tvalid_1's rmse: 2.44805\n",
      "[3900]\ttraining's rmse: 2.34387\tvalid_1's rmse: 2.44722\n",
      "[4000]\ttraining's rmse: 2.34184\tvalid_1's rmse: 2.44637\n",
      "[4100]\ttraining's rmse: 2.33983\tvalid_1's rmse: 2.44563\n",
      "[4200]\ttraining's rmse: 2.33767\tvalid_1's rmse: 2.44473\n",
      "[4300]\ttraining's rmse: 2.336\tvalid_1's rmse: 2.44413\n",
      "[4400]\ttraining's rmse: 2.33426\tvalid_1's rmse: 2.44352\n",
      "[4500]\ttraining's rmse: 2.33255\tvalid_1's rmse: 2.44287\n",
      "[4600]\ttraining's rmse: 2.33079\tvalid_1's rmse: 2.44214\n",
      "[4700]\ttraining's rmse: 2.32902\tvalid_1's rmse: 2.44148\n",
      "[4800]\ttraining's rmse: 2.32739\tvalid_1's rmse: 2.44092\n",
      "[4900]\ttraining's rmse: 2.32591\tvalid_1's rmse: 2.44043\n",
      "[5000]\ttraining's rmse: 2.32416\tvalid_1's rmse: 2.43981\n",
      "[5100]\ttraining's rmse: 2.32268\tvalid_1's rmse: 2.43932\n",
      "[5200]\ttraining's rmse: 2.32105\tvalid_1's rmse: 2.43869\n",
      "[5300]\ttraining's rmse: 2.31964\tvalid_1's rmse: 2.43823\n",
      "[5400]\ttraining's rmse: 2.31817\tvalid_1's rmse: 2.43776\n",
      "[5500]\ttraining's rmse: 2.31691\tvalid_1's rmse: 2.43736\n",
      "[5600]\ttraining's rmse: 2.31562\tvalid_1's rmse: 2.43696\n",
      "[5700]\ttraining's rmse: 2.31408\tvalid_1's rmse: 2.43639\n",
      "[5800]\ttraining's rmse: 2.31276\tvalid_1's rmse: 2.43592\n",
      "[5900]\ttraining's rmse: 2.31133\tvalid_1's rmse: 2.43541\n",
      "[6000]\ttraining's rmse: 2.31005\tvalid_1's rmse: 2.43497\n",
      "[6100]\ttraining's rmse: 2.30867\tvalid_1's rmse: 2.43448\n",
      "[6200]\ttraining's rmse: 2.30727\tvalid_1's rmse: 2.43402\n",
      "[6300]\ttraining's rmse: 2.30591\tvalid_1's rmse: 2.43354\n",
      "[6400]\ttraining's rmse: 2.30473\tvalid_1's rmse: 2.43315\n",
      "[6500]\ttraining's rmse: 2.30339\tvalid_1's rmse: 2.43271\n",
      "[6600]\ttraining's rmse: 2.3022\tvalid_1's rmse: 2.4323\n",
      "[6700]\ttraining's rmse: 2.30096\tvalid_1's rmse: 2.43191\n",
      "[6800]\ttraining's rmse: 2.29979\tvalid_1's rmse: 2.43157\n",
      "[6900]\ttraining's rmse: 2.29855\tvalid_1's rmse: 2.43116\n",
      "[7000]\ttraining's rmse: 2.29734\tvalid_1's rmse: 2.43082\n",
      "[7100]\ttraining's rmse: 2.29618\tvalid_1's rmse: 2.43046\n",
      "[7200]\ttraining's rmse: 2.29523\tvalid_1's rmse: 2.43017\n",
      "[7300]\ttraining's rmse: 2.29421\tvalid_1's rmse: 2.42982\n",
      "[7400]\ttraining's rmse: 2.29312\tvalid_1's rmse: 2.42952\n",
      "[7500]\ttraining's rmse: 2.29195\tvalid_1's rmse: 2.42914\n",
      "[7600]\ttraining's rmse: 2.29101\tvalid_1's rmse: 2.42882\n",
      "[7700]\ttraining's rmse: 2.28987\tvalid_1's rmse: 2.42846\n",
      "[7800]\ttraining's rmse: 2.28882\tvalid_1's rmse: 2.42817\n",
      "[7900]\ttraining's rmse: 2.28768\tvalid_1's rmse: 2.4278\n",
      "[8000]\ttraining's rmse: 2.28663\tvalid_1's rmse: 2.42749\n",
      "[8100]\ttraining's rmse: 2.28569\tvalid_1's rmse: 2.42721\n",
      "[8200]\ttraining's rmse: 2.28475\tvalid_1's rmse: 2.42694\n",
      "[8300]\ttraining's rmse: 2.28377\tvalid_1's rmse: 2.42663\n",
      "[8400]\ttraining's rmse: 2.28269\tvalid_1's rmse: 2.4263\n",
      "[8500]\ttraining's rmse: 2.28169\tvalid_1's rmse: 2.42599\n",
      "[8600]\ttraining's rmse: 2.28067\tvalid_1's rmse: 2.42565\n",
      "[8700]\ttraining's rmse: 2.27962\tvalid_1's rmse: 2.42533\n",
      "[8800]\ttraining's rmse: 2.27871\tvalid_1's rmse: 2.42509\n",
      "[8900]\ttraining's rmse: 2.27768\tvalid_1's rmse: 2.42478\n",
      "[9000]\ttraining's rmse: 2.27666\tvalid_1's rmse: 2.42447\n",
      "[9100]\ttraining's rmse: 2.27574\tvalid_1's rmse: 2.42418\n",
      "[9200]\ttraining's rmse: 2.27493\tvalid_1's rmse: 2.42396\n",
      "[9300]\ttraining's rmse: 2.274\tvalid_1's rmse: 2.4237\n",
      "[9400]\ttraining's rmse: 2.27313\tvalid_1's rmse: 2.42348\n",
      "[9500]\ttraining's rmse: 2.27221\tvalid_1's rmse: 2.4232\n",
      "[9600]\ttraining's rmse: 2.27128\tvalid_1's rmse: 2.42295\n",
      "[9700]\ttraining's rmse: 2.27047\tvalid_1's rmse: 2.4227\n",
      "[9800]\ttraining's rmse: 2.26948\tvalid_1's rmse: 2.42244\n",
      "[9900]\ttraining's rmse: 2.26863\tvalid_1's rmse: 2.4222\n",
      "[10000]\ttraining's rmse: 2.2677\tvalid_1's rmse: 2.42196\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's rmse: 2.2677\tvalid_1's rmse: 2.42196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9967ad97a8ae40ec8336b336e9ad7a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "idx WRMSSE : 0.34205579498599853\n",
      "Wall time: 12h 50min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# New Cross validation\n",
    "import pickle\n",
    "import random\n",
    "decay_rate= 0.05\n",
    "rounds = 1000\n",
    "cv_scores = []\n",
    "folds = 3\n",
    "cols = [\"d_%s\"%x for x in range(1,1914)]\n",
    "random.seed(99)\n",
    "random.shuffle(cols)\n",
    "days = list(df_train['day'].unique()) # 날짜 섞기\n",
    "cols = [x for x in cols if x in days] # 삭제된 day 삭제\n",
    "n= int(np.round(len(cols)/folds))\n",
    "for idx in range(folds):\n",
    "\n",
    "    print(idx)\n",
    "    # Set Evaluator\n",
    "    \n",
    "    d_valid = cols[n*(idx):n*(idx+1)]\n",
    "    d_train = [x for x in cols if x not in d_valid]\n",
    "    tmp = pd.read_csv('m5-forecasting-accuracy/sales_train_validation.csv')\n",
    "    tmp_train = pd.concat([tmp.iloc[:,:6],tmp.loc[:, d_train]], axis =1)\n",
    "    tmp_valid = tmp.loc[:, d_valid]\n",
    "#     evaluator = WRMSSEEvaluator(tmp_train, tmp_valid, calendar, price)\n",
    "    tst= df_train[df_train['day'].isin(d_valid)]\n",
    "    tst['id'] = train_id.loc[tst.index]\n",
    "    \n",
    "    \n",
    "#     evaluator = WRMSSEForLightGBM(tmp_train, tmp_valid, calendar, price,tst)\n",
    "\n",
    "    del tmp \n",
    "    gc.collect()\n",
    "    \n",
    "    # Set train, valid\n",
    "    x_train  = df_train[df_train['day'].isin(d_train)].drop(['day','volume'], axis =1)\n",
    "    y_train = df_train[df_train['day'].isin(d_train)]['volume']\n",
    "    x_valid  = df_train[df_train['day'].isin(d_valid)].drop(['day','volume'], axis =1)\n",
    "    y_valid = df_train[df_train['day'].isin(d_valid)]['volume']\n",
    "    print(\"set train, valid\")\n",
    "    # Modeling\n",
    "    lgb_train = lgb.Dataset(x_train, y_train,categorical_feature=cat_cols)\n",
    "    lgb_eval = lgb.Dataset(x_valid, y_valid,categorical_feature=cat_cols)\n",
    "    gbm = lgb.train(params, lgb_train, valid_sets=(lgb_train, lgb_eval),\n",
    "                   #feval= evaluator.feval,# Custom Loss 사용\n",
    "#                     callbacks = [lgb.early_stopping(10, first_metric_only=True)],# Metric First 체크 -earyly Stopping 에\n",
    "                    early_stopping_rounds= 100,  # rmse 를 기준으로 하고 -- 분석한 후에 WRMSSE만 넣어서 할것\n",
    "                     callbacks=[lgb.reset_parameter(learning_rate = lambda iter: (1 / (1 + decay_rate * (iter//rounds))) * params['learning_rate'])],\n",
    "                   \n",
    "#                 learning_rates=lambda iter: (1 / (1 + decay_rate * iter)) * params['learning_rate'])\n",
    "                    verbose_eval=100) \n",
    "\n",
    "    pickle.dump(gbm,open( \"20200502_model_%s_r1.pkl\"%idx, \"wb\" ))\n",
    "    \n",
    "    evaluator = WRMSSEEvaluator(tmp_train, tmp_valid, calendar, price,tst)\n",
    "    \n",
    "    preds= gbm.predict(x_valid)\n",
    "    tst= df_train[df_train['day'].isin(d_valid)]\n",
    "    tst['id'] = train_id.loc[tst.index]\n",
    "    tst['preds'] = preds\n",
    "    tst= tst.set_index(['id',\"day\"]).unstack()[\"preds\"].reset_index()\n",
    "    tst = tst.fillna(0)\n",
    "\n",
    "    val = pd.DataFrame()\n",
    "    val['id'] = tmp_train['id']\n",
    "    pred = pd.merge(val,tst, how = 'left')\n",
    "    pred = pred.fillna(0)\n",
    "    pred = pred.loc[:,d_valid]\n",
    "    cv_scores.append(evaluator.score(pred))\n",
    "    print(\"idx\",\"WRMSSE :\", evaluator.score(pred))\n",
    "    \n",
    "    \n",
    "    del gbm,tmp_train, tmp_valid, evaluator\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# seed = 99\n",
    "# folds = 3\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import mean_squared_log_error\n",
    "# import pickle\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=folds, random_state=seed, shuffle=True)\n",
    "\n",
    "# for idx, (train_index, test_index) in enumerate(skf.split(df_train.index,df_train['volume'])):\n",
    "#     print(idx)\n",
    "#     x_train = df_train.iloc[train_index].drop(['day','volume'], axis =1)\n",
    "#     y_train = df_train.iloc[train_index]['volume']\n",
    "#     x_valid = df_train.iloc[test_index].drop(['day','volume'], axis =1)\n",
    "#     y_valid = df_train.iloc[test_index]['volume'] \n",
    "    \n",
    "#     # Modeling\n",
    "#     lgb_train = lgb.Dataset(x_train, y_train,categorical_feature=cat_cols)\n",
    "#     lgb_eval = lgb.Dataset(x_valid, y_valid,categorical_feature=cat_cols)\n",
    "#     gbm = lgb.train(params, lgb_train,\n",
    "# #                     num_boost_round=1000, \n",
    "#                     valid_sets=(lgb_train, lgb_eval),\n",
    "#                     early_stopping_rounds= 50,#100,\n",
    "#                     verbose_eval=200) #100)\n",
    "\n",
    "#     pickle.dump(gbm,open( \"20200501_model_%s_r2.pkl\"%idx, \"wb\" ))\n",
    "        \n",
    "#     del gbm\n",
    "#     gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1914\n",
      "rolling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\M5\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1915\n",
      "rolling\n",
      "mean\n",
      "1916\n",
      "rolling\n",
      "mean\n",
      "1917\n",
      "rolling\n",
      "mean\n",
      "1918\n",
      "rolling\n",
      "mean\n",
      "1919\n",
      "rolling\n",
      "mean\n",
      "1920\n",
      "rolling\n",
      "mean\n",
      "1921\n",
      "rolling\n",
      "mean\n",
      "1922\n",
      "rolling\n",
      "mean\n",
      "1923\n",
      "rolling\n",
      "mean\n",
      "1924\n",
      "rolling\n",
      "mean\n",
      "1925\n",
      "rolling\n",
      "mean\n",
      "1926\n",
      "rolling\n",
      "mean\n",
      "1927\n",
      "rolling\n",
      "mean\n",
      "1928\n",
      "rolling\n",
      "mean\n",
      "1929\n",
      "rolling\n",
      "mean\n",
      "1930\n",
      "rolling\n",
      "mean\n",
      "1931\n",
      "rolling\n",
      "mean\n",
      "1932\n",
      "rolling\n",
      "mean\n",
      "1933\n",
      "rolling\n",
      "mean\n",
      "1934\n",
      "rolling\n",
      "mean\n",
      "1935\n",
      "rolling\n",
      "mean\n",
      "1936\n",
      "rolling\n",
      "mean\n",
      "1937\n",
      "rolling\n",
      "mean\n",
      "1938\n",
      "rolling\n",
      "mean\n",
      "1939\n",
      "rolling\n",
      "mean\n",
      "1940\n",
      "rolling\n",
      "mean\n",
      "1941\n",
      "rolling\n",
      "mean\n",
      "Wall time: 54min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test['id'] = train_id\n",
    "max_lag  = 120\n",
    "trn_lst = 1913\n",
    "for tdelta in range(1, 29):\n",
    "    f_day = trn_lst+tdelta\n",
    "    print(f_day)\n",
    "    days = [f\"d_{i}\" for i in range(trn_lst-max_lag+tdelta,f_day+1)]\n",
    "    tst = df_test[df_test['day'].isin(days)]\n",
    "\n",
    "    print(\"rolling\")\n",
    "   # tst['volume_1'] = tst[['id','volume']].groupby(\"id\")['volume'].shift(1)\n",
    "  #  tst['volume_2'] = tst[['id','volume']].groupby(\"id\")['volume'].shift(2)\n",
    "  #  tst['volume_3'] = tst[['id','volume']].groupby(\"id\")['volume'].shift(3)\n",
    "    \n",
    "    tst['volume_7'] = tst[['id','volume']].groupby(\"id\")['volume'].shift(7)\n",
    "    tst['volume_28'] = tst[['id','volume']].groupby(\"id\")['volume'].shift(28)\n",
    "    \n",
    "    print(\"mean\")\n",
    "    tst['rmean_7_7'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).mean())\n",
    "    tst['rmean_7_28'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).mean())\n",
    "    tst['rmean_7_50'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).mean())\n",
    "\n",
    "    tst['rmean_28_7'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).mean())\n",
    "    tst['rmean_28_28'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).mean())\n",
    "    tst['rmean_28_50'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).mean())\n",
    "    \n",
    "#     print(\"std\")\n",
    "#     tst['rstd_7_7'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).std())\n",
    "#     tst['rstd_7_28'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).std())\n",
    "#     tst['rstd_7_50'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).std())\n",
    "\n",
    "#     tst['rstd_28_7'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).std())\n",
    "#     tst['rstd_28_28'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).std())\n",
    "#     tst['rstd_28_50'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).std())\n",
    "\n",
    "#     print(\"max\")\n",
    "#     tst['rmax_7_7'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).max())\n",
    "#     tst['rmax_7_28'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).max())\n",
    "#     tst['rmax_7_50'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).max())\n",
    "\n",
    "#     tst['rmax_28_7'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).max())\n",
    "#     tst['rmax_28_28'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).max())\n",
    "#     tst['rmax_28_50'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).max())\n",
    "\n",
    "#     print(\"min\")\n",
    "#     tst['rmin_7_7'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).min())\n",
    "#     tst['rmin_7_28'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).min())\n",
    "#     tst['rmin_7_50'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).min())\n",
    "\n",
    "#     tst['rmin_28_7'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).min())\n",
    "#     tst['rmin_28_28'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).min())\n",
    "#     tst['rmin_28_50'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).min())\n",
    "\n",
    "#     print(\"count\")\n",
    "#     tst['rcount_7_7'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(7).count() if x>0).fllna(0)\n",
    "#     tst['rcount_7_28'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(28).count() if x>0).fllna(0)\n",
    "#     tst['rcount_7_50'] = tst[['id','volume_7']].groupby(\"id\")['volume_7'].transform(lambda x: x.rolling(50).count() if x>0).fllna(0)\n",
    "\n",
    "#     tst['rcount_28_7'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(7).count() if x>0).fllna(0)\n",
    "#     tst['rcount_28_28'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(28).count() if x>0).fllna(0)\n",
    "#     tst['rcount_28_50'] = tst[['id','volume_28']].groupby(\"id\")['volume_28'].transform(lambda x: x.rolling(50).count() if x>0).fllna(0)\n",
    "\n",
    "    \n",
    "    tst = tst[tst['day'] == \"d_%s\"%(f_day)]\n",
    "    t_id,t_volume,t_day = tst['id'],tst['volume'],tst['day']\n",
    "    tst = tst.drop(['id','volume','day'], axis =1)\n",
    "    \n",
    "    # Crossvalidation \n",
    "    for idx in range(folds):\n",
    "        gbm = pickle.load(open( \"20200502_model_%s_r1.pkl\"%idx, \"rb\" ))\n",
    "        df_test.loc[df_test.day==\"d_%s\"%(f_day),'volume'] += 1.028*gbm.predict(tst) / folds\n",
    "        del gbm\n",
    "        gc.collect()\n",
    " \n",
    "    del tst \n",
    "    gc.collect()\n",
    "    #0을 예측 못하니까 0으로 치환하는 것 -- test\n",
    "#     df_test.loc[df_test.volume<0.5,'volume'] = 0\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f\"d_{i}\" for i in range(1914,1942)]\n",
    "\n",
    "sub = df_test[df_test['day'].isin(cols)].loc[:,['id','volume']]\n",
    "sub['F']= [f\"F{rank}\" for rank in sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "sub = sub.set_index([\"id\", \"F\" ]).unstack()[\"volume\"].reset_index()\n",
    "sub.sort_values(\"id\", inplace = True)\n",
    "sub.reset_index(drop=True, inplace = True)                                                   \n",
    "sub =sub[['id']+[\"F%s\"% x for x in range(1,29)]]\n",
    "\n",
    "sub = sub.fillna(0)\n",
    "\n",
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "sub.to_csv(\"submission_20200502_2_LR0.01.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 체크하기\n",
    "import pickle\n",
    "gbm = pickle.load(open( \"20200502_model_2_r1.pkl\", \"rb\" ))\n",
    "# %%time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y - y_pred)))\n",
    "\n",
    "\n",
    "# x_train , x_valid = train_test_split(df_train, test_size =0.05, random_state = 99)\n",
    "# y_train, y_valid = x_train['volume'], x_valid['volume']\n",
    "\n",
    "# x_train = x_train.drop(['day','volume'], axis =1)\n",
    "# x_valid = x_valid.drop(['day','volume'], axis =1)\n",
    "\n",
    "cols = [\"d_%s\"% x for x in range(1883,1914)]\n",
    "x_valid = df_train[df_train['day'].isin(cols)]\n",
    "y_valid = x_valid['volume']\n",
    "x_valid = x_valid.drop(['day','volume'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original 2.1879806605265957\n",
      "Wall time: 7.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = gbm.predict(x_valid)\n",
    "print(\"original\", rmse(y_valid, pred))\n",
    "origin = rmse(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373d9482696f4d4b99bd4fb80a54ee0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{}\n",
      "Wall time: 25 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# 컬럼들을 랜덤하게 섞어서 예측해보는 것\n",
    "# cols = list(x_valid.columns)\n",
    "\n",
    "z = pd.read_csv('featuretest.csv')\n",
    "cols = list(x for x in x_valid.columns if x not in list(z['columns']))\n",
    "fin = dict()\n",
    "for col in tqdm(cols):\n",
    "    tmp = x_valid.copy()\n",
    "    tmp[col] = np.random.permutation(tmp[col].values)\n",
    "    t_rmse = rmse(y_valid, gbm.predict(tmp))\n",
    "    gap = t_rmse-origin  # origin 보다 에러가 커졌으면 이 컬럼은 중요한 것 !\n",
    "    print(col, t_rmse, gap)\n",
    "    fin[col] = gap\n",
    "\n",
    "print(fin)\n",
    "new = pd.DataFrame()\n",
    "new['columns'] =fin.keys()\n",
    "new['values'] = fin.values()\n",
    "z = pd.concat([z,new])\n",
    "z.to_csv('featuretest.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
