{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_identity.csv', 'test_transaction.csv', 'sample_submission.csv', 'train_transaction.csv', 'train_identity.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Standard plotly imports\n",
    "#import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "#import cufflinks\n",
    "#import cufflinks as cf\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Using plotly + cufflinks in offline mode\n",
    "init_notebook_mode(connected=True)\n",
    "#cufflinks.go_offline(connected=True)\n",
    "\n",
    "# Preprocessing, modelling and evaluating\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "## Hyperopt modules\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import gc\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 433)\n",
      "(590540, 433)\n"
     ]
    }
   ],
   "source": [
    "#modeling\n",
    "df_trans = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\n",
    "df_test_trans = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\n",
    "\n",
    "df_id = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\n",
    "df_test_id = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\n",
    "\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n",
    "\n",
    "df_train = df_trans.merge(df_id, how='left', left_index=True, right_index=True)\n",
    "df_test = df_test_trans.merge(df_test_id, how='left', left_index=True, right_index=True)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumetable(df):\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
    "    summary = summary.reset_index()\n",
    "    summary['Name'] = summary['index']\n",
    "    summary = summary[['Name','dtypes']]\n",
    "    summary['Missing'] = df.isnull().sum().values    \n",
    "    summary['Uniques'] = df.nunique().values\n",
    "    summary['First Value'] = df.loc[0].values\n",
    "    summary['Second Value'] = df.loc[1].values\n",
    "    summary['Third Value'] = df.loc[2].values\n",
    "\n",
    "    for name in summary['Name'].value_counts().index:\n",
    "        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n",
    "\n",
    "    return summary\n",
    "\n",
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def CalcOutliers(df_num): \n",
    "\n",
    "    # calculating mean and std of the array\n",
    "    data_mean, data_std = np.mean(df_num), np.std(df_num)\n",
    "\n",
    "    # seting the cut line to both higher and lower values\n",
    "    # You can change this value\n",
    "    cut = data_std * 3\n",
    "\n",
    "    #Calculating the higher and lower cut values\n",
    "    lower, upper = data_mean - cut, data_mean + cut\n",
    "\n",
    "    # creating an array of lower, higher and total outlier values \n",
    "    outliers_lower = [x for x in df_num if x < lower]\n",
    "    outliers_higher = [x for x in df_num if x > upper]\n",
    "    outliers_total = [x for x in df_num if x < lower or x > upper]\n",
    "\n",
    "    # array without outlier values\n",
    "    outliers_removed = [x for x in df_num if x > lower and x < upper]\n",
    "    \n",
    "    print('Identified lowest outliers: %d' % len(outliers_lower)) # printing total number of values in lower cut of outliers\n",
    "    print('Identified upper outliers: %d' % len(outliers_higher)) # printing total number of values in higher cut of outliers\n",
    "    print('Total outlier observations: %d' % len(outliers_total)) # printing total number of values outliers of both sides\n",
    "    print('Non-outlier observations: %d' % len(outliers_removed)) # printing total number of non outlier values\n",
    "    print(\"Total percentual of Outliers: \", round((len(outliers_total) / len(outliers_removed) )*100, 4)) # Percentual of outliers in points\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 668.22 Mb (66.2% reduction)\n",
      "Mem. usage decreased to 583.43 Mb (65.6% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "START_DATE = '2017-12-01'\n",
    "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "df_train[\"Date\"] = df_train['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "df_train['_Weekdays'] = df_train['Date'].dt.dayofweek\n",
    "df_train['_Hours'] = df_train['Date'].dt.hour\n",
    "df_train['_Days'] = df_train['Date'].dt.day\n",
    "\n",
    "START_DATE_test = '2018-06-01'\n",
    "startdate = datetime.datetime.strptime(START_DATE_test, \"%Y-%m-%d\")\n",
    "df_test[\"Date\"] = df_test['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "df_test['_Weekdays'] = df_test['Date'].dt.dayofweek\n",
    "df_test['_Hours'] = df_test['Date'].dt.hour\n",
    "df_test['_Days'] = df_test['Date'].dt.day\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corret_card_id(x): \n",
    "    x=x.replace('.0','')\n",
    "    x=x.replace('-999','nan')\n",
    "    return x\n",
    "\n",
    "def definie_indexes(df):\n",
    "    # create card ID \n",
    "    cards_cols= ['card1', 'card2', 'card3', 'card5']\n",
    "    for card in cards_cols: \n",
    "        if '1' in card: \n",
    "            df['Card_ID']= df[card].map(str)\n",
    "        else : \n",
    "            df['Card_ID']+= ' '+df[card].map(str)\n",
    "    \n",
    "    # sort train data by Card_ID and then by transaction date \n",
    "    df= df.sort_values(['Card_ID', 'Date'], ascending=[True, True])\n",
    "    \n",
    "    # small correction of the Card_ID\n",
    "    df['Card_ID']=df['Card_ID'].apply(corret_card_id)\n",
    "    \n",
    "    # set indexes \n",
    "    # df= df.set_index(['Card_ID', 'Date'])\n",
    "    return df\n",
    "\n",
    "df_train = definie_indexes(df_train)\n",
    "df_test = definie_indexes(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### M columns (except M4)\n",
    "# All these columns are binary encoded 1/0\n",
    "# We can have some features from it\n",
    "i_cols = ['M1','M2','M3','M5','M6','M7','M8','M9']\n",
    "\n",
    "df_train['M_sum'] = df_train[i_cols].sum(axis=1).astype(np.int8)\n",
    "df_test['M_sum']  = df_test[i_cols].sum(axis=1).astype(np.int8)\n",
    "\n",
    "df_train['M_na'] = df_train[i_cols].isna().sum(axis=1).astype(np.int8)\n",
    "df_test['M_na']  = df_test[i_cols].isna().sum(axis=1).astype(np.int8)\n",
    "\n",
    "df_train['M_type'] = ''\n",
    "df_test['M_type']  = ''\n",
    "\n",
    "for col in i_cols:\n",
    "    df_train['M_type'] = '_'+df_train[col].astype(str)\n",
    "    df_test['M_type'] = '_'+df_test[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier 찾기 : 3시그마 이상\n",
    "\n",
    "# CalcOutliers(df_trans['TransactionAmt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### C columns\n",
    "# C columns are some counts, based on client identity\n",
    "# Most popular Value is \"1\" -> that seems to be just a single match \n",
    "# (New or stable client)\n",
    "# You can check that auc score for that cliens are lower than global\n",
    "# Lets encode such client types\n",
    "\n",
    "i_cols = ['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14']\n",
    "\n",
    "df_train['C_sum'] = 0\n",
    "df_test['C_sum']  = 0\n",
    "\n",
    "df_train['C_null'] = 0\n",
    "df_test['C_null']  = 0\n",
    "\n",
    "for col in i_cols:\n",
    "    df_train['C_sum'] += np.where(df_train[col]==1,1,0)\n",
    "    df_test['C_sum']  += np.where(df_test[col]==1,1,0)\n",
    "\n",
    "    df_train['C_null'] += np.where(df_train[col]==0,1,0)\n",
    "    df_test['C_null']  += np.where(df_test[col]==0,1,0)\n",
    "    \n",
    "    valid_values = df_train[col].value_counts()\n",
    "    valid_values = valid_values[valid_values>1000]\n",
    "    valid_values = list(valid_values.index)\n",
    "    \n",
    "    df_train[col+'_valid'] = np.where(df_train[col].isin(valid_values),1,0)\n",
    "    df_test[col+'_valid']  = np.where(df_test[col].isin(valid_values),1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################### Reset values for \"noise\" card1\n",
    "# valid_card = df_train['card1'].value_counts()\n",
    "# valid_card = valid_card[valid_card>10]\n",
    "# valid_card = list(valid_card.index)\n",
    "    \n",
    "# df_train['card1'] = np.where(df_train['card1'].isin(valid_card), df_train['card1'], np.nan)\n",
    "# df_test['card1']  = np.where(df_test['card1'].isin(valid_card), df_test['card1'], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Device info\n",
    "df_train['DeviceInfo'] = df_train['DeviceInfo'].fillna('unknown_device').str.lower()\n",
    "df_test['DeviceInfo'] = df_test['DeviceInfo'].fillna('unknown_device').str.lower()\n",
    "\n",
    "df_train['DeviceInfo_c'] = df_train['DeviceInfo']\n",
    "df_test['DeviceInfo_c'] = df_test['DeviceInfo']\n",
    "\n",
    "device_match_dict = {\n",
    "    'sm':'sm-',\n",
    "    'sm':'samsung',\n",
    "    'huawei':'huawei',\n",
    "    'moto':'moto',\n",
    "    'rv':'rv:',\n",
    "    'trident':'trident',\n",
    "    'lg':'lg-',\n",
    "    'htc':'htc',\n",
    "    'blade':'blade',\n",
    "    'windows':'windows',\n",
    "    'lenovo':'lenovo',\n",
    "    'linux':'linux',\n",
    "    'f3':'f3',\n",
    "    'f5':'f5'\n",
    "}\n",
    "for dev_type_s, dev_type_o in device_match_dict.items():\n",
    "    df_train['DeviceInfo_c'] = df_train['DeviceInfo_c'].apply(lambda x: dev_type_s if dev_type_o in x else x)\n",
    "    df_test['DeviceInfo_c'] = df_test['DeviceInfo_c'].apply(lambda x: dev_type_s if dev_type_o in x else x)\n",
    "\n",
    "df_train['DeviceInfo_c'] = df_train['DeviceInfo_c'].apply(lambda x: 'other_d_type' if x not in device_match_dict else x)\n",
    "df_test['DeviceInfo_c'] = df_test['DeviceInfo_c'].apply(lambda x: 'other_d_type' if x not in device_match_dict else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n",
    "\n",
    "df_train.loc[df_train['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n",
    "                                             'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n",
    "                                             'yahoo.es']), 'R_emaildomain'] = 'Yahoo Mail'\n",
    "df_train.loc[df_train['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n",
    "                                             'hotmail.es','hotmail.co.uk', 'hotmail.de',\n",
    "                                             'outlook.es', 'live.com', 'live.fr',\n",
    "                                             'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\n",
    "df_train.loc[df_train.R_emaildomain.isin(df_train.R_emaildomain\\\n",
    "                                         .value_counts()[df_train.R_emaildomain.value_counts() <= 300 ]\\\n",
    "                                         .index), 'R_emaildomain'] = \"Others\"\n",
    "df_train.R_emaildomain.fillna(\"NoInf\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n",
    "\n",
    "df_test.loc[df_test['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n",
    "                                             'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n",
    "                                             'yahoo.es']), 'R_emaildomain'] = 'Yahoo Mail'\n",
    "df_test.loc[df_test['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n",
    "                                             'hotmail.es','hotmail.co.uk', 'hotmail.de',\n",
    "                                             'outlook.es', 'live.com', 'live.fr',\n",
    "                                             'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\n",
    "df_test.loc[df_test.R_emaildomain.isin(df_test.R_emaildomain\\\n",
    "                                         .value_counts()[df_test.R_emaildomain.value_counts() <= 300 ]\\\n",
    "                                         .index), 'R_emaildomain'] = \"Others\"\n",
    "df_test.R_emaildomain.fillna(\"NoInf\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\n",
    "df_train.loc[df_train['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\n",
    "df_train.loc[df_train['id_30'].str.contains('Mac OS', na=False), 'id_30'] = 'Mac'\n",
    "df_train.loc[df_train['id_30'].str.contains('Android', na=False), 'id_30'] = 'Android'\n",
    "df_train['id_30'].fillna(\"NAN\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\n",
    "df_test.loc[df_test['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\n",
    "df_test.loc[df_test['id_30'].str.contains('Mac OS', na=False), 'id_30'] = 'Mac'\n",
    "df_test.loc[df_test['id_30'].str.contains('Android', na=False), 'id_30'] = 'Android'\n",
    "df_test['id_30'].fillna(\"NAN\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['id_31'].str.contains('chrome', na=False), 'id_31'] = 'Chrome'\n",
    "df_train.loc[df_train['id_31'].str.contains('firefox', na=False), 'id_31'] = 'Firefox'\n",
    "df_train.loc[df_train['id_31'].str.contains('safari', na=False), 'id_31'] = 'Safari'\n",
    "df_train.loc[df_train['id_31'].str.contains('edge', na=False), 'id_31'] = 'Edge'\n",
    "df_train.loc[df_train['id_31'].str.contains('ie', na=False), 'id_31'] = 'IE'\n",
    "df_train.loc[df_train['id_31'].str.contains('samsung', na=False), 'id_31'] = 'Samsung'\n",
    "df_train.loc[df_train['id_31'].str.contains('opera', na=False), 'id_31'] = 'Opera'\n",
    "df_train['id_31'].fillna(\"NAN\", inplace=True)\n",
    "df_train.loc[df_train.id_31.isin(df_train.id_31.value_counts()[df_train.id_31.value_counts() < 200].index), 'id_31'] = \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['id_31'].str.contains('chrome', na=False), 'id_31'] = 'Chrome'\n",
    "df_test.loc[df_test['id_31'].str.contains('firefox', na=False), 'id_31'] = 'Firefox'\n",
    "df_test.loc[df_test['id_31'].str.contains('safari', na=False), 'id_31'] = 'Safari'\n",
    "df_test.loc[df_test['id_31'].str.contains('edge', na=False), 'id_31'] = 'Edge'\n",
    "df_test.loc[df_test['id_31'].str.contains('ie', na=False), 'id_31'] = 'IE'\n",
    "df_test.loc[df_test['id_31'].str.contains('samsung', na=False), 'id_31'] = 'Samsung'\n",
    "df_test.loc[df_test['id_31'].str.contains('opera', na=False), 'id_31'] = 'Opera'\n",
    "df_test['id_31'].fillna(\"NAN\", inplace=True)\n",
    "df_test.loc[df_test.id_31.isin(df_test.id_31.value_counts()[df_test.id_31.value_counts() < 200].index), 'id_31'] = \"Others\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_interaction(df, feature_1, feature_2):\n",
    "    return df[feature_1].astype(str) + '_' + df[feature_2].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://www.kaggle.com/nroman/lgb-single-model-lb-0-9419\n",
    "\n",
    "features_interactions = [\n",
    "    'id_02__id_20',\n",
    "    'id_02__D8',\n",
    "    'D11__DeviceInfo',\n",
    "    'DeviceInfo__P_emaildomain',\n",
    "    'P_emaildomain__C2',\n",
    "    'card2__dist1',\n",
    "    'card1__card5',\n",
    "    'card2__id_20',\n",
    "    'card5__P_emaildomain',\n",
    "    'addr1__card1'\n",
    "]\n",
    "\n",
    "for new_feature in features_interactions:\n",
    "    feature_1, feature_2 = new_feature.split('__')\n",
    "    \n",
    "    df_train[new_feature] = features_interaction(df_train, feature_1, feature_2)\n",
    "    df_test[new_feature] = features_interaction(df_test, feature_1, feature_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['count_last'] = df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).count())\n",
    "df_train['mean_last'] = df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).mean())\n",
    "df_train['min_last'] = df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).min())\n",
    "df_train['max_last'] = df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).max())\n",
    "df_train['std_last'] = df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).std())\n",
    "df_test['count_last'] = df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).count())\n",
    "df_test['mean_last'] = df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).mean())\n",
    "df_test['min_last'] = df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).min())\n",
    "df_test['max_last'] = df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).max())\n",
    "df_test['std_last'] = df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).std())\n",
    "df_train['trans_mean_last'] = df_train['TransactionAmt'] / df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).mean())\n",
    "df_train['trans_std_last'] = df_train['TransactionAmt'] / df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).std())\n",
    "df_test['trans_mean_last'] = df_test['TransactionAmt'] / df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).mean())\n",
    "df_test['trans_std_last'] = df_test['TransactionAmt'] / df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).std())\n",
    "df_train['TransactionAmt_to_mean_card_id'] = df_train['TransactionAmt'] - df_train.groupby(['Card_ID'])['TransactionAmt'].transform('mean')\n",
    "df_train['TransactionAmt_to_std_card_id'] = df_train['TransactionAmt_to_mean_card_id'] / df_train.groupby(['Card_ID'])['TransactionAmt'].transform('std')\n",
    "df_test['TransactionAmt_to_mean_card_id'] = df_test['TransactionAmt'] - df_test.groupby(['Card_ID'])['TransactionAmt'].transform('mean')\n",
    "df_test['TransactionAmt_to_std_card_id'] = df_test['TransactionAmt_to_mean_card_id'] / df_test.groupby(['Card_ID'])['TransactionAmt'].transform('std')\n",
    "df_train['id_02_to_mean_card_id'] = df_train['id_02'] / df_train.groupby(['Card_ID'])['id_02'].transform('mean')\n",
    "df_train['id_02_to_std_card_id'] = df_train['id_02'] / df_train.groupby(['Card_ID'])['id_02'].transform('std')\n",
    "df_test['id_02_to_mean_card_id'] = df_test['id_02'] / df_test.groupby(['Card_ID'])['id_02'].transform('mean')\n",
    "df_test['id_02_to_std_card_id'] = df_test['id_02'] / df_test.groupby(['Card_ID'])['id_02'].transform('std')\n",
    "df_train['D15_to_mean_card_id'] = df_train['D15'] / df_train.groupby(['Card_ID'])['D15'].transform('mean')\n",
    "df_train['D15_to_std_card_id'] = df_train['D15'] / df_train.groupby(['Card_ID'])['D15'].transform('std')\n",
    "df_test['D15_to_mean_card_id'] = df_test['D15'] / df_test.groupby(['Card_ID'])['D15'].transform('mean')\n",
    "df_test['D15_to_std_card_id'] = df_test['D15'] / df_test.groupby(['Card_ID'])['D15'].transform('std')\n",
    "df_train['D15_to_mean_addr1'] = df_train['D15'] / df_train.groupby(['addr1'])['D15'].transform('mean')\n",
    "df_train['D15_to_std_addr1'] = df_train['D15'] / df_train.groupby(['addr1'])['D15'].transform('std')\n",
    "df_test['D15_to_mean_addr1'] = df_test['D15'] / df_test.groupby(['addr1'])['D15'].transform('mean')\n",
    "df_test['D15_to_std_addr1'] = df_test['D15'] / df_test.groupby(['addr1'])['D15'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['card1_count_full'] = df_train['card1'].map(pd.concat([df_train['card1'], df_test['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card1_count_full'] = df_test['card1'].map(pd.concat([df_train['card1'], df_test['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "\n",
    "df_train['card2_count_full'] = df_train['card2'].map(pd.concat([df_train['card2'], df_test['card2']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card2_count_full'] = df_test['card2'].map(pd.concat([df_train['card2'], df_test['card2']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "df_train['card3_count_full'] = df_train['card3'].map(pd.concat([df_train['card3'], df_test['card3']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card3_count_full'] = df_test['card3'].map(pd.concat([df_train['card3'], df_test['card3']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "df_train['card4_count_full'] = df_train['card4'].map(pd.concat([df_train['card4'], df_test['card4']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card4_count_full'] = df_test['card4'].map(pd.concat([df_train['card4'], df_test['card4']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "df_train['card5_count_full'] = df_train['card5'].map(pd.concat([df_train['card5'], df_test['card5']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card5_count_full'] = df_test['card5'].map(pd.concat([df_train['card5'], df_test['card5']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "df_train['card6_count_full'] = df_train['card6'].map(pd.concat([df_train['card6'], df_test['card6']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card6_count_full'] = df_test['card6'].map(pd.concat([df_train['card6'], df_test['card6']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "\n",
    "df_train['addr1_count_full'] = df_train['addr1'].map(pd.concat([df_train['addr1'], df_test['addr1']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['addr1_count_full'] = df_test['addr1'].map(pd.concat([df_train['addr1'], df_test['addr1']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "df_train['addr2_count_full'] = df_train['addr2'].map(pd.concat([df_train['addr2'], df_test['addr2']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['addr2_count_full'] = df_test['addr2'].map(pd.concat([df_train['addr2'], df_test['addr2']], ignore_index=True).value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['id_34', 'id_36']:\n",
    "    # Count encoded for both df_train and df_test\n",
    "    df_train[feature + '_count_full'] = df_train[feature].map(pd.concat([df_train[feature], df_test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "    df_test[feature + '_count_full'] = df_test[feature].map(pd.concat([df_train[feature], df_test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "        \n",
    "for feature in ['id_01', 'id_31', 'id_33', 'id_35', 'id_36']:\n",
    "    # Count encoded separately for df_train and df_test\n",
    "    df_train[feature + '_count_dist'] = df_train[feature].map(df_train[feature].value_counts(dropna=False))\n",
    "    df_test[feature + '_count_dist'] = df_test[feature].map(df_test[feature].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['P_isproton']=(df_train['P_emaildomain']=='protonmail.com')\n",
    "df_train['R_isproton']=(df_train['R_emaildomain']=='protonmail.com')\n",
    "df_test['P_isproton']=(df_test['P_emaildomain']=='protonmail.com')\n",
    "df_test['R_isproton']=(df_test['R_emaildomain']=='protonmail.com')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(df_train.shape[0])\n",
    "df_train[\"lasdf_test_browser\"] = a\n",
    "a = np.zeros(df_test.shape[0])\n",
    "df_test[\"lasdf_test_browser\"] = a\n",
    "def setbrowser(df):\n",
    "    df.loc[df[\"id_31\"]==\"samsung browser 7.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"opera 53.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"mobile safari 10.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"google search application 49.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"firefox 60.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"edge 17.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 69.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 67.0 for android\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 63.0 for android\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 63.0 for ios\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 64.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 64.0 for android\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 64.0 for ios\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 65.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 65.0 for android\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 65.0 for ios\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 66.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 66.0 for android\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 66.0 for ios\",'lasdf_test_browser']=1\n",
    "    return df\n",
    "df_train=setbrowser(df_train)\n",
    "df_test=setbrowser(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TransactionAmt_decimal'] = ((df_train['TransactionAmt'] - df_train['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "df_test['TransactionAmt_decimal'] = ((df_test['TransactionAmt'] - df_test['TransactionAmt'].astype(int)) * 1000).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Freq encoding\n",
    "i_cols = ['card1','card2','card3','card5',\n",
    "          'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "          'D1','D2','D3','D4','D5','D6','D7','D8','D9',\n",
    "          'addr1','addr2',\n",
    "          'dist1','dist2',\n",
    "          'P_emaildomain', 'R_emaildomain',\n",
    "          'id_01','id_02','id_03','id_04','id_05','id_06','id_07','id_08','id_09','id_10',\n",
    "          'id_11','id_13','id_14','id_17','id_18','id_19','id_20','id_21','id_22','id_24',\n",
    "          'id_25','id_26','id_30','id_31','id_32','id_33',#'id_33_0','id_33_1',\n",
    "          'DeviceInfo','DeviceInfo_c',#'id_30_c','id_30_v','id_31_v',\n",
    "         ]\n",
    "\n",
    "for col in i_cols:\n",
    "    temp_df = pd.concat([df_train[[col]], df_test[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()   \n",
    "    df_train[col+'_fq_enc'] = df_train[col].map(fq_encode)\n",
    "    df_test[col+'_fq_enc']  = df_test[col].map(fq_encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_value_cols = [col for col in df_train.columns if df_train[col].nunique() <= 1]\n",
    "one_value_cols_test = [col for col in df_test.columns if df_test[col].nunique() <= 1]\n",
    "one_value_cols == one_value_cols_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_null_cols = [col for col in df_train.columns if df_train[col].isnull().sum() / df_train.shape[0] > 0.9]\n",
    "many_null_cols_test = [col for col in df_test.columns if df_test[col].isnull().sum() / df_test.shape[0] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_top_value_cols = [col for col in df_train.columns if df_train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "big_top_value_cols_test = [col for col in df_test.columns if df_test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 ['lasdf_test_browser', 'C5_valid', 'V24', 'V321', 'id_24_fq_enc', 'V25', 'V298', 'id_22', 'C7_valid', 'V68', 'V305', 'C13_valid', 'V88', 'V123', 'V119', 'V124', 'V281', 'V284', 'id_25', 'V121', 'V55', 'V318', 'id_26', 'V98', 'V296', 'id_23', 'C3', 'V112', 'V113', 'C11_valid', 'V122', 'V135', 'V86', 'V300', 'V110', 'V109', 'C2_valid', 'V102', 'V27', 'id_18', 'V301', 'dist2_fq_enc', 'V89', 'V132', 'V115', 'V137', 'V136', 'D7', 'V319', 'C8_valid', 'id_21_fq_enc', 'id_27', 'V67', 'C1_valid', 'id_21', 'id_26_fq_enc', 'C3_fq_enc', 'V299', 'V28', 'V118', 'V316', 'V23', 'V111', 'V286', 'C12_valid', 'V117', 'M_sum', 'C6_valid', 'V114', 'C14_valid', 'id_18_fq_enc', 'V125', 'isFraud', 'D7_fq_enc', 'V116', 'V65', 'V311', 'id_08_fq_enc', 'V295', 'V309', 'V297', 'V103', 'V133', 'id_22_fq_enc', 'V26', 'V320', 'V120', 'id_07_fq_enc', 'V108', 'C4_valid', 'V105', 'C3_valid', 'C9_valid', 'V14', 'V101', 'id_07', 'V293', 'id_08', 'V134', 'V77', 'V107', 'V129', 'V66', 'id_25_fq_enc', 'V290', 'id_24', 'R_isproton', 'V104', 'P_isproton', 'V106', 'C10_valid', 'dist2']\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = list(set(many_null_cols + many_null_cols_test +\n",
    "                        big_top_value_cols +\n",
    "                        big_top_value_cols_test +\n",
    "                        one_value_cols+ one_value_cols_test))\n",
    "len(cols_to_drop)\n",
    "print(len(cols_to_drop),cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop.remove('isFraud')\n",
    "\n",
    "df_train = df_train.drop(cols_to_drop, axis=1)\n",
    "df_test = df_test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0199b73e75074d47ab846836b733017e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=452), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# categorical features encoding\n",
    "from tqdm import tqdm_notebook\n",
    "# for col in cat_cols:\n",
    "#     if col in df_train.columns:\n",
    "#         le = preprocessing.LabelEncoder()\n",
    "#         le.fit(list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values))\n",
    "#         df_train[col] = le.transform(list(df_train[col].astype(str).values))\n",
    "#         df_test[col] = le.transform(list(df_test[col].astype(str).values))   \n",
    "\n",
    "for col in tqdm_notebook(df_train.columns):\n",
    "    if df_train[col].dtype == 'object':\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values))\n",
    "        df_train[col] = le.transform(list(df_train[col].astype(str).values))\n",
    "        df_test[col] = le.transform(list(df_test[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'Date'], axis=1)\n",
    "Y_train = df_train.sort_values('TransactionDT')['isFraud']\n",
    "X_test = df_test.sort_values('TransactionDT').drop(['TransactionDT','Date'], axis=1)\n",
    "del df_train\n",
    "df_test = df_test[[\"TransactionDT\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 604.30 Mb (35.2% reduction)\n",
      "Mem. usage decreased to 529.12 Mb (34.5% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter 찾기\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def objective(params):\n",
    "\n",
    "    print(\"############## New Run ################\")\n",
    "    print(\"PARAMETERS: \")\n",
    "    print(f\"params  = {params}\")\n",
    "    \n",
    "    params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'gamma': \"{:.3f}\".format(params['gamma']),\n",
    "        'reg_alpha': \"{:.3f}\".format(params['reg_alpha']),\n",
    "        'learning_rate': \"{:.3f}\".format(params['learning_rate']),\n",
    "        'gamma': \"{:.3f}\".format(params['gamma']),\n",
    "        'num_leaves': '{:.3f}'.format(params['num_leaves']),\n",
    "        'min_child_samples': '{:.3f}'.format(params['min_child_samples']),\n",
    "        'feature_fraction': '{:.3f}'.format(params['feature_fraction']),\n",
    "        'bagging_fraction': '{:.3f}'.format(params['bagging_fraction'])\n",
    "    }\n",
    "    \n",
    "    EPOCHS = 5\n",
    "    tss = TimeSeriesSplit(n_splits=EPOCHS)\n",
    "    score_mean = 0\n",
    "    print(\"CV SCORE: \")\n",
    "    for tr_idx, val_idx in tss.split(X_train, Y_train):\n",
    "        clf = xgb.XGBClassifier(\n",
    "            n_estimators=2000, random_state=4,\n",
    "            tree_method='gpu_hist', verbosity=2,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n",
    "        y_tr, y_vl = Y_train.iloc[tr_idx], Y_train.iloc[val_idx]\n",
    "        eval_set = [(X_vl, y_vl)]\n",
    "        clf.fit(X_tr, y_tr,eval_metric = 'auc', eval_set=eval_set ,early_stopping_rounds=50, verbose=False)\n",
    "        \n",
    "        y_pred_train = clf.predict_proba(X_vl)[:,1]\n",
    "        score = roc_auc_score(y_vl, y_pred_train)\n",
    "        score_mean += score\n",
    "        del clf\n",
    "        gc.collect()\n",
    "        print(f'ROC AUC {score}')\n",
    "    del X_tr, X_vl, y_tr, y_vl, clf, y_pred_train    \n",
    "    gc.collect()\n",
    "    print(f'Mean ROC_AUC: {score_mean / EPOCHS} \\n')\n",
    "    return -(score_mean / EPOCHS)\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 7, 24, 1),\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.9),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.1, 1.0),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.01),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 0.8),\n",
    "    'num_leaves': hp.choice('num_leaves', list(range(20, 300, 20))),       \n",
    "    'min_child_samples': hp.choice('min_child_samples', list(range(10, 80, 3))),\n",
    "    'feature_fraction': hp.choice('feature_fraction', [.5, .6, .7, .8, .9]),\n",
    "    'bagging_fraction': hp.choice('bagging_fraction', [.5, .6, .7, .8, .9])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'bagging_fraction': 0.9, 'colsample_bytree': 0.4378309249475988, 'feature_fraction': 0.8, 'gamma': 0.5942504733210476, 'learning_rate': 0.009489092224723203, 'max_depth': 22.0, 'min_child_samples': 31, 'num_leaves': 80, 'reg_alpha': 0.26381255542215887, 'reg_lambda': 0.3816239750315529}\n",
      "CV SCORE: \n",
      "ROC AUC 0.9006447594815646\n",
      "ROC AUC 0.914669305090494\n",
      "ROC AUC 0.9101905792356325\n",
      "ROC AUC 0.9324018824229795\n",
      "ROC AUC 0.9318381766839439\n",
      "  0%|          | 0/40 [33:45<?, ?it/s, best loss: ?]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'clf' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4b42fa0d3c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             max_evals=40)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    406\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    407\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-630a1302779d>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'ROC AUC {score}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mdel\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_vl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Mean ROC_AUC: {score_mean / EPOCHS} \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'clf' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Set algoritm parameters\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=40)\n",
    "\n",
    "# Print best parameters\n",
    "# best_params = space_eval(space, best)\n",
    "\n",
    "print(\"BEST PARAMS: \", best)\n",
    "\n",
    "best['max_depth'] = int(best['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-e00f5ad1946f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;34m**\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtree_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpu_hist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=2000,\n",
    "    \n",
    "    **best,early_stopping_rounds=50,\n",
    "    tree_method='gpu_hist'\n",
    ")\n",
    "#num_boost_round\n",
    "clf.fit(X_train, y_train,eval_metric = 'auc',early_stopping_rounds=50)\n",
    "\n",
    "y_preds = clf.predict_proba(X_test)[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f2d7d45dae57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot log loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "results = clf.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot log loss\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "ax.legend()\n",
    "pyplot.ylabel('Log Loss')\n",
    "pyplot.title('XGBoost Log Loss')\n",
    "pyplot.show()\n",
    "# plot classification error\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "ax.legend()\n",
    "pyplot.ylabel('Classification Error')\n",
    "pyplot.title('XGBoost Classification Error')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-ad216b981f71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_important\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_important\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_important\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_important = clf.get_booster().get_score(importance_type=\"weight\")\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "\n",
    "# Top 10 features\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-67397b183377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isFraud'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# sample_submission.to_csv('XGB_hypopt_model.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_preds' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_submission['isFraud'] = y_preds\n",
    "# sample_submission.to_csv('XGB_hypopt_model.csv')\n",
    "sample_submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0199b73e75074d47ab846836b733017e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_983f711127be433e86d3957f47a83ac6",
        "IPY_MODEL_22e1dba78df240879e18f7bfec777228"
       ],
       "layout": "IPY_MODEL_2cdf02f35e634a4eae72584aa62d2ae0"
      }
     },
     "0ad1388b721e40cc97e25a6e6f72529b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d63091c0b214333a6a92e8f0e4b91c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1a33d688444346e6ae0f8d5c56daf2de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "22e1dba78df240879e18f7bfec777228": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ad1388b721e40cc97e25a6e6f72529b",
       "placeholder": "​",
       "style": "IPY_MODEL_1a33d688444346e6ae0f8d5c56daf2de",
       "value": "100% 452/452 [01:10&lt;00:00,  6.42it/s]"
      }
     },
     "2cdf02f35e634a4eae72584aa62d2ae0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "951b123ce6b74f3a91927679446b4fb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "983f711127be433e86d3957f47a83ac6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_951b123ce6b74f3a91927679446b4fb9",
       "max": 452,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0d63091c0b214333a6a92e8f0e4b91c4",
       "value": 452
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
