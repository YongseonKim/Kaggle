{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseriessplit 0.01 컬럼추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_identity.csv', 'sample_submission.csv', 'train_identity.csv', 'train_transaction.csv', 'test_transaction.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "# Standard plotly imports\n",
    "#import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "#import cufflinks\n",
    "#import cufflinks as cf\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Using plotly + cufflinks in offline mode\n",
    "init_notebook_mode(connected=True)\n",
    "#cufflinks.go_offline(connected=True)\n",
    "\n",
    "# Preprocessing, modelling and evaluating\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
    "# from xgboost import XGBClassifier\n",
    "# import xgboost as xgb\n",
    "\n",
    "## Hyperopt modules\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import gc\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 433)\n",
      "(590540, 433)\n"
     ]
    }
   ],
   "source": [
    "#modeling\n",
    "df_trans = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\n",
    "df_test_trans = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\n",
    "\n",
    "df_id = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\n",
    "df_test_id = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\n",
    "\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n",
    "\n",
    "df_train = df_trans.merge(df_id, how='left', left_index=True, right_index=True)\n",
    "df_test = df_test_trans.merge(df_test_id, how='left', left_index=True, right_index=True)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumetable(df):\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
    "    summary = summary.reset_index()\n",
    "    summary['Name'] = summary['index']\n",
    "    summary = summary[['Name','dtypes']]\n",
    "    summary['Missing'] = df.isnull().sum().values    \n",
    "    summary['Uniques'] = df.nunique().values\n",
    "    summary['First Value'] = df.loc[0].values\n",
    "    summary['Second Value'] = df.loc[1].values\n",
    "    summary['Third Value'] = df.loc[2].values\n",
    "\n",
    "    for name in summary['Name'].value_counts().index:\n",
    "        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n",
    "\n",
    "    return summary\n",
    "\n",
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def CalcOutliers(df_num): \n",
    "\n",
    "    # calculating mean and std of the array\n",
    "    data_mean, data_std = np.mean(df_num), np.std(df_num)\n",
    "\n",
    "    # seting the cut line to both higher and lower values\n",
    "    # You can change this value\n",
    "    cut = data_std * 3\n",
    "\n",
    "    #Calculating the higher and lower cut values\n",
    "    lower, upper = data_mean - cut, data_mean + cut\n",
    "\n",
    "    # creating an array of lower, higher and total outlier values \n",
    "    outliers_lower = [x for x in df_num if x < lower]\n",
    "    outliers_higher = [x for x in df_num if x > upper]\n",
    "    outliers_total = [x for x in df_num if x < lower or x > upper]\n",
    "\n",
    "    # array without outlier values\n",
    "    outliers_removed = [x for x in df_num if x > lower and x < upper]\n",
    "    \n",
    "    print('Identified lowest outliers: %d' % len(outliers_lower)) # printing total number of values in lower cut of outliers\n",
    "    print('Identified upper outliers: %d' % len(outliers_higher)) # printing total number of values in higher cut of outliers\n",
    "    print('Total outlier observations: %d' % len(outliers_total)) # printing total number of values outliers of both sides\n",
    "    print('Non-outlier observations: %d' % len(outliers_removed)) # printing total number of non outlier values\n",
    "    print(\"Total percentual of Outliers: \", round((len(outliers_total) / len(outliers_removed) )*100, 4)) # Percentual of outliers in points\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 668.22 Mb (66.2% reduction)\n",
      "Mem. usage decreased to 583.43 Mb (65.6% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "START_DATE = '2017-12-01'\n",
    "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "df_train[\"Date\"] = df_train['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "df_train['_Weekdays'] = df_train['Date'].dt.dayofweek\n",
    "df_train['_Hours'] = df_train['Date'].dt.hour\n",
    "df_train['_Days'] = df_train['Date'].dt.day\n",
    "\n",
    "START_DATE_test = '2018-06-01'\n",
    "startdate = datetime.datetime.strptime(START_DATE_test, \"%Y-%m-%d\")\n",
    "df_test[\"Date\"] = df_test['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "df_test['_Weekdays'] = df_test['Date'].dt.dayofweek\n",
    "df_test['_Hours'] = df_test['Date'].dt.hour\n",
    "df_test['_Days'] = df_test['Date'].dt.day\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corret_card_id(x): \n",
    "    x=x.replace('.0','')\n",
    "    x=x.replace('-999','nan')\n",
    "    return x\n",
    "\n",
    "def definie_indexes(df):\n",
    "    # create card ID \n",
    "    cards_cols= ['card1', 'card2', 'card3', 'card5']\n",
    "    for card in cards_cols: \n",
    "        if '1' in card: \n",
    "            df['Card_ID']= df[card].map(str)\n",
    "        else : \n",
    "            df['Card_ID']+= ' '+df[card].map(str)\n",
    "    \n",
    "    # sort train data by Card_ID and then by transaction date \n",
    "    df= df.sort_values(['Card_ID', 'Date'], ascending=[True, True])\n",
    "    \n",
    "    # small correction of the Card_ID\n",
    "    df['Card_ID']=df['Card_ID'].apply(corret_card_id)\n",
    "    \n",
    "    # set indexes \n",
    "    # df= df.set_index(['Card_ID', 'Date'])\n",
    "    return df\n",
    "\n",
    "df_train = definie_indexes(df_train)\n",
    "df_test = definie_indexes(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### M columns (except M4)\n",
    "# All these columns are binary encoded 1/0\n",
    "# We can have some features from it\n",
    "i_cols = ['M1','M2','M3','M5','M6','M7','M8','M9']\n",
    "\n",
    "df_train['M_sum'] = df_train[i_cols].sum(axis=1).astype(np.int8)\n",
    "df_test['M_sum']  = df_test[i_cols].sum(axis=1).astype(np.int8)\n",
    "\n",
    "df_train['M_na'] = df_train[i_cols].isna().sum(axis=1).astype(np.int8)\n",
    "df_test['M_na']  = df_test[i_cols].isna().sum(axis=1).astype(np.int8)\n",
    "\n",
    "df_train['M_type'] = ''\n",
    "df_test['M_type']  = ''\n",
    "\n",
    "for col in i_cols:\n",
    "    df_train['M_type'] = '_'+df_train[col].astype(str)\n",
    "    df_test['M_type'] = '_'+df_test[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### C columns\n",
    "# C columns are some counts, based on client identity\n",
    "# Most popular Value is \"1\" -> that seems to be just a single match \n",
    "# (New or stable client)\n",
    "# You can check that auc score for that cliens are lower than global\n",
    "# Lets encode such client types\n",
    "\n",
    "i_cols = ['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14']\n",
    "\n",
    "df_train['C_sum'] = 0\n",
    "df_test['C_sum']  = 0\n",
    "\n",
    "df_train['C_null'] = 0\n",
    "df_test['C_null']  = 0\n",
    "\n",
    "for col in i_cols:\n",
    "    df_train['C_sum'] += np.where(df_train[col]==1,1,0)\n",
    "    df_test['C_sum']  += np.where(df_test[col]==1,1,0)\n",
    "\n",
    "    df_train['C_null'] += np.where(df_train[col]==0,1,0)\n",
    "    df_test['C_null']  += np.where(df_test[col]==0,1,0)\n",
    "    \n",
    "    valid_values = df_train[col].value_counts()\n",
    "    valid_values = valid_values[valid_values>1000]\n",
    "    valid_values = list(valid_values.index)\n",
    "    \n",
    "    df_train[col+'_valid'] = np.where(df_train[col].isin(valid_values),1,0)\n",
    "    df_test[col+'_valid']  = np.where(df_test[col].isin(valid_values),1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################### Reset values for \"noise\" card1\n",
    "# valid_card = df_train['card1'].value_counts()\n",
    "# valid_card = valid_card[valid_card>10]\n",
    "# valid_card = list(valid_card.index)\n",
    "    \n",
    "# df_train['card1'] = np.where(df_train['card1'].isin(valid_card), df_train['card1'], np.nan)\n",
    "# df_test['card1']  = np.where(df_test['card1'].isin(valid_card), df_test['card1'], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Device info\n",
    "df_train['DeviceInfo'] = df_train['DeviceInfo'].fillna('unknown_device').str.lower()\n",
    "df_test['DeviceInfo'] = df_test['DeviceInfo'].fillna('unknown_device').str.lower()\n",
    "\n",
    "df_train['DeviceInfo_c'] = df_train['DeviceInfo']\n",
    "df_test['DeviceInfo_c'] = df_test['DeviceInfo']\n",
    "\n",
    "device_match_dict = {\n",
    "    'sm':'sm-',\n",
    "    'sm':'samsung',\n",
    "    'huawei':'huawei',\n",
    "    'moto':'moto',\n",
    "    'rv':'rv:',\n",
    "    'trident':'trident',\n",
    "    'lg':'lg-',\n",
    "    'htc':'htc',\n",
    "    'blade':'blade',\n",
    "    'windows':'windows',\n",
    "    'lenovo':'lenovo',\n",
    "    'linux':'linux',\n",
    "    'f3':'f3',\n",
    "    'f5':'f5'\n",
    "}\n",
    "for dev_type_s, dev_type_o in device_match_dict.items():\n",
    "    df_train['DeviceInfo_c'] = df_train['DeviceInfo_c'].apply(lambda x: dev_type_s if dev_type_o in x else x)\n",
    "    df_test['DeviceInfo_c'] = df_test['DeviceInfo_c'].apply(lambda x: dev_type_s if dev_type_o in x else x)\n",
    "\n",
    "df_train['DeviceInfo_c'] = df_train['DeviceInfo_c'].apply(lambda x: 'other_d_type' if x not in device_match_dict else x)\n",
    "df_test['DeviceInfo_c'] = df_test['DeviceInfo_c'].apply(lambda x: 'other_d_type' if x not in device_match_dict else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n",
    "\n",
    "df_train.loc[df_train['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n",
    "                                             'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n",
    "                                             'yahoo.es']), 'R_emaildomain'] = 'Yahoo Mail'\n",
    "df_train.loc[df_train['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n",
    "                                             'hotmail.es','hotmail.co.uk', 'hotmail.de',\n",
    "                                             'outlook.es', 'live.com', 'live.fr',\n",
    "                                             'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\n",
    "df_train.loc[df_train.R_emaildomain.isin(df_train.R_emaildomain\\\n",
    "                                         .value_counts()[df_train.R_emaildomain.value_counts() <= 300 ]\\\n",
    "                                         .index), 'R_emaildomain'] = \"Others\"\n",
    "df_train.R_emaildomain.fillna(\"NoInf\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n",
    "\n",
    "df_test.loc[df_test['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n",
    "                                             'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n",
    "                                             'yahoo.es']), 'R_emaildomain'] = 'Yahoo Mail'\n",
    "df_test.loc[df_test['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n",
    "                                             'hotmail.es','hotmail.co.uk', 'hotmail.de',\n",
    "                                             'outlook.es', 'live.com', 'live.fr',\n",
    "                                             'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\n",
    "df_test.loc[df_test.R_emaildomain.isin(df_test.R_emaildomain\\\n",
    "                                         .value_counts()[df_test.R_emaildomain.value_counts() <= 300 ]\\\n",
    "                                         .index), 'R_emaildomain'] = \"Others\"\n",
    "df_test.R_emaildomain.fillna(\"NoInf\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\n",
    "df_train.loc[df_train['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\n",
    "df_train.loc[df_train['id_30'].str.contains('Mac OS', na=False), 'id_30'] = 'Mac'\n",
    "df_train.loc[df_train['id_30'].str.contains('Android', na=False), 'id_30'] = 'Android'\n",
    "df_train['id_30'].fillna(\"NAN\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\n",
    "df_test.loc[df_test['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\n",
    "df_test.loc[df_test['id_30'].str.contains('Mac OS', na=False), 'id_30'] = 'Mac'\n",
    "df_test.loc[df_test['id_30'].str.contains('Android', na=False), 'id_30'] = 'Android'\n",
    "df_test['id_30'].fillna(\"NAN\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['id_31'].str.contains('chrome', na=False), 'id_31'] = 'Chrome'\n",
    "df_train.loc[df_train['id_31'].str.contains('firefox', na=False), 'id_31'] = 'Firefox'\n",
    "df_train.loc[df_train['id_31'].str.contains('safari', na=False), 'id_31'] = 'Safari'\n",
    "df_train.loc[df_train['id_31'].str.contains('edge', na=False), 'id_31'] = 'Edge'\n",
    "df_train.loc[df_train['id_31'].str.contains('ie', na=False), 'id_31'] = 'IE'\n",
    "df_train.loc[df_train['id_31'].str.contains('samsung', na=False), 'id_31'] = 'Samsung'\n",
    "df_train.loc[df_train['id_31'].str.contains('opera', na=False), 'id_31'] = 'Opera'\n",
    "df_train['id_31'].fillna(\"NAN\", inplace=True)\n",
    "df_train.loc[df_train.id_31.isin(df_train.id_31.value_counts()[df_train.id_31.value_counts() < 200].index), 'id_31'] = \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['id_31'].str.contains('chrome', na=False), 'id_31'] = 'Chrome'\n",
    "df_test.loc[df_test['id_31'].str.contains('firefox', na=False), 'id_31'] = 'Firefox'\n",
    "df_test.loc[df_test['id_31'].str.contains('safari', na=False), 'id_31'] = 'Safari'\n",
    "df_test.loc[df_test['id_31'].str.contains('edge', na=False), 'id_31'] = 'Edge'\n",
    "df_test.loc[df_test['id_31'].str.contains('ie', na=False), 'id_31'] = 'IE'\n",
    "df_test.loc[df_test['id_31'].str.contains('samsung', na=False), 'id_31'] = 'Samsung'\n",
    "df_test.loc[df_test['id_31'].str.contains('opera', na=False), 'id_31'] = 'Opera'\n",
    "df_test['id_31'].fillna(\"NAN\", inplace=True)\n",
    "df_test.loc[df_test.id_31.isin(df_test.id_31.value_counts()[df_test.id_31.value_counts() < 200].index), 'id_31'] = \"Others\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_interaction(df, feature_1, feature_2):\n",
    "    return df[feature_1].astype(str) + '_' + df[feature_2].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://www.kaggle.com/nroman/lgb-single-model-lb-0-9419\n",
    "\n",
    "features_interactions = [\n",
    "    'id_02__id_20',\n",
    "    'id_02__D8',\n",
    "    'D11__DeviceInfo',\n",
    "    'DeviceInfo__P_emaildomain',\n",
    "    'P_emaildomain__C2',\n",
    "    'card2__dist1',\n",
    "    'card1__card5',\n",
    "    'card2__id_20',\n",
    "    'card5__P_emaildomain',\n",
    "    'addr1__card1'\n",
    "]\n",
    "\n",
    "for new_feature in features_interactions:\n",
    "    feature_1, feature_2 = new_feature.split('__')\n",
    "    \n",
    "    df_train[new_feature] = features_interaction(df_train, feature_1, feature_2)\n",
    "    df_test[new_feature] = features_interaction(df_test, feature_1, feature_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['count_last'] = df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).count())\n",
    "df_train['mean_last'] = df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).mean())\n",
    "df_train['min_last'] = df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).min())\n",
    "df_train['max_last'] = df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).max())\n",
    "df_train['std_last'] = df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).std())\n",
    "df_test['count_last'] = df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).count())\n",
    "df_test['mean_last'] = df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).mean())\n",
    "df_test['min_last'] = df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).min())\n",
    "df_test['max_last'] = df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).max())\n",
    "df_test['std_last'] = df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).std())\n",
    "df_train['trans_mean_last'] = df_train['TransactionAmt'] / df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).mean())\n",
    "df_train['trans_std_last'] = df_train['TransactionAmt'] / df_train.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).std())\n",
    "df_test['trans_mean_last'] = df_test['TransactionAmt'] / df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).mean())\n",
    "df_test['trans_std_last'] = df_test['TransactionAmt'] / df_test.groupby('Card_ID')['TransactionAmt'].transform(lambda x: x.rolling(10, 1).std())\n",
    "df_train['TransactionAmt_to_mean_card_id'] = df_train['TransactionAmt'] - df_train.groupby(['Card_ID'])['TransactionAmt'].transform('mean')\n",
    "df_train['TransactionAmt_to_std_card_id'] = df_train['TransactionAmt_to_mean_card_id'] / df_train.groupby(['Card_ID'])['TransactionAmt'].transform('std')\n",
    "df_test['TransactionAmt_to_mean_card_id'] = df_test['TransactionAmt'] - df_test.groupby(['Card_ID'])['TransactionAmt'].transform('mean')\n",
    "df_test['TransactionAmt_to_std_card_id'] = df_test['TransactionAmt_to_mean_card_id'] / df_test.groupby(['Card_ID'])['TransactionAmt'].transform('std')\n",
    "df_train['id_02_to_mean_card_id'] = df_train['id_02'] / df_train.groupby(['Card_ID'])['id_02'].transform('mean')\n",
    "df_train['id_02_to_std_card_id'] = df_train['id_02'] / df_train.groupby(['Card_ID'])['id_02'].transform('std')\n",
    "df_test['id_02_to_mean_card_id'] = df_test['id_02'] / df_test.groupby(['Card_ID'])['id_02'].transform('mean')\n",
    "df_test['id_02_to_std_card_id'] = df_test['id_02'] / df_test.groupby(['Card_ID'])['id_02'].transform('std')\n",
    "df_train['D15_to_mean_card_id'] = df_train['D15'] / df_train.groupby(['Card_ID'])['D15'].transform('mean')\n",
    "df_train['D15_to_std_card_id'] = df_train['D15'] / df_train.groupby(['Card_ID'])['D15'].transform('std')\n",
    "df_test['D15_to_mean_card_id'] = df_test['D15'] / df_test.groupby(['Card_ID'])['D15'].transform('mean')\n",
    "df_test['D15_to_std_card_id'] = df_test['D15'] / df_test.groupby(['Card_ID'])['D15'].transform('std')\n",
    "df_train['D15_to_mean_addr1'] = df_train['D15'] / df_train.groupby(['addr1'])['D15'].transform('mean')\n",
    "df_train['D15_to_std_addr1'] = df_train['D15'] / df_train.groupby(['addr1'])['D15'].transform('std')\n",
    "df_test['D15_to_mean_addr1'] = df_test['D15'] / df_test.groupby(['addr1'])['D15'].transform('mean')\n",
    "df_test['D15_to_std_addr1'] = df_test['D15'] / df_test.groupby(['addr1'])['D15'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['card1_count_full'] = df_train['card1'].map(pd.concat([df_train['card1'], df_test['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card1_count_full'] = df_test['card1'].map(pd.concat([df_train['card1'], df_test['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "\n",
    "df_train['card2_count_full'] = df_train['card2'].map(pd.concat([df_train['card2'], df_test['card2']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card2_count_full'] = df_test['card2'].map(pd.concat([df_train['card2'], df_test['card2']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "df_train['card3_count_full'] = df_train['card3'].map(pd.concat([df_train['card3'], df_test['card3']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card3_count_full'] = df_test['card3'].map(pd.concat([df_train['card3'], df_test['card3']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "df_train['card4_count_full'] = df_train['card4'].map(pd.concat([df_train['card4'], df_test['card4']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card4_count_full'] = df_test['card4'].map(pd.concat([df_train['card4'], df_test['card4']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "df_train['card5_count_full'] = df_train['card5'].map(pd.concat([df_train['card5'], df_test['card5']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card5_count_full'] = df_test['card5'].map(pd.concat([df_train['card5'], df_test['card5']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "df_train['card6_count_full'] = df_train['card6'].map(pd.concat([df_train['card6'], df_test['card6']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['card6_count_full'] = df_test['card6'].map(pd.concat([df_train['card6'], df_test['card6']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "\n",
    "df_train['addr1_count_full'] = df_train['addr1'].map(pd.concat([df_train['addr1'], df_test['addr1']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['addr1_count_full'] = df_test['addr1'].map(pd.concat([df_train['addr1'], df_test['addr1']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "df_train['addr2_count_full'] = df_train['addr2'].map(pd.concat([df_train['addr2'], df_test['addr2']], ignore_index=True).value_counts(dropna=False))\n",
    "df_test['addr2_count_full'] = df_test['addr2'].map(pd.concat([df_train['addr2'], df_test['addr2']], ignore_index=True).value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['id_34', 'id_36']:\n",
    "    # Count encoded for both df_train and df_test\n",
    "    df_train[feature + '_count_full'] = df_train[feature].map(pd.concat([df_train[feature], df_test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "    df_test[feature + '_count_full'] = df_test[feature].map(pd.concat([df_train[feature], df_test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "        \n",
    "for feature in ['id_01', 'id_31', 'id_33', 'id_35', 'id_36']:\n",
    "    # Count encoded separately for df_train and df_test\n",
    "    df_train[feature + '_count_dist'] = df_train[feature].map(df_train[feature].value_counts(dropna=False))\n",
    "    df_test[feature + '_count_dist'] = df_test[feature].map(df_test[feature].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['P_isproton']=(df_train['P_emaildomain']=='protonmail.com')\n",
    "df_train['R_isproton']=(df_train['R_emaildomain']=='protonmail.com')\n",
    "df_test['P_isproton']=(df_test['P_emaildomain']=='protonmail.com')\n",
    "df_test['R_isproton']=(df_test['R_emaildomain']=='protonmail.com')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(df_train.shape[0])\n",
    "df_train[\"lasdf_test_browser\"] = a\n",
    "a = np.zeros(df_test.shape[0])\n",
    "df_test[\"lasdf_test_browser\"] = a\n",
    "def setbrowser(df):\n",
    "    df.loc[df[\"id_31\"]==\"samsung browser 7.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"opera 53.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"mobile safari 10.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"google search application 49.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"firefox 60.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"edge 17.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 69.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 67.0 for android\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 63.0 for android\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 63.0 for ios\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 64.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 64.0 for android\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 64.0 for ios\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 65.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 65.0 for android\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 65.0 for ios\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 66.0\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 66.0 for android\",'lasdf_test_browser']=1\n",
    "    df.loc[df[\"id_31\"]==\"chrome 66.0 for ios\",'lasdf_test_browser']=1\n",
    "    return df\n",
    "df_train=setbrowser(df_train)\n",
    "df_test=setbrowser(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TransactionAmt_decimal'] = ((df_train['TransactionAmt'] - df_train['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "df_test['TransactionAmt_decimal'] = ((df_test['TransactionAmt'] - df_test['TransactionAmt'].astype(int)) * 1000).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Freq encoding\n",
    "i_cols = ['card1','card2','card3','card5',\n",
    "          'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "          'D1','D2','D3','D4','D5','D6','D7','D8','D9',\n",
    "          'addr1','addr2',\n",
    "          'dist1','dist2',\n",
    "          'P_emaildomain', 'R_emaildomain',\n",
    "          'id_01','id_02','id_03','id_04','id_05','id_06','id_07','id_08','id_09','id_10',\n",
    "          'id_11','id_13','id_14','id_17','id_18','id_19','id_20','id_21','id_22','id_24',\n",
    "          'id_25','id_26','id_30','id_31','id_32','id_33',#'id_33_0','id_33_1',\n",
    "          'DeviceInfo','DeviceInfo_c',#'id_30_c','id_30_v','id_31_v',\n",
    "         ]\n",
    "\n",
    "for col in i_cols:\n",
    "    temp_df = pd.concat([df_train[[col]], df_test[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()   \n",
    "    df_train[col+'_fq_enc'] = df_train[col].map(fq_encode)\n",
    "    df_test[col+'_fq_enc']  = df_test[col].map(fq_encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_value_cols = [col for col in df_train.columns if df_train[col].nunique() <= 1]\n",
    "one_value_cols_test = [col for col in df_test.columns if df_test[col].nunique() <= 1]\n",
    "one_value_cols == one_value_cols_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_null_cols = [col for col in df_train.columns if df_train[col].isnull().sum() / df_train.shape[0] > 0.9]\n",
    "many_null_cols_test = [col for col in df_test.columns if df_test[col].isnull().sum() / df_test.shape[0] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_top_value_cols = [col for col in df_train.columns if df_train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "big_top_value_cols_test = [col for col in df_test.columns if df_test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 ['V116', 'C3_valid', 'C4_valid', 'V102', 'id_23', 'V123', 'V24', 'C3', 'C3_fq_enc', 'V305', 'V25', 'V129', 'V105', 'V298', 'V120', 'id_07', 'id_18_fq_enc', 'V26', 'lasdf_test_browser', 'id_22', 'V137', 'C11_valid', 'C13_valid', 'V65', 'V111', 'V115', 'V136', 'R_isproton', 'V117', 'V301', 'P_isproton', 'V106', 'M_sum', 'C8_valid', 'V297', 'V299', 'C6_valid', 'C2_valid', 'id_26', 'V114', 'V28', 'V109', 'V135', 'V110', 'V121', 'V112', 'V311', 'C7_valid', 'V316', 'V125', 'V281', 'V89', 'V295', 'id_08', 'id_22_fq_enc', 'id_07_fq_enc', 'V86', 'V284', 'V68', 'id_08_fq_enc', 'id_24', 'V119', 'V133', 'V309', 'V55', 'C9_valid', 'V14', 'V88', 'V321', 'V98', 'V107', 'V103', 'dist2_fq_enc', 'D7_fq_enc', 'V77', 'V118', 'V286', 'V134', 'id_25', 'V101', 'id_21_fq_enc', 'V27', 'id_26_fq_enc', 'V318', 'V320', 'V104', 'id_18', 'V132', 'V113', 'V319', 'V67', 'isFraud', 'C12_valid', 'C14_valid', 'dist2', 'C1_valid', 'V122', 'V293', 'V300', 'C5_valid', 'V108', 'V290', 'id_27', 'V23', 'id_21', 'D7', 'id_25_fq_enc', 'V296', 'V66', 'C10_valid', 'id_24_fq_enc', 'V124']\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = list(set(many_null_cols + many_null_cols_test +\n",
    "                        big_top_value_cols +\n",
    "                        big_top_value_cols_test +\n",
    "                        one_value_cols+ one_value_cols_test))\n",
    "len(cols_to_drop)\n",
    "print(len(cols_to_drop),cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop.remove('isFraud')\n",
    "\n",
    "df_train = df_train.drop(cols_to_drop, axis=1)\n",
    "df_test = df_test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n",
    "#             'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n",
    "#             'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9', 'Card_ID','id_02__id_20', 'id_02__D8', \n",
    "#             'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', 'card2__dist1', 'card1__card5', 'card2__id_20',\n",
    "#             'card5__P_emaildomain', 'addr1__card1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42de25ccde847c89d5ebcf9316cf491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=452), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# categorical features encoding\n",
    "from tqdm import tqdm_notebook\n",
    "# for col in cat_cols:\n",
    "#     if col in df_train.columns:\n",
    "#         le = preprocessing.LabelEncoder()\n",
    "#         le.fit(list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values))\n",
    "#         df_train[col] = le.transform(list(df_train[col].astype(str).values))\n",
    "#         df_test[col] = le.transform(list(df_test[col].astype(str).values))   \n",
    "\n",
    "for col in tqdm_notebook(df_train.columns):\n",
    "    if df_train[col].dtype == 'object':\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values))\n",
    "        df_train[col] = le.transform(list(df_train[col].astype(str).values))\n",
    "        df_test[col] = le.transform(list(df_test[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 다중공선성 제거\n",
    "\n",
    "# threshold = 0.98\n",
    "    \n",
    "# # Absolute value correlation matrix\n",
    "# corr_matrix = df_train[df_train['isFraud'].notnull()].corr().abs()\n",
    "\n",
    "# # Getting the upper triangle of correlations\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# # Select columns with correlations above threshold\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "# print('There are %d columns to remove.' % (len(to_drop)))\n",
    "# df_train = df_train.drop(columns = to_drop)\n",
    "# df_test = df_test.drop(columns = to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['isFraud', 'TransactionDT', 'Date'], axis=1)#df_train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'Date'], axis=1)\n",
    "Y_train = df_train['isFraud']#df_train.sort_values('TransactionDT')['isFraud']\n",
    "X_test = df_test.drop(['TransactionDT','Date'], axis=1)#df_test.sort_values('TransactionDT').drop(['TransactionDT','Date'], axis=1)\n",
    "del df_train\n",
    "df_test = df_test[[\"TransactionDT\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 604.30 Mb (35.2% reduction)\n",
      "Mem. usage decreased to 529.12 Mb (34.5% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 449)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter 찾기\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# scaled_x_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_train, x_train_valid, y_train_train, y_train_valid = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "# del scaled_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_train = lgb.Dataset(data=x_train_train.astype('float32'), label=y_train_train.astype('float32'))\n",
    "# lgb_valid = lgb.Dataset(data=x_train_valid.astype('float32'), label=y_train_valid.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | learni... | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'learning_rate': 0.005820760396195786, 'num_iterations': 1000, 'num_leaves': 332, 'min_data_in_leaf': 0, 'max_depth': 3, 'bagging_fraction': 0.17536593150674396, 'feature_fraction': 0.40015566323110086, 'lambda_l1': 0.8593557450886471, 'lambda_l2': 0.10568683531908452, 'min_child_weight': 0.036715112080303196, 'bagging_seed': 11, 'verbose': -1, 'seed': 105}\n",
      "[500]\tvalid_0's auc: 0.850092\n",
      "[1000]\tvalid_0's auc: 0.854833\n",
      "Fold :  0 train_auc :  0.8918011992958857 val_auc :  0.8548328230574298\n",
      "[500]\tvalid_0's auc: 0.863007\n",
      "[1000]\tvalid_0's auc: 0.856532\n",
      "Fold :  1 train_auc :  0.8856513149015741 val_auc :  0.8565323151132747\n",
      "[500]\tvalid_0's auc: 0.641596\n",
      "[1000]\tvalid_0's auc: 0.613201\n",
      "Fold :  2 train_auc :  0.889840119188222 val_auc :  0.6132009701339224\n",
      "[500]\tvalid_0's auc: 0.849975\n",
      "[1000]\tvalid_0's auc: 0.82894\n",
      "Fold :  3 train_auc :  0.8910956803994893 val_auc :  0.8289398914564703\n",
      "[500]\tvalid_0's auc: 0.731241\n",
      "[1000]\tvalid_0's auc: 0.770837\n",
      "Fold :  4 train_auc :  0.888137187096692 val_auc :  0.7708372341805737\n",
      "                                           parameter     score\n",
      "0  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.784869\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7849  \u001b[0m | \u001b[0m 0.1754  \u001b[0m | \u001b[0m 0.4002  \u001b[0m | \u001b[0m 0.8594  \u001b[0m | \u001b[0m 0.1057  \u001b[0m | \u001b[0m 0.005821\u001b[0m | \u001b[0m 3.522   \u001b[0m | \u001b[0m 0.03672 \u001b[0m | \u001b[0m 0.449   \u001b[0m | \u001b[0m 332.8   \u001b[0m |\n",
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'learning_rate': 0.0016317845761595357, 'num_iterations': 1000, 'num_leaves': 490, 'min_data_in_leaf': 163, 'max_depth': 37, 'bagging_fraction': 0.8952576456958836, 'feature_fraction': 0.6193518402001765, 'lambda_l1': 0.24887771881659537, 'lambda_l2': 0.3415530541569666, 'min_child_weight': 0.05729353553013524, 'bagging_seed': 11, 'verbose': -1, 'seed': 105}\n",
      "[500]\tvalid_0's auc: 0.861892\n",
      "[1000]\tvalid_0's auc: 0.85777\n",
      "Fold :  0 train_auc :  0.9695042041510076 val_auc :  0.8577696416228217\n",
      "[500]\tvalid_0's auc: 0.88398\n",
      "[1000]\tvalid_0's auc: 0.885196\n",
      "Fold :  1 train_auc :  0.9667809754543709 val_auc :  0.8851956351009564\n",
      "[500]\tvalid_0's auc: 0.694288\n",
      "[1000]\tvalid_0's auc: 0.696738\n",
      "Fold :  2 train_auc :  0.9683755701118976 val_auc :  0.6967381122956711\n",
      "[500]\tvalid_0's auc: 0.862049\n",
      "[1000]\tvalid_0's auc: 0.859859\n",
      "Fold :  3 train_auc :  0.9673102784838234 val_auc :  0.8598590811192908\n",
      "[500]\tvalid_0's auc: 0.605778\n",
      "[1000]\tvalid_0's auc: 0.697714\n",
      "Fold :  4 train_auc :  0.9685775924586304 val_auc :  0.6977135701919992\n",
      "                                           parameter     score\n",
      "0  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.784869\n",
      "1  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.799455\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7995  \u001b[0m | \u001b[95m 0.8953  \u001b[0m | \u001b[95m 0.6194  \u001b[0m | \u001b[95m 0.2489  \u001b[0m | \u001b[95m 0.3416  \u001b[0m | \u001b[95m 0.001632\u001b[0m | \u001b[95m 37.23   \u001b[0m | \u001b[95m 0.05729 \u001b[0m | \u001b[95m 163.8   \u001b[0m | \u001b[95m 490.2   \u001b[0m |\n",
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'learning_rate': 0.0024934382049881425, 'num_iterations': 1000, 'num_leaves': 397, 'min_data_in_leaf': 179, 'max_depth': 6, 'bagging_fraction': 0.6678704098072986, 'feature_fraction': 0.43335022006969603, 'lambda_l1': 0.5361085251544213, 'lambda_l2': 0.1731619728199083, 'min_child_weight': 0.03932675923311867, 'bagging_seed': 11, 'verbose': -1, 'seed': 105}\n",
      "[500]\tvalid_0's auc: 0.855054\n",
      "[1000]\tvalid_0's auc: 0.858912\n",
      "Fold :  0 train_auc :  0.9112070608620807 val_auc :  0.8589123586678913\n",
      "[500]\tvalid_0's auc: 0.866358\n",
      "[1000]\tvalid_0's auc: 0.87503\n",
      "Fold :  1 train_auc :  0.9059921497693365 val_auc :  0.875030291077448\n",
      "[500]\tvalid_0's auc: 0.714135\n",
      "[1000]\tvalid_0's auc: 0.707026\n",
      "Fold :  2 train_auc :  0.9070961499210769 val_auc :  0.7070260228197687\n",
      "[500]\tvalid_0's auc: 0.85926\n",
      "[1000]\tvalid_0's auc: 0.852532\n",
      "Fold :  3 train_auc :  0.9094328226143814 val_auc :  0.8525318301702938\n",
      "[500]\tvalid_0's auc: 0.728833\n",
      "[1000]\tvalid_0's auc: 0.785218\n",
      "Fold :  4 train_auc :  0.9071332904316882 val_auc :  0.7852176380793754\n",
      "                                           parameter     score\n",
      "0  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.784869\n",
      "1  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.799455\n",
      "2  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.815744\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8157  \u001b[0m | \u001b[95m 0.6679  \u001b[0m | \u001b[95m 0.4334  \u001b[0m | \u001b[95m 0.5361  \u001b[0m | \u001b[95m 0.1732  \u001b[0m | \u001b[95m 0.002493\u001b[0m | \u001b[95m 6.843   \u001b[0m | \u001b[95m 0.03933 \u001b[0m | \u001b[95m 179.5   \u001b[0m | \u001b[95m 397.9   \u001b[0m |\n",
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'learning_rate': 0.008471256485497344, 'num_iterations': 1000, 'num_leaves': 36, 'min_data_in_leaf': 199, 'max_depth': 63, 'bagging_fraction': 0.5041156111071963, 'feature_fraction': 0.9969341441879197, 'lambda_l1': 0.13674730816747183, 'lambda_l2': 0.1916023751567525, 'min_child_weight': 0.0351671257558561, 'bagging_seed': 11, 'verbose': -1, 'seed': 105}\n",
      "[500]\tvalid_0's auc: 0.84841\n",
      "[1000]\tvalid_0's auc: 0.859058\n",
      "Fold :  0 train_auc :  0.9511091421469005 val_auc :  0.8590584846171936\n",
      "[500]\tvalid_0's auc: 0.833115\n",
      "[1000]\tvalid_0's auc: 0.802411\n",
      "Fold :  1 train_auc :  0.9471932257402977 val_auc :  0.8024107180204302\n",
      "[500]\tvalid_0's auc: 0.608332\n",
      "[1000]\tvalid_0's auc: 0.583558\n",
      "Fold :  2 train_auc :  0.9507800631833074 val_auc :  0.5835579559170628\n",
      "[500]\tvalid_0's auc: 0.802101\n",
      "[1000]\tvalid_0's auc: 0.783606\n",
      "Fold :  3 train_auc :  0.9510327019327289 val_auc :  0.7836060051211958\n",
      "[500]\tvalid_0's auc: 0.772185\n",
      "[1000]\tvalid_0's auc: 0.779317\n",
      "Fold :  4 train_auc :  0.9471811606971823 val_auc :  0.7793170397713362\n",
      "                                           parameter     score\n",
      "0  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.784869\n",
      "1  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.799455\n",
      "2  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.815744\n",
      "3  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.761590\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7616  \u001b[0m | \u001b[0m 0.5041  \u001b[0m | \u001b[0m 0.9969  \u001b[0m | \u001b[0m 0.1367  \u001b[0m | \u001b[0m 0.1916  \u001b[0m | \u001b[0m 0.008471\u001b[0m | \u001b[0m 63.82   \u001b[0m | \u001b[0m 0.03517 \u001b[0m | \u001b[0m 199.9   \u001b[0m | \u001b[0m 36.35   \u001b[0m |\n",
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'learning_rate': 0.004036940259462621, 'num_iterations': 1000, 'num_leaves': 691, 'min_data_in_leaf': 196, 'max_depth': 0, 'bagging_fraction': 0.6941436891701346, 'feature_fraction': 0.32856215695365615, 'lambda_l1': 0.8402731721589676, 'lambda_l2': 0.46004874112049143, 'min_child_weight': 0.07084201105608613, 'bagging_seed': 11, 'verbose': -1, 'seed': 105}\n",
      "[500]\tvalid_0's auc: 0.861868\n",
      "[1000]\tvalid_0's auc: 0.86011\n",
      "Fold :  0 train_auc :  0.9947619713390907 val_auc :  0.8601098178822897\n",
      "[500]\tvalid_0's auc: 0.883827\n",
      "[1000]\tvalid_0's auc: 0.867956\n",
      "Fold :  1 train_auc :  0.9947020791691207 val_auc :  0.8679560072592274\n",
      "[500]\tvalid_0's auc: 0.761853\n",
      "[1000]\tvalid_0's auc: 0.738034\n",
      "Fold :  2 train_auc :  0.9948960129439308 val_auc :  0.7380344646025254\n",
      "[500]\tvalid_0's auc: 0.853298\n",
      "[1000]\tvalid_0's auc: 0.815769\n",
      "Fold :  3 train_auc :  0.9949339628294414 val_auc :  0.8157687006563615\n",
      "[500]\tvalid_0's auc: 0.814493\n",
      "[1000]\tvalid_0's auc: 0.833556\n",
      "Fold :  4 train_auc :  0.9946926389857489 val_auc :  0.833555519363526\n",
      "                                           parameter     score\n",
      "0  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.784869\n",
      "1  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.799455\n",
      "2  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.815744\n",
      "3  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.761590\n",
      "4  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.823085\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.8231  \u001b[0m | \u001b[95m 0.6941  \u001b[0m | \u001b[95m 0.3286  \u001b[0m | \u001b[95m 0.8403  \u001b[0m | \u001b[95m 0.46    \u001b[0m | \u001b[95m 0.004037\u001b[0m | \u001b[95m 0.3982  \u001b[0m | \u001b[95m 0.07084 \u001b[0m | \u001b[95m 196.2   \u001b[0m | \u001b[95m 691.6   \u001b[0m |\n",
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'learning_rate': 0.009924310523252409, 'num_iterations': 1000, 'num_leaves': 497, 'min_data_in_leaf': 199, 'max_depth': 0, 'bagging_fraction': 0.6331450702841553, 'feature_fraction': 0.6573036033463057, 'lambda_l1': 0.21214415924505214, 'lambda_l2': 0.8879058652298129, 'min_child_weight': 0.04668222394235578, 'bagging_seed': 11, 'verbose': -1, 'seed': 105}\n",
      "[500]\tvalid_0's auc: 0.844757\n",
      "[1000]\tvalid_0's auc: 0.846531\n",
      "Fold :  0 train_auc :  0.9999231271690916 val_auc :  0.8465306244257771\n",
      "[500]\tvalid_0's auc: 0.847816\n",
      "[1000]\tvalid_0's auc: 0.841009\n",
      "Fold :  1 train_auc :  0.9999198628567368 val_auc :  0.8410089743276867\n",
      "[500]\tvalid_0's auc: 0.625189\n",
      "[1000]\tvalid_0's auc: 0.57455\n",
      "Fold :  2 train_auc :  0.9999332339450596 val_auc :  0.5745497776895839\n",
      "[500]\tvalid_0's auc: 0.794183\n",
      "[1000]\tvalid_0's auc: 0.782919\n",
      "Fold :  3 train_auc :  0.9999386394187537 val_auc :  0.7829190369909673\n",
      "[500]\tvalid_0's auc: 0.767624\n",
      "[1000]\tvalid_0's auc: 0.778649\n",
      "Fold :  4 train_auc :  0.9999281015255946 val_auc :  0.7786488243736474\n",
      "                                           parameter     score\n",
      "0  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.784869\n",
      "1  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.799455\n",
      "2  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.815744\n",
      "3  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.761590\n",
      "4  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.823085\n",
      "5  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.764731\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 0.6331  \u001b[0m | \u001b[0m 0.6573  \u001b[0m | \u001b[0m 0.2121  \u001b[0m | \u001b[0m 0.8879  \u001b[0m | \u001b[0m 0.009924\u001b[0m | \u001b[0m 0.9184  \u001b[0m | \u001b[0m 0.04668 \u001b[0m | \u001b[0m 199.1   \u001b[0m | \u001b[0m 497.5   \u001b[0m |\n",
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'learning_rate': 0.0010000000944051027, 'num_iterations': 1000, 'num_leaves': 700, 'min_data_in_leaf': 0, 'max_depth': -1, 'bagging_fraction': 0.1, 'feature_fraction': 0.10000000050179973, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'min_child_weight': 0.010000000944051027, 'bagging_seed': 11, 'verbose': -1, 'seed': 105}\n",
      "[500]\tvalid_0's auc: 0.865\n",
      "[1000]\tvalid_0's auc: 0.866419\n",
      "Fold :  0 train_auc :  0.9753988565403099 val_auc :  0.8664190869426481\n",
      "[500]\tvalid_0's auc: 0.876327\n",
      "[1000]\tvalid_0's auc: 0.878421\n",
      "Fold :  1 train_auc :  0.972635967244738 val_auc :  0.8784215925618138\n",
      "[500]\tvalid_0's auc: 0.758907\n",
      "[1000]\tvalid_0's auc: 0.769895\n",
      "Fold :  2 train_auc :  0.974743076689333 val_auc :  0.7698947652328025\n",
      "[500]\tvalid_0's auc: 0.838399\n",
      "[1000]\tvalid_0's auc: 0.836903\n",
      "Fold :  3 train_auc :  0.973675797543544 val_auc :  0.836903165063754\n",
      "[500]\tvalid_0's auc: 0.844029\n",
      "[1000]\tvalid_0's auc: 0.829427\n",
      "Fold :  4 train_auc :  0.9729334334288511 val_auc :  0.8294281027050523\n",
      "                                           parameter     score\n",
      "0  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.784869\n",
      "1  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.799455\n",
      "2  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.815744\n",
      "3  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.761590\n",
      "4  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.823085\n",
      "5  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.764731\n",
      "6  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.836213\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.8362  \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.001   \u001b[0m | \u001b[95m-1.0     \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 700.0   \u001b[0m |\n",
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'learning_rate': 0.0010000000055557534, 'num_iterations': 1000, 'num_leaves': 31, 'min_data_in_leaf': 0, 'max_depth': 70, 'bagging_fraction': 0.9999999999525592, 'feature_fraction': 0.1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'min_child_weight': 0.01, 'bagging_seed': 11, 'verbose': -1, 'seed': 105}\n",
      "[500]\tvalid_0's auc: 0.852837\n",
      "[1000]\tvalid_0's auc: 0.855324\n",
      "Fold :  0 train_auc :  0.8873920254545026 val_auc :  0.8553236089910116\n",
      "[500]\tvalid_0's auc: 0.858443\n",
      "[1000]\tvalid_0's auc: 0.86416\n",
      "Fold :  1 train_auc :  0.8809348047913944 val_auc :  0.8641600389305198\n",
      "[500]\tvalid_0's auc: 0.745788\n",
      "[1000]\tvalid_0's auc: 0.755173\n",
      "Fold :  2 train_auc :  0.8852285351876561 val_auc :  0.7551725238899378\n",
      "[500]\tvalid_0's auc: 0.84653\n",
      "[1000]\tvalid_0's auc: 0.849914\n",
      "Fold :  3 train_auc :  0.8840780300333688 val_auc :  0.8499138784235177\n",
      "[500]\tvalid_0's auc: 0.876856\n",
      "[1000]\tvalid_0's auc: 0.878038\n",
      "Fold :  4 train_auc :  0.8867157625878057 val_auc :  0.8780378821547413\n",
      "                                           parameter     score\n",
      "0  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.784869\n",
      "1  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.799455\n",
      "2  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.815744\n",
      "3  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.761590\n",
      "4  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.823085\n",
      "5  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.764731\n",
      "6  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.836213\n",
      "7  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.840522\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.8405  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.001   \u001b[0m | \u001b[95m 70.0    \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 31.0    \u001b[0m |\n",
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'learning_rate': 0.0024571629297077766, 'num_iterations': 1000, 'num_leaves': 398, 'min_data_in_leaf': 176, 'max_depth': 2, 'bagging_fraction': 0.9321024572106282, 'feature_fraction': 0.94183290615712, 'lambda_l1': 0.6836681687228664, 'lambda_l2': 0.5583452431145476, 'min_child_weight': 0.01699922000127199, 'bagging_seed': 11, 'verbose': -1, 'seed': 105}\n",
      "[500]\tvalid_0's auc: 0.831381\n",
      "[1000]\tvalid_0's auc: 0.841076\n",
      "Fold :  0 train_auc :  0.8626220333151392 val_auc :  0.8410758910943359\n",
      "[500]\tvalid_0's auc: 0.827778\n",
      "[1000]\tvalid_0's auc: 0.847911\n",
      "Fold :  1 train_auc :  0.8574182399925708 val_auc :  0.8479105465698323\n",
      "[500]\tvalid_0's auc: 0.7463\n",
      "[1000]\tvalid_0's auc: 0.708283\n",
      "Fold :  2 train_auc :  0.8584696131654769 val_auc :  0.7082833152366848\n",
      "[500]\tvalid_0's auc: 0.827297\n",
      "[1000]\tvalid_0's auc: 0.843275\n",
      "Fold :  3 train_auc :  0.8591916144872884 val_auc :  0.8432748208016779\n",
      "[500]\tvalid_0's auc: 0.797671\n",
      "[1000]\tvalid_0's auc: 0.831178\n",
      "Fold :  4 train_auc :  0.8646637414897311 val_auc :  0.8311784642655496\n",
      "                                           parameter     score\n",
      "0  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.784869\n",
      "1  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.799455\n",
      "2  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.815744\n",
      "3  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.761590\n",
      "4  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.823085\n",
      "5  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.764731\n",
      "6  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.836213\n",
      "7  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.840522\n",
      "8  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.814345\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8143  \u001b[0m | \u001b[0m 0.9321  \u001b[0m | \u001b[0m 0.9418  \u001b[0m | \u001b[0m 0.6837  \u001b[0m | \u001b[0m 0.5583  \u001b[0m | \u001b[0m 0.002457\u001b[0m | \u001b[0m 2.473   \u001b[0m | \u001b[0m 0.017   \u001b[0m | \u001b[0m 176.3   \u001b[0m | \u001b[0m 398.6   \u001b[0m |\n",
      "############## New Run ################\n",
      "PARAMETERS: \n",
      "params  = {'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'learning_rate': 0.005471215582493474, 'num_iterations': 1000, 'num_leaves': 694, 'min_data_in_leaf': 45, 'max_depth': 68, 'bagging_fraction': 0.9194948041424679, 'feature_fraction': 0.5294939428978201, 'lambda_l1': 0.7494131981097794, 'lambda_l2': 0.37460341205946057, 'min_child_weight': 0.022028625768835502, 'bagging_seed': 11, 'verbose': -1, 'seed': 105}\n",
      "[500]\tvalid_0's auc: 0.848245\n",
      "[1000]\tvalid_0's auc: 0.84853\n",
      "Fold :  0 train_auc :  0.9995895342180964 val_auc :  0.8485302431263051\n",
      "[500]\tvalid_0's auc: 0.871942\n",
      "[1000]\tvalid_0's auc: 0.841732\n",
      "Fold :  1 train_auc :  0.9995670956534404 val_auc :  0.841732281271503\n",
      "[500]\tvalid_0's auc: 0.663749\n",
      "[1000]\tvalid_0's auc: 0.606722\n",
      "Fold :  2 train_auc :  0.9996040222641219 val_auc :  0.6067223961006556\n",
      "[500]\tvalid_0's auc: 0.823046\n",
      "[1000]\tvalid_0's auc: 0.774801\n",
      "Fold :  3 train_auc :  0.9996183581359739 val_auc :  0.7748010201622397\n",
      "[500]\tvalid_0's auc: 0.684118\n",
      "[1000]\tvalid_0's auc: 0.706144\n",
      "Fold :  4 train_auc :  0.9995723490779757 val_auc :  0.706144137517632\n",
      "                                           parameter     score\n",
      "0  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.784869\n",
      "1  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.799455\n",
      "2  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.815744\n",
      "3  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.761590\n",
      "4  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.823085\n",
      "5  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.764731\n",
      "6  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.836213\n",
      "7  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.840522\n",
      "8  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.814345\n",
      "9  {'objective': 'binary', 'metric': 'auc', 'is_u...  0.755586\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7556  \u001b[0m | \u001b[0m 0.9195  \u001b[0m | \u001b[0m 0.5295  \u001b[0m | \u001b[0m 0.7494  \u001b[0m | \u001b[0m 0.3746  \u001b[0m | \u001b[0m 0.005471\u001b[0m | \u001b[0m 68.93   \u001b[0m | \u001b[0m 0.02203 \u001b[0m | \u001b[0m 45.01   \u001b[0m | \u001b[0m 694.5   \u001b[0m |\n",
      "=====================================================================================================================================\n",
      "{'objective': 'binary', 'metric': 'auc', 'is_unbalance': False, 'boost_from_average': True, 'num_threads': 4, 'bagging_seed': 11, 'learning_rate': 0.0010000000055557534, 'n_estimators': 3000, 'num_leaves': 31, 'min_data_in_leaf': 0, 'max_depth': 70, 'bagging_fraction': 0.9999999999525592, 'feature_fraction': 0.1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'min_child_weight': 0.01, 'verbose': -1, 'seed': 105}\n"
     ]
    }
   ],
   "source": [
    "def train_model(learning_rate,num_leaves, min_data_in_leaf, max_depth, bagging_fraction, feature_fraction, lambda_l1, lambda_l2,min_child_weight):\n",
    "    print(\"############## New Run ################\")\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'is_unbalance': False,\n",
    "        'boost_from_average': True,\n",
    "        'num_threads': 4,\n",
    "        'learning_rate': learning_rate,#0.01, # learning rate\n",
    "        'num_iterations' : 1000,\n",
    "        #'n_estimators' : 800,\n",
    "        'num_leaves': int(num_leaves),\n",
    "        'min_data_in_leaf': int(min_data_in_leaf),\n",
    "        'max_depth': int(max_depth),\n",
    "        'bagging_fraction' : bagging_fraction,\n",
    "        'feature_fraction' : feature_fraction,\n",
    "        'lambda_l1': lambda_l1,\n",
    "        'lambda_l2': lambda_l2,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'bagging_seed' : 11,\n",
    "        #'early_stopping_round' : 50,\n",
    "        'verbose' : -1,\n",
    "        'seed' : 105\n",
    "    }\n",
    "    print(\"PARAMETERS: \")\n",
    "    print(f\"params  = {params}\")\n",
    "    \n",
    "    tscv =  StratifiedKFold(n_splits=5)#TimeSeriesSplit(n_splits=3)\n",
    "    sc = []\n",
    "#     for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    for fold_,(train_idx, test_idx) in enumerate(tscv.split(X_train, Y_train)):\n",
    "#         print( Y_train.iloc[train_idx].head())\n",
    "        x_train, x_val = X_train.iloc[train_idx,:], X_train.iloc[test_idx,:]\n",
    "        y_train, y_val = Y_train.iloc[train_idx], Y_train.iloc[test_idx]\n",
    "        lgb_train = lgb.Dataset(data=x_train.astype('float32'), label=y_train.astype('float32'))\n",
    "        lgb_valid = lgb.Dataset(data=x_val.astype('float32'), label=y_val.astype('float32'))\n",
    "    \n",
    "        lgb_model = lgb.train(params, lgb_train, valid_sets=lgb_valid, verbose_eval=500)\n",
    "        y = lgb_model.predict(x_train.astype('float32'), num_iteration=lgb_model.best_iteration)\n",
    "        train_score = roc_auc_score(y_train.astype('float32'), y)        \n",
    "        y = lgb_model.predict(x_val.astype('float32'), num_iteration=lgb_model.best_iteration)\n",
    "        score = roc_auc_score(y_val.astype('float32'), y)\n",
    "        print (\"Fold : \", fold_,\"train_auc : \",train_score,\"val_auc : \", score)\n",
    "        sc.append(score)\n",
    "        \n",
    "    paralst.append(params)\n",
    "    scorelst.append(np.mean(sc))\n",
    "    df_para = pd.DataFrame({\"parameter\" :paralst,\"score\":scorelst})\n",
    "    print(df_para)\n",
    "    df_para.to_csv('para.csv',index=False)\n",
    "\n",
    "        \n",
    "    return np.mean(sc)\n",
    "\n",
    "bounds = {\n",
    "    'num_leaves': (31, 700),\n",
    "    'min_data_in_leaf': (0, 200),\n",
    "    'max_depth': (-1, 70),#(-1, 50), # -> -1\n",
    "    'learning_rate': (0.001,0.01),#0.006883242363721497,\n",
    "    'bagging_fraction' : (0.1, 1),\n",
    "    'feature_fraction' : (0.1, 1),\n",
    "    'lambda_l1': (0, 1),\n",
    "    'lambda_l2': (0, 1),\n",
    "    'min_child_weight': (0.01, 0.1),\n",
    "}\n",
    "\n",
    "traintime =True\n",
    "if traintime :\n",
    "    paralst,scorelst = [],[]\n",
    "    bo = BayesianOptimization(train_model, bounds, random_state=105)\n",
    "    bo.maximize(init_points=3, n_iter=7, acq='ucb', xi=0.0, alpha=1e-6)\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'is_unbalance': False,\n",
    "        'boost_from_average': True,\n",
    "        'num_threads': 4,\n",
    "        'bagging_seed' : 11,\n",
    "        'learning_rate':bo.max['params']['learning_rate'],#0.01,\n",
    "        'n_estimators' : 3000,\n",
    "        'num_leaves': int(bo.max['params']['num_leaves']),\n",
    "        'min_data_in_leaf': int(bo.max['params']['min_data_in_leaf']),\n",
    "        'max_depth': int(bo.max['params']['max_depth']),\n",
    "        'bagging_fraction' : bo.max['params']['bagging_fraction'],\n",
    "        'feature_fraction' : bo.max['params']['feature_fraction'],\n",
    "        'lambda_l1': bo.max['params']['lambda_l1'],\n",
    "        'lambda_l2': bo.max['params']['lambda_l2'],\n",
    "        'min_child_weight' :  bo.max['params']['min_child_weight'],\n",
    "       #'early_stopping_round' : 50,\n",
    "        'verbose' : -1,\n",
    "        'seed' :105\n",
    "\n",
    "    }\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not traintime :\n",
    "    params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'is_unbalance': False,\n",
    "            'boost_from_average': True,\n",
    "            'num_threads': 4,\n",
    "            #'bagging_seed' : 11,\n",
    "            'learning_rate':0.0070281530255225,\n",
    "            'n_estimators' : 5000,\n",
    "            'num_leaves': 326,\n",
    "            'min_data_in_leaf': 111,\n",
    "            'max_depth': 47,\n",
    "            'bagging_fraction' : 0.768240140757717,\n",
    "            'feature_fraction' : 0.26179858102782727,\n",
    "            'lambda_l1': 0.1742026705579186,            \n",
    "            'lambda_l2': 0.4491470796888313,\n",
    "            'min_child_weight' : 0.008349999182168921,\n",
    "           #'early_stopping_round' : 50,\n",
    "            'verbose' : -1,\n",
    "            'seed' : 40\n",
    "            }\n",
    "\n",
    "    print(params)\n",
    "\n",
    "    # \n",
    "    # x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "    # lgb_train = lgb.Dataset(data=x_train.astype('float32'), label=y_train.astype('float32'))\n",
    "    # lgb_valid = lgb.Dataset(data=x_val.astype('float32'), label=y_val.astype('float32'))\n",
    "\n",
    "\n",
    "\n",
    "    # lgb_model = lgb.train(params, lgb_train, valid_sets=lgb_valid, verbose_eval=100,early_stopping_rounds=50)\n",
    "\n",
    "    # y = lgb_model.predict(X_test.astype('float32'), num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "    # submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n",
    "    # submission['isFraud'] = y\n",
    "    # submission.to_csv('submission.csv')\n",
    "\n",
    "\n",
    "    # Cross validation Score?로 제출?\n",
    "\n",
    "    tscv =  StratifiedKFold(n_splits=5)#(n_splits=8, shuffle=True, random_state=42)#TimeSeriesSplit(n_splits=5) #? -> \n",
    "    sc = []\n",
    "    #     for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    for fold_,(train_idx, test_idx) in enumerate(tscv.split(X_train, Y_train)):\n",
    "    #         print( Y_train.iloc[train_idx].head())\n",
    "        x_train, x_val = X_train.iloc[train_idx,:], X_train.iloc[test_idx,:]\n",
    "        y_train, y_val = Y_train.iloc[train_idx], Y_train.iloc[test_idx]\n",
    "        lgb_train = lgb.Dataset(data=x_train.astype('float32'), label=y_train.astype('float32'))\n",
    "        lgb_valid = lgb.Dataset(data=x_val.astype('float32'), label=y_val.astype('float32'))\n",
    "        lgb_model = lgb.train(params, lgb_train, valid_sets=lgb_valid, verbose_eval=200,early_stopping_rounds=50)\n",
    "        y = lgb_model.predict(x_train.astype('float32'), num_iteration=lgb_model.best_iteration)\n",
    "        train_score = roc_auc_score(y_train.astype('float32'), y)        \n",
    "        y = lgb_model.predict(x_val.astype('float32'), num_iteration=lgb_model.best_iteration)\n",
    "        score = roc_auc_score(y_val.astype('float32'), y)\n",
    "        print (\"Fold : \", fold_,\"train_auc : \",train_score,\"val_auc : \", score)\n",
    "        y = lgb_model.predict(X_test.astype('float32'), num_iteration=lgb_model.best_iteration)\n",
    "        sc.append(y)\n",
    "\n",
    "    print(np.mean(sc,axis =0))\n",
    "\n",
    "    submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n",
    "    submission['isFraud'] = np.mean(sc, axis =0)\n",
    "    submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # single fold로 train하고 그걸로 classifier 만들기\n",
    "\n",
    "# x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "# lgb_train = lgb.Dataset(data=x_train.astype('float32'), label=y_train.astype('float32'))\n",
    "# lgb_valid = lgb.Dataset(data=x_val.astype('float32'), label=y_val.astype('float32'))\n",
    "# lgb_model = lgb.train(params, lgb_train, valid_sets=lgb_valid, verbose_eval=100,early_stopping_rounds=50)\n",
    "# clf = lgb.LGBMClassifier(**params, num_boost_round=lgb_model.best_iteration) #데이터 전부다 넣고 학습\n",
    "# clf.fit(X_train, Y_train)\n",
    "\n",
    "# submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n",
    "# submission['isFraud'] = clf.predict_proba(X_test)[:, 1]\n",
    "# submission.to_csv('submission.csv')\n",
    "# # y = lgb_model.predict(X_test.astype('float32'), num_iteration=lgb_model.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clf = lgb.LGBMClassifier(**params, num_boost_round=lgb_model.best_iteration) #데이터 전부다 넣고 학습\n",
    "# # lgb_train = lgb.Dataset(data=X_train.astype('float32'), label=Y_train.astype('float32'))\n",
    "# clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n",
    "# submission['isFraud'] = clf.predict_proba(X_test)[:, 1]\n",
    "# submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_df = pd.concat([\n",
    "#     pd.Series(X_train.columns),\n",
    "#     pd.Series(lgb_model.feature_importance())], axis=1)\n",
    "# feature_importance_df.columns = ['featureName', 'importance']\n",
    "\n",
    "# # get top 100 features sorted by importance descending\n",
    "# temp = feature_importance_df.sort_values(by=['importance'], ascending=False).head(100)\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# sns.barplot(x=\"importance\", y=\"featureName\", data=temp)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "#scaled_x_test = scaler.transform(x_test)\n",
    "\n",
    "# y = lgb_model.predict(X_test.astype('float32'), num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "#del scaled_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n",
    "# submission['isFraud'] = y\n",
    "# submission.to_csv('lightgbm-simple.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2426aef571144815a2fca01c8c7d5984": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "488244dbf52f4c93b9065f880653dbfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2426aef571144815a2fca01c8c7d5984",
       "max": 452,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a9c7c316df6c4f1483a4570c1632df76",
       "value": 452
      }
     },
     "6560151a8a944c339f6862b2f5445eeb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "854cb0b2fa8540a2b953e7471511f341": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e57bd35798194610b197646b43e23a89",
       "placeholder": "​",
       "style": "IPY_MODEL_6560151a8a944c339f6862b2f5445eeb",
       "value": "100% 452/452 [01:13&lt;00:00,  6.19it/s]"
      }
     },
     "a9c7c316df6c4f1483a4570c1632df76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c85f7318d8944d14a4313eae7fc953c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d42de25ccde847c89d5ebcf9316cf491": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_488244dbf52f4c93b9065f880653dbfa",
        "IPY_MODEL_854cb0b2fa8540a2b953e7471511f341"
       ],
       "layout": "IPY_MODEL_c85f7318d8944d14a4313eae7fc953c3"
      }
     },
     "e57bd35798194610b197646b43e23a89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
