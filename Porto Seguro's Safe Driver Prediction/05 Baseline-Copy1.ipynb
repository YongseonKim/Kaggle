{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action ='ignore')\n",
    "import os\n",
    "import gc\n",
    "pd.options.display.max_rows = 99\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0   7          2              2          5              1              0   \n",
       "1   9          1              1          7              0              0   \n",
       "2  13          5              4          9              1              0   \n",
       "3  16          0              1          2              0              0   \n",
       "4  17          0              2          0              1              0   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ...  \\\n",
       "0              0              1              0              0  ...   \n",
       "1              0              0              1              0  ...   \n",
       "2              0              0              1              0  ...   \n",
       "3              1              0              0              0  ...   \n",
       "4              1              0              0              0  ...   \n",
       "\n",
       "   ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "0           1           5           8               0               1   \n",
       "1           1           1           9               0               1   \n",
       "2           2           7           7               0               1   \n",
       "3           2           4           9               0               0   \n",
       "4           1           1           3               0               0   \n",
       "\n",
       "   ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin   flag  \n",
       "0               1               0               0               1  train  \n",
       "1               1               0               1               0  train  \n",
       "2               1               0               1               0  train  \n",
       "3               0               0               0               0  train  \n",
       "4               0               1               1               0  train  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['flag'], test['flag'] = 'train','test'\n",
    "target = train['target']\n",
    "full_df = pd.concat([train.drop(['target'],axis =1 ),test])\n",
    "full_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Table 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in full_df.columns:\n",
    "    # Defining the role\n",
    "    if f == 'target':\n",
    "        role = 'target'\n",
    "    elif f == 'id':\n",
    "        role = 'id'\n",
    "    else:\n",
    "        role = 'input'\n",
    "         \n",
    "    # Defining the level\n",
    "    if 'bin' in f or f == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in f or f == 'id':\n",
    "        level = 'nominal'\n",
    "    elif train[f].dtype == float:\n",
    "        level = 'interval'\n",
    "    elif train[f].dtype == 'int64':\n",
    "        level = 'ordinal'\n",
    "        \n",
    "    # Initialize keep to True for all variables except for id\n",
    "    keep = True\n",
    "    if f == 'id':\n",
    "        keep = False\n",
    "    \n",
    "    # Defining the data type \n",
    "    dtype = full_df[f].dtype\n",
    "    \n",
    "    # Creating a Dict that contains all the metadata for the variable\n",
    "    f_dict = {\n",
    "        'varname': f,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep': keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    data.append(f_dict)\n",
    "    \n",
    "meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n",
    "meta.set_index('varname', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>level</th>\n",
       "      <th>keep</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>id</td>\n",
       "      <td>nominal</td>\n",
       "      <td>False</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_01</th>\n",
       "      <td>input</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>input</td>\n",
       "      <td>nominal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_03</th>\n",
       "      <td>input</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <td>input</td>\n",
       "      <td>nominal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                role    level   keep  dtype\n",
       "varname                                    \n",
       "id                id  nominal  False  int64\n",
       "ps_ind_01      input  ordinal   True  int64\n",
       "ps_ind_02_cat  input  nominal   True  int64\n",
       "ps_ind_03      input  ordinal   True  int64\n",
       "ps_ind_04_cat  input  nominal   True  int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ind / reg / car / calc  데이터\n",
    "- _cat / _bin \n",
    "- 아무것도 없는 컬럼을 type으로 interval / ordinal로 구분\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Value 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -1-> Null\n",
    "full_df = full_df.replace(-1,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval \n",
    "cols =list(meta[(meta['level']=='interval') & (meta['keep']==True)].index)\n",
    "#  Null Value  Portion\n",
    "# print(full_df[cols].isnull().sum()/full_df[cols].shape[0]*100)\n",
    "# 평균으로 처리\n",
    "full_df[cols] = full_df[cols].fillna(full_df[cols].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal : 순서형 자료 (매우높다, 높다, 낮다 등)\n",
    "cols =list(meta[(meta['level']=='ordinal') & (meta['keep']==True)].index)\n",
    "#  Null Value  Portion\n",
    "# print(full_df[cols].isnull().sum()/full_df[cols].shape[0]*100)\n",
    "# 최빈값을 넣어두자 \n",
    "full_df[cols] = full_df[cols].fillna(full_df[cols].mode().iloc[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norminal  : 카테고리 변수 --\n",
    "cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "#  Null Value  Portion\n",
    "# print(full_df[cols].isnull().sum()/full_df[cols].shape[0]*100)\n",
    "# Null 값을 하나의 카테고리로 분류  = '-999' 입력\n",
    "full_df[cols] = full_df[cols].fillna('-999')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary \n",
    "cols =list(meta[(meta['level']=='binary') & (meta['keep']==True)].index)\n",
    "#  Null Value  Portion\n",
    "# print(full_df[cols].isnull().sum()/full_df[cols].shape[0]*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freq encoding \n",
    "- 각 카테고리 컬럼의 빈도수를 카운트 한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal value에 대해\n",
    "cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "\n",
    "for col in cols :\n",
    "    col_name = '%s_count_full' % col\n",
    "    full_df[col_name] = full_df[col].map(full_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal value에 대해\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]\n",
      "  7%|█████▉                                                                             | 1/14 [00:21<04:36, 21.28s/it]\n",
      " 14%|███████████▊                                                                       | 2/14 [00:50<04:44, 23.73s/it]\n",
      " 21%|█████████████████▊                                                                 | 3/14 [01:29<05:11, 28.30s/it]\n",
      " 29%|███████████████████████▋                                                           | 4/14 [02:20<05:49, 35.00s/it]\n",
      " 36%|█████████████████████████████▋                                                     | 5/14 [03:20<06:23, 42.65s/it]"
     ]
    }
   ],
   "source": [
    "# # Catgory column별로 interval value 평균과 편차는 무슨 의미가 있을까\n",
    "\n",
    "# # full_df.head()\n",
    "# cat_cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "# cols = list(meta[(meta['level']!='nominal') & (meta['keep']==True)].index)\n",
    "# cols.remove('flag')\n",
    "# newcol_name = [x+'_avg' for x in cols]\n",
    "# for col in tqdm(cat_cols) :\n",
    "#     tmp = [x+'_for_%s'%col for x in newcol_name]\n",
    "#     for c,original  in zip(tmp,cols) :\n",
    "#         full_df[c] = full_df[col].map(full_df.groupby(col)[original].mean())\n",
    "# #     print(full_df.groupby(col)[cols].mean())\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interaction\n",
    "- 상관관계를 기반으로 곱하기를 해보자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Car features\n",
    "ps_car_12 are (with some approximations) square roots (divided by 10) of natural numbers whilst ps_car_15 are square roots of natural numbers. Let's represent the values using pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = trainset.sample(frac=0.05)\n",
    "# var = ['ps_car_12', 'ps_car_15', 'target']\n",
    "# sample = sample[var]\n",
    "# sns.pairplot(sample,  hue='target', palette = 'Set1', diag_kind='kde')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the public kernels (wheel of fortune eg.) that suggest to remove *calc features,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in meta.index if 'calc' in x]\n",
    "meta.loc[cols,'keep'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Removing featues with low variance\n",
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "# sel.fit_transform(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree-based Feature selection\n",
    "#https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]\n",
      "  7%|█████▉                                                                             | 1/14 [00:01<00:24,  1.89s/it]\n",
      " 14%|███████████▊                                                                       | 2/14 [00:03<00:22,  1.89s/it]\n",
      " 21%|█████████████████▊                                                                 | 3/14 [00:05<00:19,  1.81s/it]\n",
      " 29%|███████████████████████▋                                                           | 4/14 [00:07<00:19,  1.93s/it]\n",
      " 36%|█████████████████████████████▋                                                     | 5/14 [00:09<00:16,  1.89s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 6/14 [00:09<00:12,  1.50s/it]\n",
      " 50%|█████████████████████████████████████████▌                                         | 7/14 [00:10<00:08,  1.16s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 8/14 [00:12<00:08,  1.34s/it]\n",
      " 64%|█████████████████████████████████████████████████████▎                             | 9/14 [00:12<00:05,  1.04s/it]\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 10/14 [00:14<00:04,  1.22s/it]\n",
      " 79%|████████████████████████████████████████████████████████████████▍                 | 11/14 [00:14<00:02,  1.05it/s]\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 12/14 [00:16<00:02,  1.23s/it]\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▏     | 13/14 [00:16<00:00,  1.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:17<00:00,  1.28it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# nominal value에 대해\n",
    "cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "for col in tqdm(cols) :\n",
    "    lbl = LabelEncoder()\n",
    "    full_df[col] = lbl.fit_transform(list(full_df[col].values))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =list(meta[meta['keep']==True].index)\n",
    "full_df = full_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-d0635a3e2a1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'flag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'flag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'flag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'flag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "full_df.head()\n",
    "train_df = full_df[full_df['flag']=='train'].drop(['flag'],axis =1 )\n",
    "test_df = full_df[full_df['flag']=='test'].drop(['flag'],axis =1 )\n",
    "target = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ea99a0224e67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JIT 컴파일(just-in-time compilation) 또는 동적 번역(dynamic translation)은 프로그램을 실제 실행하는 시점에\n",
    "기계어로 번역하는 컴파일 기법이다. 이 기법은 프로그램의 실행 속도를 빠르게 하기 위해 사용된다.\n",
    "\n",
    "\n",
    "출처: https://hamait.tistory.com/476 [HAMA 블로그]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "@jit\n",
    "\n",
    "#\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "early_stopping_round = 30\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds= 5\n",
    "kf = KFold(n_splits =n_folds, random_state = 99, shuffle =True)\n",
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = XGBClassifier( \n",
    "            n_estimators = 1000,\n",
    "            max_depth =4,\n",
    "    objective = \"binary:logistic\",\n",
    "    learing_rateing_rate = learning_rate,\n",
    "    subsample = .8,\n",
    "    min_child_weight = 6,\n",
    "    colsample_bytree = .8,\n",
    "    scale_pos_weight = 1.6,\n",
    "    gamma = 10,\n",
    "    reg_alpha = 8,\n",
    "    reg_lambda =1.3,\n",
    "    tree_method = 'gpu_hist'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "y_test_pred = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    x_train,x_valid = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train,y_valid = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    eval_set = [(x_valid,y_valid)]\n",
    "    fit_model = model.fit(x_train,y_train,\n",
    "                         eval_set =eval_set,\n",
    "                         eval_metric = gini_xgb,\n",
    "                        early_stopping_rounds = early_stopping_round,\n",
    "                          verbose = 50\n",
    "                         )\n",
    "    print( \"Best N tress = \" , model.best_ntree_limit)\n",
    "    print(\" Best gini = \", -model.best_score)\n",
    "\n",
    "    \n",
    "    #  prediction\n",
    "    pred = fit_model.predict_proba(x_valid)[:,1]\n",
    "    print( \" Gini = \", eval_gini(y_valid, pred))\n",
    "    scores.append(eval_gini(y_valid, pred))\n",
    "    y_test_pred.append(fit_model.predict_proba(test_df)[:,1])\n",
    "    \n",
    "    \n",
    "    del x_train,x_valid,y_train,y_valid\n",
    "    gc.collect()\n",
    "print(\" Cross validadation score, Gini \" ,sum(scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame()\n",
    "sub_df['id'] = test['id']\n",
    "sub_df['target'] = sum(y_test_pred)/n_folds\n",
    "\n",
    "sub_df.to_csv('submission_baseline_XGBOOST_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_lgbm(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = eval_gini(labels, preds)\n",
    "    return 'gini', gini_score,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM\n",
    "import lightgbm as lgb\n",
    "seeds = 99\n",
    "params =  {\n",
    "        'objective': 'binary',\n",
    "        'num_threads': 4,\n",
    "        'learning_rate': 0.01, \n",
    "        'num_iterations' : 1000,\n",
    "        'max_depth': -1,\n",
    "        'reg_alpha': 0.3,\n",
    "         'reg_lambda': 0.3,\n",
    "        'bagging_seed' : seeds,\n",
    "        'verbose' : -1,\n",
    "        'seed' :seeds\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "y_test_pred= []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    x_train,x_valid = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train,y_valid = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(data = x_train, label = y_train)\n",
    "    lgb_valid = lgb.Dataset(data = x_valid, label = y_valid)\n",
    "    \n",
    "    lgb_model = lgb.train(params, lgb_train, valid_sets = [lgb_valid], \n",
    "                          feval = gini_lgbm,verbose_eval = 100, early_stopping_rounds = early_stopping_round)\n",
    "    \n",
    "    pred = lgb_model.predict(x_valid, num_iteration = lgb_model.best_iteration)\n",
    "#     pred = fit_model.predict_proba(x_valid)[:,1]\n",
    "    print(pred.shape)\n",
    "    print( \" Gini = \", eval_gini(y_valid, pred))\n",
    "    scores.append(eval_gini(y_valid, pred))\n",
    "    y_test_pred.append(lgb_model.predict(test_df))\n",
    "    \n",
    "    del x_train,x_valid,y_train,y_valid\n",
    "    gc.collect()\n",
    "print(\" Cross validadation score, Gini \" ,sum(scores)/n_folds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['id'] = test['id']\n",
    "sub_df['target'] = sum(y_test_pred)/n_folds\n",
    "\n",
    "sub_df.to_csv('submission_baseline_LGBM_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM_Categorical Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_lgbm(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = eval_gini(labels, preds)\n",
    "    return 'gini', gini_score,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal value에 대해\n",
    "cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "\n",
    "# LGBM\n",
    "import lightgbm as lgb\n",
    "seeds = 99\n",
    "params =  {\n",
    "        'objective': 'binary',\n",
    "        'num_threads': 4,\n",
    "        'learning_rate': 0.01, \n",
    "        'num_iterations' : 1000,\n",
    "        'max_depth': -1,\n",
    "        'reg_alpha': 0.3,\n",
    "         'reg_lambda': 0.3,\n",
    "        'bagging_seed' : seeds,\n",
    "        'verbose' : -1,\n",
    "        'seed' :seeds\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.151767\tvalid_0's gini: 0.249186\n",
      "[200]\tvalid_0's binary_logloss: 0.150992\tvalid_0's gini: 0.257855\n",
      "[300]\tvalid_0's binary_logloss: 0.150695\tvalid_0's gini: 0.262629\n",
      "[400]\tvalid_0's binary_logloss: 0.150577\tvalid_0's gini: 0.265408\n",
      "[500]\tvalid_0's binary_logloss: 0.150535\tvalid_0's gini: 0.266414\n",
      "Early stopping, best iteration is:\n",
      "[531]\tvalid_0's binary_logloss: 0.150533\tvalid_0's gini: 0.266525\n",
      "(119043,)\n",
      " Gini =  0.2665252768135875\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.155468\tvalid_0's gini: 0.239307\n",
      "[200]\tvalid_0's binary_logloss: 0.154779\tvalid_0's gini: 0.248473\n",
      "[300]\tvalid_0's binary_logloss: 0.154578\tvalid_0's gini: 0.251739\n",
      "[400]\tvalid_0's binary_logloss: 0.154536\tvalid_0's gini: 0.252678\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid_0's binary_logloss: 0.154533\tvalid_0's gini: 0.252729\n",
      "(119043,)\n",
      " Gini =  0.252728996421557\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153911\tvalid_0's gini: 0.241924\n",
      "[200]\tvalid_0's binary_logloss: 0.153188\tvalid_0's gini: 0.251275\n",
      "[300]\tvalid_0's binary_logloss: 0.152962\tvalid_0's gini: 0.254059\n",
      "[400]\tvalid_0's binary_logloss: 0.152883\tvalid_0's gini: 0.255954\n",
      "Early stopping, best iteration is:\n",
      "[444]\tvalid_0's binary_logloss: 0.152861\tvalid_0's gini: 0.256926\n",
      "(119042,)\n",
      " Gini =  0.2569255262267083\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.154535\tvalid_0's gini: 0.26486\n",
      "[200]\tvalid_0's binary_logloss: 0.153658\tvalid_0's gini: 0.274561\n",
      "[300]\tvalid_0's binary_logloss: 0.153353\tvalid_0's gini: 0.27854\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's binary_logloss: 0.153344\tvalid_0's gini: 0.278664\n",
      "(119042,)\n",
      " Gini =  0.27866367154186966\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.151964\tvalid_0's gini: 0.241771\n",
      "[200]\tvalid_0's binary_logloss: 0.151275\tvalid_0's gini: 0.250982\n",
      "[300]\tvalid_0's binary_logloss: 0.151047\tvalid_0's gini: 0.254664\n",
      "[400]\tvalid_0's binary_logloss: 0.150964\tvalid_0's gini: 0.256748\n",
      "Early stopping, best iteration is:\n",
      "[394]\tvalid_0's binary_logloss: 0.150962\tvalid_0's gini: 0.256816\n",
      "(119042,)\n",
      " Gini =  0.2568162040605273\n",
      " Cross validadation score, Gini  0.26233193501284996\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "y_test_pred= []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    x_train,x_valid = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train,y_valid = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "#     x_train[cols] , x_valid[cols]= x_train[cols].astype(object), x_valid[cols].astype(object)\n",
    "    lgb_train = lgb.Dataset(data = x_train, label = y_train)\n",
    "    lgb_valid = lgb.Dataset(data = x_valid, label = y_valid)\n",
    "    \n",
    "    lgb_model = lgb.train(params, lgb_train, valid_sets = [lgb_valid], \n",
    "                          feval = gini_lgbm,verbose_eval = 100, early_stopping_rounds = early_stopping_round,\n",
    "                         categorical_feature=cols)\n",
    "        \n",
    "    pred = lgb_model.predict(x_valid, num_iteration = lgb_model.best_iteration)\n",
    "#     pred = fit_model.predict_proba(x_valid)[:,1]\n",
    "    print(pred.shape)\n",
    "    print( \" Gini = \", eval_gini(y_valid, pred))\n",
    "    scores.append(eval_gini(y_valid, pred))\n",
    "    y_test_pred.append(lgb_model.predict(test_df))\n",
    "    \n",
    "    del x_train,x_valid,y_train,y_valid\n",
    "    gc.collect()\n",
    "print(\" Cross validadation score, Gini \" ,sum(scores)/n_folds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['id'] = test['id']\n",
    "sub_df['target'] = sum(y_test_pred)/n_folds\n",
    "\n",
    "sub_df.to_csv('submission_baseline_LGBM_Cat_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "params =    {     #'iterations' : 2000,\n",
    "        'n_estimators': 2000,\n",
    "        'learning_rate': 0.05,\n",
    "        'eval_metric': 'RMSE',\n",
    "        'loss_function': 'RMSE',\n",
    "        'random_seed': seed,\n",
    "        'metric_period': 10,\n",
    "        'task_type': 'GPU',\n",
    "        #'subsample' : 0.8,\n",
    "        'depth': 8,\n",
    "    }\n",
    "\n",
    "model = CatBoostClassifier(iterations=2,\n",
    "                           learning_rate=1,\n",
    "                           depth=2)\n",
    "# Fit model\n",
    "model.fit(train_data, train_labels, cat_features)\n",
    "# Get predicted classes\n",
    "preds_class = model.predict(eval_data)\n",
    "# Get predicted probabilities for each class\n",
    "preds_proba = model.predict_proba(eval_data)\n",
    "# Get predicted RawFormulaVal\n",
    "preds_raw = model.predict(eval_data, prediction_type='RawFormulaVal')\n",
    "\n",
    "\n",
    " gbm = CatBoostRegressor(**params)\n",
    "    print(i)\n",
    "    gbm.fit(\n",
    "            train_X, train_y,\n",
    "             eval_set=(val_X, val_y),\n",
    "            early_stopping_rounds = 30,\n",
    "            cat_features=categorical_features,\n",
    "            verbose=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ve used this to get a network that has a local CV AUC around 0.642, which corresponds to Gini of 0.284. \n",
    "\n",
    "the formula GINI = 2 * AUC -1\n",
    "2*AUC-1 will be same as calculated with gini_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# https://www.kaggle.com/rspadim/gini-keras-callback-earlystopping-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold = StratifiedKFold(n_splits = K, \n",
    "#                             random_state = 100, \n",
    "#                             shuffle = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "# FROM https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41108\n",
    "def jacek_auc(y_true, y_pred):\n",
    "    score, up_opt = tf.metrics.auc(y_true, y_pred)\n",
    "    #score, up_opt = tf.contrib.metrics.streaming_auc(y_pred, y_true)    \n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    with tf.control_dependencies([up_opt]):\n",
    "        score = tf.identity(score)\n",
    "    return score\n",
    "\n",
    "# FROM https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41015\n",
    "# AUC for a binary classifier\n",
    "def discussion41015_auc(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "\n",
    "# PFA, prob false alert for binary classifier\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "\n",
    "#----------------\n",
    "# P_TA prob true alerts for binary classifier\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    "\n",
    "\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/tomcwalker/keras-nn-with-custom-loss-function-for-gini-auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mlp = keras.utils.np_utils.to_categorical(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 22s - loss: 1211.5840 - jacek_auc: 0.9342\n",
      "Epoch 2/1000\n",
      " - 21s - loss: 0.4911 - jacek_auc: 0.9556\n",
      "Epoch 3/1000\n",
      " - 21s - loss: 0.2010 - jacek_auc: 0.9588\n",
      "Epoch 4/1000\n",
      " - 21s - loss: 0.3525 - jacek_auc: 0.9601\n",
      "Epoch 5/1000\n",
      " - 21s - loss: 0.1726 - jacek_auc: 0.9608\n",
      "Epoch 6/1000\n",
      " - 21s - loss: 0.1830 - jacek_auc: 0.9613\n",
      "Epoch 7/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9617\n",
      "Epoch 8/1000\n",
      " - 21s - loss: 0.2207 - jacek_auc: 0.9619\n",
      "Epoch 9/1000\n",
      " - 21s - loss: 0.1582 - jacek_auc: 0.9619\n",
      "Epoch 10/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9622\n",
      "Epoch 11/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9623\n",
      "Epoch 12/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9624\n",
      "Epoch 13/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9625\n",
      "Epoch 14/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9625\n",
      "Epoch 15/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9625\n",
      "Epoch 16/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9628\n",
      "Epoch 17/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9628\n",
      "Epoch 18/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9628\n",
      "Epoch 19/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9628\n",
      "Epoch 20/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 21/1000\n",
      " - 21s - loss: 0.1583 - jacek_auc: 0.9629\n",
      "Epoch 22/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 23/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 24/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 25/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 26/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 27/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 28/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 29/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 30/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 31/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 32/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 33/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 34/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 35/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 36/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 37/1000\n",
      " - 22s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 38/1000\n",
      " - 22s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 39/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 40/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 41/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 42/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 43/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 44/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 45/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 46/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 47/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 48/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 49/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 50/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 51/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 52/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 53/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 54/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 55/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 56/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 57/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 58/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 59/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 60/1000\n",
      " - 24s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 61/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 62/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 63/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 64/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 65/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 66/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 67/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 68/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 69/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 70/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 71/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 72/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 73/1000\n",
      " - 22s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 74/1000\n",
      " - 22s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 75/1000\n",
      " - 22s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 76/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 77/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 78/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 79/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 80/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 81/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 82/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 83/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 84/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 00084: early stopping\n",
      "0 Gini  [-0.00273351  0.00271041]\n",
      "Epoch 1/1000\n",
      " - 21s - loss: 520.6350 - jacek_auc: 0.9417\n",
      "Epoch 2/1000\n",
      " - 20s - loss: 0.2661 - jacek_auc: 0.9575\n",
      "Epoch 3/1000\n",
      " - 20s - loss: 0.3227 - jacek_auc: 0.9601\n",
      "Epoch 4/1000\n",
      " - 20s - loss: 0.1643 - jacek_auc: 0.9611\n",
      "Epoch 5/1000\n",
      " - 20s - loss: 0.1702 - jacek_auc: 0.9617\n",
      "Epoch 6/1000\n",
      " - 22s - loss: 0.1560 - jacek_auc: 0.9619\n",
      "Epoch 7/1000\n",
      " - 22s - loss: 0.1560 - jacek_auc: 0.9623\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-37f047bd3488>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m        \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m        \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcallback_early_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m        verbose = 2)\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 1000\n",
    "learning_rate = 0.001\n",
    "scores = []\n",
    "y_test_pred= []\n",
    "\n",
    "def mlpmodel(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation ='relu', input_dim = input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(Dense(64,activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2,activation='sigmoid'))\n",
    "    adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "    model.compile(loss ='binary_crossentropy',\n",
    "                 optimizer = adam,metrics = [jacek_auc])\n",
    "\n",
    "    return model\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='jacek_auc', patience=10, verbose=2, mode='max')\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    x_train,x_valid = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train,y_valid = target_mlp[train_index], target_mlp[test_index]\n",
    "    \n",
    "    \n",
    "    mlp = mlpmodel(x_train.shape[1])\n",
    "    mlp.fit(x_train,y_train,\n",
    "       epochs = epochs,\n",
    "       batch_size = batch_size,\n",
    "       callbacks = [callback_early_stopping],\n",
    "       verbose = 2)\n",
    "    \n",
    "    \n",
    "    pred  = mlp.predict(x_valid)\n",
    "    score = -eval_gini(y_valid, pred[:,0])\n",
    "    scores.append(score)\n",
    "    print(i, \"Gini \", score )\n",
    "    \n",
    "    y_test_pred.append(mlp.predict(test_df))\n",
    "#     mlp.predict(test_df)\n",
    "    del x_train,x_valid,y_train,y_valid\n",
    "    gc.collect()\n",
    "\n",
    "print(\" Cross validadation score, Gini \" ,sum(scores)/n_folds)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['id'] = test['id']\n",
    "sub_df['target'] = sum(y_test_pred)/n_folds\n",
    "\n",
    "sub_df.to_csv('submission_baseline_MLP_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03637472, 0.03637472, 0.03637472, ..., 0.03637472, 0.03637472,\n",
       "       0.03637472], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.backend' from 'C:\\\\Users\\\\yseon\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\keras\\\\backend\\\\__init__.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
