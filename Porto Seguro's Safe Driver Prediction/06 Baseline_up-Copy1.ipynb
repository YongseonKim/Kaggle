{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action ='ignore')\n",
    "import os\n",
    "import gc\n",
    "pd.options.display.max_rows = 99\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0   7          2              2          5              1              0   \n",
       "1   9          1              1          7              0              0   \n",
       "2  13          5              4          9              1              0   \n",
       "3  16          0              1          2              0              0   \n",
       "4  17          0              2          0              1              0   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ...  \\\n",
       "0              0              1              0              0  ...   \n",
       "1              0              0              1              0  ...   \n",
       "2              0              0              1              0  ...   \n",
       "3              1              0              0              0  ...   \n",
       "4              1              0              0              0  ...   \n",
       "\n",
       "   ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "0           1           5           8               0               1   \n",
       "1           1           1           9               0               1   \n",
       "2           2           7           7               0               1   \n",
       "3           2           4           9               0               0   \n",
       "4           1           1           3               0               0   \n",
       "\n",
       "   ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin   flag  \n",
       "0               1               0               0               1  train  \n",
       "1               1               0               1               0  train  \n",
       "2               1               0               1               0  train  \n",
       "3               0               0               0               0  train  \n",
       "4               0               1               1               0  train  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['flag'], test['flag'] = 'train','test'\n",
    "target = train['target']\n",
    "full_df = pd.concat([train.drop(['target'],axis =1 ),test])\n",
    "full_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Table 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in full_df.columns:\n",
    "    # Defining the role\n",
    "    if f == 'target':\n",
    "        role = 'target'\n",
    "    elif f == 'id':\n",
    "        role = 'id'\n",
    "    else:\n",
    "        role = 'input'\n",
    "         \n",
    "    # Defining the level\n",
    "    if 'bin' in f or f == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in f or f == 'id':\n",
    "        level = 'nominal'\n",
    "    elif train[f].dtype == float:\n",
    "        level = 'interval'\n",
    "    elif train[f].dtype == 'int64':\n",
    "        level = 'ordinal'\n",
    "        \n",
    "    # Initialize keep to True for all variables except for id\n",
    "    keep = True\n",
    "    if f == 'id':\n",
    "        keep = False\n",
    "    \n",
    "    # Defining the data type \n",
    "    dtype = full_df[f].dtype\n",
    "    \n",
    "    # Creating a Dict that contains all the metadata for the variable\n",
    "    f_dict = {\n",
    "        'varname': f,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep': keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    data.append(f_dict)\n",
    "    \n",
    "meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n",
    "meta.set_index('varname', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>level</th>\n",
       "      <th>keep</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>id</td>\n",
       "      <td>nominal</td>\n",
       "      <td>False</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_01</th>\n",
       "      <td>input</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>input</td>\n",
       "      <td>nominal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_03</th>\n",
       "      <td>input</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <td>input</td>\n",
       "      <td>nominal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                role    level   keep  dtype\n",
       "varname                                    \n",
       "id                id  nominal  False  int64\n",
       "ps_ind_01      input  ordinal   True  int64\n",
       "ps_ind_02_cat  input  nominal   True  int64\n",
       "ps_ind_03      input  ordinal   True  int64\n",
       "ps_ind_04_cat  input  nominal   True  int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ind / reg / car / calc  데이터\n",
    "- _cat / _bin \n",
    "- 아무것도 없는 컬럼을 type으로 interval / ordinal로 구분\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Value 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -1-> Null\n",
    "full_df = full_df.replace(-1,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval \n",
    "cols =list(meta[(meta['level']=='interval') & (meta['keep']==True)].index)\n",
    "#  Null Value  Portion\n",
    "# print(full_df[cols].isnull().sum()/full_df[cols].shape[0]*100)\n",
    "# 평균으로 처리\n",
    "full_df[cols] = full_df[cols].fillna(full_df[cols].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal : 순서형 자료 (매우높다, 높다, 낮다 등)\n",
    "cols =list(meta[(meta['level']=='ordinal') & (meta['keep']==True)].index)\n",
    "#  Null Value  Portion\n",
    "# print(full_df[cols].isnull().sum()/full_df[cols].shape[0]*100)\n",
    "# 최빈값을 넣어두자 \n",
    "full_df[cols] = full_df[cols].fillna(full_df[cols].mode().iloc[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norminal  : 카테고리 변수 --\n",
    "cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "#  Null Value  Portion\n",
    "# print(full_df[cols].isnull().sum()/full_df[cols].shape[0]*100)\n",
    "# Null 값을 하나의 카테고리로 분류  = '-999' 입력\n",
    "full_df[cols] = full_df[cols].fillna('-999')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary \n",
    "cols =list(meta[(meta['level']=='binary') & (meta['keep']==True)].index)\n",
    "#  Null Value  Portion\n",
    "# print(full_df[cols].isnull().sum()/full_df[cols].shape[0]*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freq encoding \n",
    "- 각 카테고리 컬럼의 빈도수를 카운트 한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal value에 대해\n",
    "cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "\n",
    "for col in cols :\n",
    "    col_name = '%s_count_full' % col\n",
    "    full_df[col_name] = full_df[col].map(full_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Catgory column별로 interval value 평균과 편차는 무슨 의미가 있을까\n",
    "\n",
    "# # full_df.head()\n",
    "# cat_cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "# cols = list(meta[(meta['level']!='nominal') & (meta['keep']==True)].index)\n",
    "# cols.remove('flag')\n",
    "# newcol_name = [x+'_avg' for x in cols]\n",
    "# for col in tqdm(cat_cols) :\n",
    "#     tmp = [x+'_for_%s'%col for x in newcol_name]\n",
    "#     for c,original  in zip(tmp,cols) :\n",
    "#         full_df[c] = full_df[col].map(full_df.groupby(col)[original].mean())\n",
    "# #     print(full_df.groupby(col)[cols].mean())\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interaction\n",
    "- 상관관계를 기반으로 곱하기를 해보자\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Car features\n",
    "ps_car_12 are (with some approximations) square roots (divided by 10) of natural numbers whilst ps_car_15 are square roots of natural numbers. Let's represent the values using pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = trainset.sample(frac=0.05)\n",
    "# var = ['ps_car_12', 'ps_car_15', 'target']\n",
    "# sample = sample[var]\n",
    "# sns.pairplot(sample,  hue='target', palette = 'Set1', diag_kind='kde')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the public kernels (wheel of fortune eg.) that suggest to remove *calc features,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in meta.index if 'calc' in x]\n",
    "meta.loc[cols,'keep'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Removing featues with low variance\n",
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "# sel.fit_transform(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree-based Feature selection\n",
    "#https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]\n",
      "  7%|█████▉                                                                             | 1/14 [00:01<00:16,  1.29s/it]\n",
      " 14%|███████████▊                                                                       | 2/14 [00:02<00:15,  1.29s/it]\n",
      " 21%|█████████████████▊                                                                 | 3/14 [00:03<00:13,  1.22s/it]\n",
      " 29%|███████████████████████▋                                                           | 4/14 [00:05<00:13,  1.33s/it]\n",
      " 36%|█████████████████████████████▋                                                     | 5/14 [00:06<00:11,  1.30s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 6/14 [00:06<00:08,  1.02s/it]\n",
      " 50%|█████████████████████████████████████████▌                                         | 7/14 [00:07<00:05,  1.26it/s]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 8/14 [00:08<00:05,  1.04it/s]\n",
      " 64%|█████████████████████████████████████████████████████▎                             | 9/14 [00:08<00:03,  1.31it/s]\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 10/14 [00:09<00:03,  1.16it/s]\n",
      " 79%|████████████████████████████████████████████████████████████████▍                 | 11/14 [00:10<00:02,  1.47it/s]\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 12/14 [00:11<00:01,  1.13it/s]\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▏     | 13/14 [00:11<00:00,  1.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:12<00:00,  1.74it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# nominal value에 대해\n",
    "cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "for col in tqdm(cols) :\n",
    "    lbl = LabelEncoder()\n",
    "    full_df[col] = lbl.fit_transform(list(full_df[col].values))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =list(meta[meta['keep']==False].index)\n",
    "cols  =[x for x in full_df.columns if x not in cols]\n",
    "full_df = full_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()\n",
    "train_df = full_df[full_df['flag']=='train'].drop(['flag'],axis =1 )\n",
    "test_df = full_df[full_df['flag']=='test'].drop(['flag'],axis =1 )\n",
    "target = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 51)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoding\n",
    "Target encoding with smoothing\n",
    "min_samples_leaf define a threshold where prior and target mean (for a given category value) have the same weight. Below the threshold prior becomes more important and above mean becomes more important.\n",
    "\n",
    "How weight behaves against value counts is controlled by smoothing parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_noise(series, noise_level):\n",
    "#     return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "# def target_encode(trn_series=None, \n",
    "#                   tst_series=None, \n",
    "#                   target=None, \n",
    "#                   min_samples_leaf=1, \n",
    "#                   smoothing=1,\n",
    "#                   noise_level=0):\n",
    "#     \"\"\"\n",
    "#     Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "#     https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "#     trn_series : training categorical feature as a pd.Series\n",
    "#     tst_series : test categorical feature as a pd.Series\n",
    "#     target : target data as a pd.Series\n",
    "#     min_samples_leaf (int) : minimum samples to take category average into account\n",
    "#     smoothing (int) : smoothing effect to balance categorical average vs prior  \n",
    "#     \"\"\" \n",
    "#     assert len(trn_series) == len(target)\n",
    "#     assert trn_series.name == tst_series.name\n",
    "#     temp = pd.concat([trn_series, target], axis=1)\n",
    "#     # Compute target mean \n",
    "#     averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "#     # Compute smoothing\n",
    "#     smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "#     # Apply average function to all target data\n",
    "#     prior = target.mean()\n",
    "#     # The bigger the count the less full_avg is taken into account\n",
    "#     averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "#     averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "#     # Apply averages to trn and tst series\n",
    "#     ft_trn_series = pd.merge(\n",
    "#         trn_series.to_frame(trn_series.name),\n",
    "#         averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "#         on=trn_series.name,\n",
    "#         how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "#     # pd.merge does not keep the index so restore it\n",
    "#     ft_trn_series.index = trn_series.index \n",
    "#     ft_tst_series = pd.merge(\n",
    "#         tst_series.to_frame(tst_series.name),\n",
    "#         averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "#         on=tst_series.name,\n",
    "#         how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "#     # pd.merge does not keep the index so restore it\n",
    "#     ft_tst_series.index = tst_series.index\n",
    "#     return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]\n",
      "  7%|█████▉                                                                             | 1/14 [00:00<00:02,  4.40it/s]\n",
      " 14%|███████████▊                                                                       | 2/14 [00:00<00:02,  4.48it/s]\n",
      " 21%|█████████████████▊                                                                 | 3/14 [00:00<00:02,  4.51it/s]\n",
      " 29%|███████████████████████▋                                                           | 4/14 [00:00<00:02,  4.60it/s]\n",
      " 36%|█████████████████████████████▋                                                     | 5/14 [00:01<00:01,  4.59it/s]\n",
      " 43%|███████████████████████████████████▌                                               | 6/14 [00:01<00:01,  4.64it/s]\n",
      " 50%|█████████████████████████████████████████▌                                         | 7/14 [00:01<00:01,  4.65it/s]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 8/14 [00:01<00:01,  4.61it/s]\n",
      " 64%|█████████████████████████████████████████████████████▎                             | 9/14 [00:01<00:01,  4.62it/s]\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 10/14 [00:02<00:00,  4.57it/s]\n",
      " 79%|████████████████████████████████████████████████████████████████▍                 | 11/14 [00:02<00:00,  4.58it/s]\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 12/14 [00:02<00:00,  4.59it/s]\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▏     | 13/14 [00:02<00:00,  4.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:03<00:00,  4.49it/s]"
     ]
    }
   ],
   "source": [
    "# # Nominal value에 대해\n",
    "# cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "\n",
    "# for col in tqdm(cols):\n",
    "#     col_name = '%s_target_enc' % col\n",
    "#     train_df[col_name],test_df[col_name] = target_encode(train_df[col], \n",
    "#                                              test_df[col], \n",
    "#                                              target=target, \n",
    "#                                              min_samples_leaf=100,\n",
    "#                                              smoothing=10,\n",
    "#                                              noise_level=0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_car_02_cat_target_enc</th>\n",
       "      <th>ps_car_03_cat_target_enc</th>\n",
       "      <th>ps_car_04_cat_target_enc</th>\n",
       "      <th>ps_car_05_cat_target_enc</th>\n",
       "      <th>ps_car_06_cat_target_enc</th>\n",
       "      <th>ps_car_07_cat_target_enc</th>\n",
       "      <th>ps_car_08_cat_target_enc</th>\n",
       "      <th>ps_car_09_cat_target_enc</th>\n",
       "      <th>ps_car_10_cat_target_enc</th>\n",
       "      <th>ps_car_11_cat_target_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033271</td>\n",
       "      <td>0.032586</td>\n",
       "      <td>0.033896</td>\n",
       "      <td>0.040799</td>\n",
       "      <td>0.033947</td>\n",
       "      <td>0.035021</td>\n",
       "      <td>0.044502</td>\n",
       "      <td>0.033129</td>\n",
       "      <td>0.036352</td>\n",
       "      <td>0.038279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033567</td>\n",
       "      <td>0.032878</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>0.034469</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>0.035923</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>0.023885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033950</td>\n",
       "      <td>0.032409</td>\n",
       "      <td>0.033498</td>\n",
       "      <td>0.031326</td>\n",
       "      <td>0.034721</td>\n",
       "      <td>0.035024</td>\n",
       "      <td>0.034983</td>\n",
       "      <td>0.035938</td>\n",
       "      <td>0.035904</td>\n",
       "      <td>0.031496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.038970</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>0.040539</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.034673</td>\n",
       "      <td>0.035028</td>\n",
       "      <td>0.035009</td>\n",
       "      <td>0.035725</td>\n",
       "      <td>0.044677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033573</td>\n",
       "      <td>0.032541</td>\n",
       "      <td>0.033655</td>\n",
       "      <td>0.031870</td>\n",
       "      <td>0.034280</td>\n",
       "      <td>0.035131</td>\n",
       "      <td>0.034745</td>\n",
       "      <td>0.036654</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.026163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0          2              2          5              2              1   \n",
       "1          1              1          7              1              1   \n",
       "2          5              4          9              2              1   \n",
       "3          0              1          2              1              1   \n",
       "4          0              2          0              2              1   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  \\\n",
       "0              0              1              0              0              0   \n",
       "1              0              0              1              0              0   \n",
       "2              0              0              1              0              0   \n",
       "3              1              0              0              0              0   \n",
       "4              1              0              0              0              0   \n",
       "\n",
       "   ...  ps_car_02_cat_target_enc  ps_car_03_cat_target_enc  \\\n",
       "0  ...                  0.033271                  0.032586   \n",
       "1  ...                  0.033567                  0.032878   \n",
       "2  ...                  0.033950                  0.032409   \n",
       "3  ...                  0.033346                  0.038970   \n",
       "4  ...                  0.033573                  0.032541   \n",
       "\n",
       "   ps_car_04_cat_target_enc  ps_car_05_cat_target_enc  \\\n",
       "0                  0.033896                  0.040799   \n",
       "1                  0.033816                  0.032007   \n",
       "2                  0.033498                  0.031326   \n",
       "3                  0.033283                  0.040539   \n",
       "4                  0.033655                  0.031870   \n",
       "\n",
       "   ps_car_06_cat_target_enc  ps_car_07_cat_target_enc  \\\n",
       "0                  0.033947                  0.035021   \n",
       "1                  0.031528                  0.034469   \n",
       "2                  0.034721                  0.035024   \n",
       "3                  0.031726                  0.034673   \n",
       "4                  0.034280                  0.035131   \n",
       "\n",
       "   ps_car_08_cat_target_enc  ps_car_09_cat_target_enc  \\\n",
       "0                  0.044502                  0.033129   \n",
       "1                  0.034424                  0.035923   \n",
       "2                  0.034983                  0.035938   \n",
       "3                  0.035028                  0.035009   \n",
       "4                  0.034745                  0.036654   \n",
       "\n",
       "   ps_car_10_cat_target_enc  ps_car_11_cat_target_enc  \n",
       "0                  0.036352                  0.038279  \n",
       "1                  0.036617                  0.023885  \n",
       "2                  0.035904                  0.031496  \n",
       "3                  0.035725                  0.044677  \n",
       "4                  0.036667                  0.026163  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature elimination : Xgboost 결과 Feature Importance 0.01 미만 삭제\n",
    "cols = ['ps_ind_10_bin',\n",
    " 'ps_ind_11_bin',\n",
    " 'ps_ind_12_bin',\n",
    " 'ps_ind_13_bin',\n",
    " 'ps_ind_14',\n",
    " 'ps_car_02_cat',\n",
    " 'ps_car_08_cat',\n",
    " 'ps_car_10_cat',\n",
    " 'ps_car_02_cat_count_full',\n",
    " 'ps_car_03_cat_count_full',\n",
    " 'ps_car_04_cat_count_full',\n",
    " 'ps_car_08_cat_count_full',\n",
    " 'ps_car_10_cat_count_full']\n",
    "\n",
    "train_df = train_df.drop(cols,axis =1)\n",
    "test_df = test_df.drop(cols,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling \n",
    "https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html\n",
    "https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "\n",
    "Apart from the random sampling with replacement, there are two popular methods to over-sample minority classes: (i) the Synthetic Minority Oversampling Technique (SMOTE) [CBHK2002] and (ii) the Adaptive Synthetic (ADASYN) [HBGL2008] sampling method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# sm = SMOTE(random_state = 99)\n",
    "# train_df_sm, target_sm = sm.fit_sample(train_df, target.ravel())\n",
    "# # SMOTE.fit_sample(train_df,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 37) (1147036, 37)\n",
      "(595212,) (1147036,)\n",
      "(21694,) 573518\n",
      "573518 21694\n",
      "573518 573518\n"
     ]
    }
   ],
   "source": [
    "# print(train_df.shape, train_df_sm.shape)\n",
    "# print(target.shape, target_sm.shape)\n",
    "# print(target[target==1].shape,np.sum(target_sm))\n",
    "# print(sum(target==0),sum(target==1))  # target ==1인 데이터가 26배가 되었다.\n",
    "# print(sum(target_sm==0),sum(target_sm==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df_sm.copy()\n",
    "# target= target_sm.copy()\n",
    "# train_df['target'] = target\n",
    "# target= train_df['target']\n",
    "# train_df = train_df.drop(['target'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JIT 컴파일(just-in-time compilation) 또는 동적 번역(dynamic translation)은 프로그램을 실제 실행하는 시점에\n",
    "기계어로 번역하는 컴파일 기법이다. 이 기법은 프로그램의 실행 속도를 빠르게 하기 위해 사용된다.\n",
    "\n",
    "\n",
    "출처: https://hamait.tistory.com/476 [HAMA 블로그]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "@jit\n",
    "\n",
    "#\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "early_stopping_round = 30\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds= 5\n",
    "kf = KFold(n_splits =n_folds, random_state = 99, shuffle =True)\n",
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = XGBClassifier( \n",
    "            n_estimators = 1000,\n",
    "            max_depth =4,\n",
    "    objective = \"binary:logistic\",\n",
    "    learing_rateing_rate = learning_rate,\n",
    "    subsample = .8,\n",
    "    min_child_weight = 6,\n",
    "    colsample_bytree = .8,\n",
    "    scale_pos_weight = 1.6,\n",
    "    gamma = 10,\n",
    "    reg_alpha = 8,\n",
    "    reg_lambda =1.3,\n",
    "    tree_method = 'gpu_hist'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.036449\tvalidation_0-gini:-0.183907\n",
      "Multiple eval metrics have been passed: 'validation_0-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-gini hasn't improved in 30 rounds.\n",
      "[50]\tvalidation_0-error:0.036449\tvalidation_0-gini:-0.263271\n",
      "[100]\tvalidation_0-error:0.036466\tvalidation_0-gini:-0.277449\n",
      "[150]\tvalidation_0-error:0.036466\tvalidation_0-gini:-0.281548\n",
      "[200]\tvalidation_0-error:0.036474\tvalidation_0-gini:-0.28276\n",
      "[250]\tvalidation_0-error:0.036474\tvalidation_0-gini:-0.283151\n",
      "Stopping. Best iteration:\n",
      "[240]\tvalidation_0-error:0.036474\tvalidation_0-gini:-0.283763\n",
      "\n",
      "Best N tress =  241\n",
      " Best gini =  0.283763\n",
      " Gini =  0.2837628086228603\n",
      "[0]\tvalidation_0-error:0.036449\tvalidation_0-gini:-0.193886\n",
      "Multiple eval metrics have been passed: 'validation_0-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-gini hasn't improved in 30 rounds.\n",
      "[50]\tvalidation_0-error:0.036449\tvalidation_0-gini:-0.268073\n",
      "[100]\tvalidation_0-error:0.036449\tvalidation_0-gini:-0.275294\n",
      "[150]\tvalidation_0-error:0.036432\tvalidation_0-gini:-0.27964\n",
      "[200]\tvalidation_0-error:0.036432\tvalidation_0-gini:-0.280818\n",
      "Stopping. Best iteration:\n",
      "[191]\tvalidation_0-error:0.036432\tvalidation_0-gini:-0.281417\n",
      "\n",
      "Best N tress =  192\n",
      " Best gini =  0.281417\n",
      " Gini =  0.2814172943344483\n",
      "[0]\tvalidation_0-error:0.036441\tvalidation_0-gini:-0.194739\n",
      "Multiple eval metrics have been passed: 'validation_0-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-gini hasn't improved in 30 rounds.\n",
      "[50]\tvalidation_0-error:0.036441\tvalidation_0-gini:-0.28038\n",
      "[100]\tvalidation_0-error:0.036441\tvalidation_0-gini:-0.29106\n",
      "[150]\tvalidation_0-error:0.036441\tvalidation_0-gini:-0.29381\n",
      "[200]\tvalidation_0-error:0.036449\tvalidation_0-gini:-0.294207\n",
      "Stopping. Best iteration:\n",
      "[176]\tvalidation_0-error:0.036449\tvalidation_0-gini:-0.295154\n",
      "\n",
      "Best N tress =  177\n",
      " Best gini =  0.295154\n",
      " Gini =  0.29515369437117867\n",
      "[0]\tvalidation_0-error:0.036449\tvalidation_0-gini:-0.193096\n",
      "Multiple eval metrics have been passed: 'validation_0-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-gini hasn't improved in 30 rounds.\n",
      "[50]\tvalidation_0-error:0.036458\tvalidation_0-gini:-0.269448\n",
      "[100]\tvalidation_0-error:0.036458\tvalidation_0-gini:-0.28092\n",
      "[150]\tvalidation_0-error:0.036466\tvalidation_0-gini:-0.28411\n",
      "[200]\tvalidation_0-error:0.036466\tvalidation_0-gini:-0.285295\n",
      "[250]\tvalidation_0-error:0.036466\tvalidation_0-gini:-0.285971\n",
      "Stopping. Best iteration:\n",
      "[241]\tvalidation_0-error:0.036466\tvalidation_0-gini:-0.286243\n",
      "\n",
      "Best N tress =  242\n",
      " Best gini =  0.286243\n",
      " Gini =  0.2862432132484517\n",
      "[0]\tvalidation_0-error:0.036449\tvalidation_0-gini:-0.186489\n",
      "Multiple eval metrics have been passed: 'validation_0-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_0-gini hasn't improved in 30 rounds.\n",
      "[50]\tvalidation_0-error:0.036449\tvalidation_0-gini:-0.259967\n",
      "[100]\tvalidation_0-error:0.036441\tvalidation_0-gini:-0.274551\n",
      "[150]\tvalidation_0-error:0.036433\tvalidation_0-gini:-0.278332\n",
      "[200]\tvalidation_0-error:0.036433\tvalidation_0-gini:-0.281054\n",
      "Stopping. Best iteration:\n",
      "[203]\tvalidation_0-error:0.036433\tvalidation_0-gini:-0.281356\n",
      "\n",
      "Best N tress =  204\n",
      " Best gini =  0.281356\n",
      " Gini =  0.28135636977197076\n",
      " Cross validadation score, Gini  0.28558667606978194\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "y_test_pred = []\n",
    "fi =[]\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    x_train,x_valid = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train,y_valid = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    eval_set = [(x_valid,y_valid)]\n",
    "    fit_model = model.fit(x_train,y_train,\n",
    "                         eval_set =eval_set,\n",
    "                         eval_metric = gini_xgb,\n",
    "                        early_stopping_rounds = early_stopping_round,\n",
    "                          verbose = 50\n",
    "                         )\n",
    "    print( \"Best N tress = \" , model.best_ntree_limit)\n",
    "    print(\" Best gini = \", -model.best_score)\n",
    "    fi.append(model.feature_importances_)\n",
    "#     plot_importance(fit_model)\n",
    "#     pyplot.show()\n",
    "#     selection = SelectFromModel(fit_model,threshold = 0.15,prefit =True)\n",
    "#     sel_x_train = selection.transform(x_train)\n",
    "#     sel_x_valid = selection.transform(x_valid)\n",
    "#     s_model = XGBClassifier()\n",
    "#     eval_set = [(sel_x_valid,y_valid)]\n",
    "#     fit_model = s_model.fit(sel_x_train,y_train,\n",
    "#                      eval_set =eval_set,\n",
    "#                      eval_metric = gini_xgb,\n",
    "#                     early_stopping_rounds = early_stopping_round,\n",
    "#                       verbose = 50\n",
    "#                      )\n",
    "    \n",
    "    #  prediction\n",
    "    pred = fit_model.predict_proba(x_valid)[:,1]\n",
    "    print( \" Gini = \", eval_gini(y_valid, pred))\n",
    "    scores.append(eval_gini(y_valid, pred))\n",
    "    y_test_pred.append(fit_model.predict_proba(test_df)[:,1])\n",
    "    \n",
    "    \n",
    "    del x_train,x_valid,y_train,y_valid\n",
    "    gc.collect()\n",
    "print(\" Cross validadation score, Gini \" ,sum(scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_ind_10_bin',\n",
       " 'ps_ind_11_bin',\n",
       " 'ps_ind_12_bin',\n",
       " 'ps_ind_13_bin',\n",
       " 'ps_ind_14',\n",
       " 'ps_car_02_cat',\n",
       " 'ps_car_08_cat',\n",
       " 'ps_car_10_cat',\n",
       " 'ps_car_02_cat_count_full',\n",
       " 'ps_car_03_cat_count_full',\n",
       " 'ps_car_04_cat_count_full',\n",
       " 'ps_car_08_cat_count_full',\n",
       " 'ps_car_10_cat_count_full']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importance = pd.DataFrame()\n",
    "# Importance['column'] = train_df.columns\n",
    "# Importance['Feature_Importance'] = np.mean(fi,axis =0)\n",
    "# list(Importance[Importance['Feature_Importance']<0.01]['column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame()\n",
    "sub_df['id'] = test['id']\n",
    "sub_df['target'] = sum(y_test_pred)/n_folds\n",
    "\n",
    "sub_df.to_csv('submission_baseline_XGBOOST_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_lgbm(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = eval_gini(labels, preds)\n",
    "    return 'gini', gini_score,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM\n",
    "import lightgbm as lgb\n",
    "seeds = 99\n",
    "params =  {\n",
    "        'objective': 'binary',\n",
    "        'num_threads': 4,\n",
    "        'learning_rate': 0.01, \n",
    "        'num_iterations' : 1000,\n",
    "        'max_depth': -1,\n",
    "        'reg_alpha': 0.3,\n",
    "         'reg_lambda': 0.3,\n",
    "        'bagging_seed' : seeds,\n",
    "        'verbose' : -1,\n",
    "        'seed' :seeds\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153469\tvalid_0's gini: 0.254685\n",
      "[200]\tvalid_0's binary_logloss: 0.152624\tvalid_0's gini: 0.267997\n",
      "[300]\tvalid_0's binary_logloss: 0.152298\tvalid_0's gini: 0.273225\n",
      "[400]\tvalid_0's binary_logloss: 0.152162\tvalid_0's gini: 0.275546\n",
      "[500]\tvalid_0's binary_logloss: 0.152089\tvalid_0's gini: 0.277333\n",
      "[600]\tvalid_0's binary_logloss: 0.152059\tvalid_0's gini: 0.278012\n",
      "[700]\tvalid_0's binary_logloss: 0.152036\tvalid_0's gini: 0.278568\n",
      "Early stopping, best iteration is:\n",
      "[706]\tvalid_0's binary_logloss: 0.152032\tvalid_0's gini: 0.278685\n",
      "(119043,)\n",
      " Gini =  0.2786854032195609\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153296\tvalid_0's gini: 0.261378\n",
      "[200]\tvalid_0's binary_logloss: 0.152385\tvalid_0's gini: 0.270735\n",
      "[300]\tvalid_0's binary_logloss: 0.152053\tvalid_0's gini: 0.274506\n",
      "[400]\tvalid_0's binary_logloss: 0.151895\tvalid_0's gini: 0.277016\n",
      "[500]\tvalid_0's binary_logloss: 0.151827\tvalid_0's gini: 0.278111\n",
      "Early stopping, best iteration is:\n",
      "[525]\tvalid_0's binary_logloss: 0.151816\tvalid_0's gini: 0.278379\n",
      "(119043,)\n",
      " Gini =  0.27837865658750505\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153216\tvalid_0's gini: 0.266925\n",
      "[200]\tvalid_0's binary_logloss: 0.152286\tvalid_0's gini: 0.279253\n",
      "[300]\tvalid_0's binary_logloss: 0.15189\tvalid_0's gini: 0.285217\n",
      "[400]\tvalid_0's binary_logloss: 0.151709\tvalid_0's gini: 0.288668\n",
      "[500]\tvalid_0's binary_logloss: 0.151642\tvalid_0's gini: 0.290025\n",
      "[600]\tvalid_0's binary_logloss: 0.151585\tvalid_0's gini: 0.29104\n",
      "[700]\tvalid_0's binary_logloss: 0.151555\tvalid_0's gini: 0.291665\n",
      "Early stopping, best iteration is:\n",
      "[734]\tvalid_0's binary_logloss: 0.151546\tvalid_0's gini: 0.291881\n",
      "(119042,)\n",
      " Gini =  0.29188127481541115\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153402\tvalid_0's gini: 0.259001\n",
      "[200]\tvalid_0's binary_logloss: 0.152518\tvalid_0's gini: 0.271662\n",
      "[300]\tvalid_0's binary_logloss: 0.152131\tvalid_0's gini: 0.278866\n",
      "[400]\tvalid_0's binary_logloss: 0.151958\tvalid_0's gini: 0.282181\n",
      "[500]\tvalid_0's binary_logloss: 0.151875\tvalid_0's gini: 0.283995\n",
      "[600]\tvalid_0's binary_logloss: 0.151832\tvalid_0's gini: 0.28526\n",
      "[700]\tvalid_0's binary_logloss: 0.151812\tvalid_0's gini: 0.285665\n",
      "Early stopping, best iteration is:\n",
      "[755]\tvalid_0's binary_logloss: 0.1518\tvalid_0's gini: 0.28591\n",
      "(119042,)\n",
      " Gini =  0.28591002211495165\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153516\tvalid_0's gini: 0.247805\n",
      "[200]\tvalid_0's binary_logloss: 0.15267\tvalid_0's gini: 0.262534\n",
      "[300]\tvalid_0's binary_logloss: 0.152354\tvalid_0's gini: 0.268863\n",
      "[400]\tvalid_0's binary_logloss: 0.152194\tvalid_0's gini: 0.272815\n",
      "[500]\tvalid_0's binary_logloss: 0.152115\tvalid_0's gini: 0.275453\n",
      "Early stopping, best iteration is:\n",
      "[520]\tvalid_0's binary_logloss: 0.152108\tvalid_0's gini: 0.275799\n",
      "(119042,)\n",
      " Gini =  0.27579922195807605\n",
      " Cross validadation score, Gini  0.282130915739101\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "y_test_pred= []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    x_train,x_valid = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train,y_valid = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(data = x_train, label = y_train)\n",
    "    lgb_valid = lgb.Dataset(data = x_valid, label = y_valid)\n",
    "    \n",
    "    lgb_model = lgb.train(params, lgb_train, valid_sets = [lgb_valid], \n",
    "                          feval = gini_lgbm,verbose_eval = 100, early_stopping_rounds = early_stopping_round)\n",
    "    \n",
    "    pred = lgb_model.predict(x_valid, num_iteration = lgb_model.best_iteration)\n",
    "#     pred = fit_model.predict_proba(x_valid)[:,1]\n",
    "    print(pred.shape)\n",
    "    print( \" Gini = \", eval_gini(y_valid, pred))\n",
    "    scores.append(eval_gini(y_valid, pred))\n",
    "    y_test_pred.append(lgb_model.predict(test_df))\n",
    "    \n",
    "    del x_train,x_valid,y_train,y_valid\n",
    "    gc.collect()\n",
    "print(\" Cross validadation score, Gini \" ,sum(scores)/n_folds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['id'] = test['id']\n",
    "sub_df['target'] = sum(y_test_pred)/n_folds\n",
    "\n",
    "sub_df.to_csv('submission_baseline_LGBM_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM_Categorical Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_lgbm(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = eval_gini(labels, preds)\n",
    "    return 'gini', gini_score,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal value에 대해\n",
    "cols =list(meta[(meta['level']=='nominal') & (meta['keep']==True)].index)\n",
    "\n",
    "# LGBM\n",
    "import lightgbm as lgb\n",
    "seeds = 99\n",
    "params =  {\n",
    "        'objective': 'binary',\n",
    "        'num_threads': 4,\n",
    "        'learning_rate': 0.01, \n",
    "        'num_iterations' : 1000,\n",
    "        'max_depth': -1,\n",
    "        'reg_alpha': 0.3,\n",
    "         'reg_lambda': 0.3,\n",
    "        'bagging_seed' : seeds,\n",
    "        'verbose' : -1,\n",
    "        'seed' :seeds\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.151767\tvalid_0's gini: 0.249186\n",
      "[200]\tvalid_0's binary_logloss: 0.150992\tvalid_0's gini: 0.257855\n",
      "[300]\tvalid_0's binary_logloss: 0.150695\tvalid_0's gini: 0.262629\n",
      "[400]\tvalid_0's binary_logloss: 0.150577\tvalid_0's gini: 0.265408\n",
      "[500]\tvalid_0's binary_logloss: 0.150535\tvalid_0's gini: 0.266414\n",
      "Early stopping, best iteration is:\n",
      "[531]\tvalid_0's binary_logloss: 0.150533\tvalid_0's gini: 0.266525\n",
      "(119043,)\n",
      " Gini =  0.2665252768135875\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.155468\tvalid_0's gini: 0.239307\n",
      "[200]\tvalid_0's binary_logloss: 0.154779\tvalid_0's gini: 0.248473\n",
      "[300]\tvalid_0's binary_logloss: 0.154578\tvalid_0's gini: 0.251739\n",
      "[400]\tvalid_0's binary_logloss: 0.154536\tvalid_0's gini: 0.252678\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid_0's binary_logloss: 0.154533\tvalid_0's gini: 0.252729\n",
      "(119043,)\n",
      " Gini =  0.252728996421557\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153911\tvalid_0's gini: 0.241924\n",
      "[200]\tvalid_0's binary_logloss: 0.153188\tvalid_0's gini: 0.251275\n",
      "[300]\tvalid_0's binary_logloss: 0.152962\tvalid_0's gini: 0.254059\n",
      "[400]\tvalid_0's binary_logloss: 0.152883\tvalid_0's gini: 0.255954\n",
      "Early stopping, best iteration is:\n",
      "[444]\tvalid_0's binary_logloss: 0.152861\tvalid_0's gini: 0.256926\n",
      "(119042,)\n",
      " Gini =  0.2569255262267083\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.154535\tvalid_0's gini: 0.26486\n",
      "[200]\tvalid_0's binary_logloss: 0.153658\tvalid_0's gini: 0.274561\n",
      "[300]\tvalid_0's binary_logloss: 0.153353\tvalid_0's gini: 0.27854\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's binary_logloss: 0.153344\tvalid_0's gini: 0.278664\n",
      "(119042,)\n",
      " Gini =  0.27866367154186966\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.151964\tvalid_0's gini: 0.241771\n",
      "[200]\tvalid_0's binary_logloss: 0.151275\tvalid_0's gini: 0.250982\n",
      "[300]\tvalid_0's binary_logloss: 0.151047\tvalid_0's gini: 0.254664\n",
      "[400]\tvalid_0's binary_logloss: 0.150964\tvalid_0's gini: 0.256748\n",
      "Early stopping, best iteration is:\n",
      "[394]\tvalid_0's binary_logloss: 0.150962\tvalid_0's gini: 0.256816\n",
      "(119042,)\n",
      " Gini =  0.2568162040605273\n",
      " Cross validadation score, Gini  0.26233193501284996\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "y_test_pred= []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    x_train,x_valid = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train,y_valid = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "#     x_train[cols] , x_valid[cols]= x_train[cols].astype(object), x_valid[cols].astype(object)\n",
    "    lgb_train = lgb.Dataset(data = x_train, label = y_train)\n",
    "    lgb_valid = lgb.Dataset(data = x_valid, label = y_valid)\n",
    "    \n",
    "    lgb_model = lgb.train(params, lgb_train, valid_sets = [lgb_valid], \n",
    "                          feval = gini_lgbm,verbose_eval = 100, early_stopping_rounds = early_stopping_round,\n",
    "                         categorical_feature=cols)\n",
    "        \n",
    "    pred = lgb_model.predict(x_valid, num_iteration = lgb_model.best_iteration)\n",
    "#     pred = fit_model.predict_proba(x_valid)[:,1]\n",
    "    print(pred.shape)\n",
    "    print( \" Gini = \", eval_gini(y_valid, pred))\n",
    "    scores.append(eval_gini(y_valid, pred))\n",
    "    y_test_pred.append(lgb_model.predict(test_df))\n",
    "    \n",
    "    del x_train,x_valid,y_train,y_valid\n",
    "    gc.collect()\n",
    "print(\" Cross validadation score, Gini \" ,sum(scores)/n_folds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['id'] = test['id']\n",
    "sub_df['target'] = sum(y_test_pred)/n_folds\n",
    "\n",
    "sub_df.to_csv('submission_baseline_LGBM_Cat_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "params =    {     #'iterations' : 2000,\n",
    "        'n_estimators': 2000,\n",
    "        'learning_rate': 0.05,\n",
    "        'eval_metric': 'RMSE',\n",
    "        'loss_function': 'RMSE',\n",
    "        'random_seed': seed,\n",
    "        'metric_period': 10,\n",
    "        'task_type': 'GPU',\n",
    "        #'subsample' : 0.8,\n",
    "        'depth': 8,\n",
    "    }\n",
    "\n",
    "model = CatBoostClassifier(iterations=2,\n",
    "                           learning_rate=1,\n",
    "                           depth=2)\n",
    "# Fit model\n",
    "model.fit(train_data, train_labels, cat_features)\n",
    "# Get predicted classes\n",
    "preds_class = model.predict(eval_data)\n",
    "# Get predicted probabilities for each class\n",
    "preds_proba = model.predict_proba(eval_data)\n",
    "# Get predicted RawFormulaVal\n",
    "preds_raw = model.predict(eval_data, prediction_type='RawFormulaVal')\n",
    "\n",
    "\n",
    " gbm = CatBoostRegressor(**params)\n",
    "    print(i)\n",
    "    gbm.fit(\n",
    "            train_X, train_y,\n",
    "             eval_set=(val_X, val_y),\n",
    "            early_stopping_rounds = 30,\n",
    "            cat_features=categorical_features,\n",
    "            verbose=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ve used this to get a network that has a local CV AUC around 0.642, which corresponds to Gini of 0.284. \n",
    "\n",
    "the formula GINI = 2 * AUC -1\n",
    "2*AUC-1 will be same as calculated with gini_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# https://www.kaggle.com/rspadim/gini-keras-callback-earlystopping-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold = StratifiedKFold(n_splits = K, \n",
    "#                             random_state = 100, \n",
    "#                             shuffle = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "# FROM https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41108\n",
    "def jacek_auc(y_true, y_pred):\n",
    "    score, up_opt = tf.metrics.auc(y_true, y_pred)\n",
    "    #score, up_opt = tf.contrib.metrics.streaming_auc(y_pred, y_true)    \n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    with tf.control_dependencies([up_opt]):\n",
    "        score = tf.identity(score)\n",
    "    return score\n",
    "\n",
    "# FROM https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41015\n",
    "# AUC for a binary classifier\n",
    "def discussion41015_auc(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "\n",
    "# PFA, prob false alert for binary classifier\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "\n",
    "#----------------\n",
    "# P_TA prob true alerts for binary classifier\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    "\n",
    "\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/tomcwalker/keras-nn-with-custom-loss-function-for-gini-auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mlp = keras.utils.np_utils.to_categorical(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 22s - loss: 1211.5840 - jacek_auc: 0.9342\n",
      "Epoch 2/1000\n",
      " - 21s - loss: 0.4911 - jacek_auc: 0.9556\n",
      "Epoch 3/1000\n",
      " - 21s - loss: 0.2010 - jacek_auc: 0.9588\n",
      "Epoch 4/1000\n",
      " - 21s - loss: 0.3525 - jacek_auc: 0.9601\n",
      "Epoch 5/1000\n",
      " - 21s - loss: 0.1726 - jacek_auc: 0.9608\n",
      "Epoch 6/1000\n",
      " - 21s - loss: 0.1830 - jacek_auc: 0.9613\n",
      "Epoch 7/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9617\n",
      "Epoch 8/1000\n",
      " - 21s - loss: 0.2207 - jacek_auc: 0.9619\n",
      "Epoch 9/1000\n",
      " - 21s - loss: 0.1582 - jacek_auc: 0.9619\n",
      "Epoch 10/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9622\n",
      "Epoch 11/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9623\n",
      "Epoch 12/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9624\n",
      "Epoch 13/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9625\n",
      "Epoch 14/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9625\n",
      "Epoch 15/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9625\n",
      "Epoch 16/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9628\n",
      "Epoch 17/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9628\n",
      "Epoch 18/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9628\n",
      "Epoch 19/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9628\n",
      "Epoch 20/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 21/1000\n",
      " - 21s - loss: 0.1583 - jacek_auc: 0.9629\n",
      "Epoch 22/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 23/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 24/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 25/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 26/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 27/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 28/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 29/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9629\n",
      "Epoch 30/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 31/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 32/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 33/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 34/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 35/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 36/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 37/1000\n",
      " - 22s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 38/1000\n",
      " - 22s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 39/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 40/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 41/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 42/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 43/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9630\n",
      "Epoch 44/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 45/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 46/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 47/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 48/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 49/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 50/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 51/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 52/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 53/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 54/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 55/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 56/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 57/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 58/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 59/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 60/1000\n",
      " - 24s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 61/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 62/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 63/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 64/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 65/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 66/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 67/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 68/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 69/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 70/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 71/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 72/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 73/1000\n",
      " - 22s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 74/1000\n",
      " - 22s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 75/1000\n",
      " - 22s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 76/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 77/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 78/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 79/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 80/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 81/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 82/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 83/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 84/1000\n",
      " - 21s - loss: 0.1569 - jacek_auc: 0.9632\n",
      "Epoch 00084: early stopping\n",
      "0 Gini  [-0.00273351  0.00271041]\n",
      "Epoch 1/1000\n",
      " - 21s - loss: 520.6350 - jacek_auc: 0.9417\n",
      "Epoch 2/1000\n",
      " - 20s - loss: 0.2661 - jacek_auc: 0.9575\n",
      "Epoch 3/1000\n",
      " - 20s - loss: 0.3227 - jacek_auc: 0.9601\n",
      "Epoch 4/1000\n",
      " - 20s - loss: 0.1643 - jacek_auc: 0.9611\n",
      "Epoch 5/1000\n",
      " - 20s - loss: 0.1702 - jacek_auc: 0.9617\n",
      "Epoch 6/1000\n",
      " - 22s - loss: 0.1560 - jacek_auc: 0.9619\n",
      "Epoch 7/1000\n",
      " - 22s - loss: 0.1560 - jacek_auc: 0.9623\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-37f047bd3488>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m        \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m        \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcallback_early_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m        verbose = 2)\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 1000\n",
    "learning_rate = 0.001\n",
    "scores = []\n",
    "y_test_pred= []\n",
    "\n",
    "def mlpmodel(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation ='relu', input_dim = input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(Dense(64,activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2,activation='sigmoid'))\n",
    "    adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "    model.compile(loss ='binary_crossentropy',\n",
    "                 optimizer = adam,metrics = [jacek_auc])\n",
    "\n",
    "    return model\n",
    "\n",
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='jacek_auc', patience=10, verbose=2, mode='max')\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    x_train,x_valid = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train,y_valid = target_mlp[train_index], target_mlp[test_index]\n",
    "    \n",
    "    \n",
    "    mlp = mlpmodel(x_train.shape[1])\n",
    "    mlp.fit(x_train,y_train,\n",
    "       epochs = epochs,\n",
    "       batch_size = batch_size,\n",
    "       callbacks = [callback_early_stopping],\n",
    "       verbose = 2)\n",
    "    \n",
    "    \n",
    "    pred  = mlp.predict(x_valid)\n",
    "    score = -eval_gini(y_valid, pred[:,0])\n",
    "    scores.append(score)\n",
    "    print(i, \"Gini \", score )\n",
    "    \n",
    "    y_test_pred.append(mlp.predict(test_df))\n",
    "#     mlp.predict(test_df)\n",
    "    del x_train,x_valid,y_train,y_valid\n",
    "    gc.collect()\n",
    "\n",
    "print(\" Cross validadation score, Gini \" ,sum(scores)/n_folds)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['id'] = test['id']\n",
    "sub_df['target'] = sum(y_test_pred)/n_folds\n",
    "\n",
    "sub_df.to_csv('submission_baseline_MLP_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03637472, 0.03637472, 0.03637472, ..., 0.03637472, 0.03637472,\n",
       "       0.03637472], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.backend' from 'C:\\\\Users\\\\yseon\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\keras\\\\backend\\\\__init__.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
