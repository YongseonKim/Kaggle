{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/virajbagal/fast-ai-mixup-cutmix-augmix-and-gridmask-visuals\n",
    "# https://www.kaggle.com/ipythonx/keras-grapheme-gridmask-augmix-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "import time, gc\n",
    "import cv2\n",
    "\n",
    "from tensorflow import keras\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.utils import Sequence\n",
    "from pathlib import Path\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, ImageOnlyTransform\n",
    "from albumentations.augmentations import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ = pd.read_csv('bengaliai-cv19/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(class_map_df.head())\n",
    "# class_map_df['component_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=64\n",
    "SEED = 999\n",
    "N_CHANNELS = 1\n",
    "im_path = 'bengaliai-cv19/'\n",
    "stats = (0.0692, 0.2051)\n",
    "datadir = Path('bengaliai-cv19/')\n",
    "featherdir = Path('bengaliai-cv19/bengaliaicv19feather')\n",
    "outdir = Path('.')\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_image(datadir, featherdir, data_type='train',\n",
    "#                   submission=False, indices=[0, 1, 2, 3]):\n",
    "#     assert data_type in ['train', 'test']\n",
    "#     if submission:\n",
    "#         image_df_list = [pd.read_parquet(datadir / f'{data_type}_image_data_{i}.parquet')\n",
    "#                          for i in indices]\n",
    "#     else:\n",
    "#         image_df_list = [pd.read_feather(featherdir / f'{data_type}_image_data_{i}.feather')\n",
    "#                          for i in indices]\n",
    "\n",
    "#     print('image_df_list', len(image_df_list))\n",
    "#     HEIGHT = 137\n",
    "#     WIDTH = 236\n",
    "#     images = [df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH) for df in image_df_list]\n",
    "#     del image_df_list\n",
    "#     gc.collect()\n",
    "#     images = np.concatenate(images, axis=0)\n",
    "#     return images\n",
    "\n",
    "# # train = pd.read_csv(datadir/'train.csv')\n",
    "# # train_labels = train[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "# indices = [0, 1, 2, 3]\n",
    "# train_images = prepare_image(\n",
    "#     datadir, featherdir, data_type='train', submission=False, indices=indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphemeGenerator(Sequence):\n",
    "    def __init__(self, data, batch_size, IMG_SIZE, shuffle=True, transform=None):\n",
    "        self._data = data\n",
    "        self._label_1 = pd.get_dummies(self._data['grapheme_root'], \n",
    "                                       columns = ['grapheme_root'])\n",
    "        self._label_2 = pd.get_dummies(self._data['vowel_diacritic'], \n",
    "                                       columns = ['vowel_diacritic'])\n",
    "        self._label_3 = pd.get_dummies(self._data['consonant_diacritic'], \n",
    "                                       columns = ['consonant_diacritic'])\n",
    "        self._list_idx = data.index.values\n",
    "        \n",
    "        self._data = self._data.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic','grapheme'], axis=1)    \n",
    "        self._data = self.preprocess_resizing()\n",
    "        \n",
    "        self._batch_size = batch_size\n",
    "        self._dim = (IMG_SIZE,IMG_SIZE)\n",
    "        self._img_size = IMG_SIZE\n",
    "        self._shuffle = shuffle\n",
    "        self.transform = transform\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self._data)/self._batch_size))\n",
    "    \n",
    "    def preprocess_resizing(self):\n",
    "        resized = {}\n",
    "#         print(self._data)\n",
    "        lst = list(self._data.index)\n",
    "        for x in tqdm(range(len(lst))):\n",
    "            img = self._data.loc[lst[x]].values.reshape(137,236)\n",
    "            img = crop_char_image(img)\n",
    "            img = cv2.resize(img,  (IMG_SIZE,IMG_SIZE)) \n",
    "            resized[self._data.index[x]] =img.reshape(-1)\n",
    "        resized =pd.DataFrame(resized).T\n",
    "        return resized\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        batch_idx = self._indices[index*self._batch_size:(index+1)*self._batch_size]\n",
    "        _idx = [self._list_idx[k] for k in batch_idx]\n",
    "\n",
    "        Data     = np.empty((self._batch_size, *self._dim, 1))\n",
    "        Target_1 = np.empty((self._batch_size, 168), dtype = int)\n",
    "        Target_2 = np.empty((self._batch_size, 11 ), dtype = int)\n",
    "        Target_3 = np.empty((self._batch_size,  7 ), dtype = int)\n",
    "        \n",
    "        for i, k in enumerate(_idx):\n",
    "            # load the image file using cv2\n",
    "\n",
    "#             image=self._data.loc[k].values.reshape(137,236)\n",
    "            image=self._data.loc[k].values.reshape(64,64)\n",
    "#             image = cv2.imread(im_path + self._data['image_id'][k] + '.png')\n",
    "            \n",
    "            # Cropping 부분이 속도를 에폭당 40초를 늘린다.\n",
    "#             image = crop_char_image(image)\n",
    "#             image = cv2.resize(image,  self._dim) \n",
    "            # 에폭당 30초 더걸림\n",
    "#             image =  crop_resize(image)\n",
    "#             → 전처리로 다 변경했다.\n",
    "\n",
    "            image = image.reshape(self._img_size,self._img_size,1)\n",
    "        \n",
    "            if self.transform is not None:\n",
    "                if np.random.rand() > 0.7:\n",
    "                    # albumentation : grid mask\n",
    "                    res = self.transform(image=image)\n",
    "                    image = res['image']\n",
    "                    # Affine Image\n",
    "                    image = affine_image(image)\n",
    "                    \n",
    "                    \n",
    "#                 else:\n",
    "                    # augmix augmentation\n",
    "#                     image = augment_and_mix(image)\n",
    "            \n",
    "            # scaling \n",
    "            image = (image.astype(np.float32)/255.0 - stats[0])/stats[1]\n",
    "            \n",
    "            # gray scaling \n",
    "#             gray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114]) \n",
    "#             image = gray(image)  \n",
    "            \n",
    "#             # expand the axises \n",
    "#             image = image[:, :, np.newaxis]\n",
    "\n",
    "            \n",
    "            Data[i,:, :, :] =  image\n",
    "        \n",
    "            Target_1[i,:] = self._label_1.loc[k, :].values\n",
    "            Target_2[i,:] = self._label_2.loc[k, :].values\n",
    "            Target_3[i,:] = self._label_3.loc[k, :].values\n",
    "            \n",
    "        return Data, [Target_1, Target_2, Target_3]\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self._indices = np.arange(len(self._list_idx))\n",
    "        if self._shuffle:\n",
    "            np.random.shuffle(self._indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에폭당 40초 이상 더 걸린다.\n",
    "def crop_char_image(image, threshold=5./255.):\n",
    "    assert image.ndim == 2\n",
    "    is_black = image > threshold\n",
    "\n",
    "    is_black_vertical = np.sum(is_black, axis=0) > 0\n",
    "    is_black_horizontal = np.sum(is_black, axis=1) > 0\n",
    "    left = np.argmax(is_black_horizontal)\n",
    "    right = np.argmax(is_black_horizontal[::-1])\n",
    "    top = np.argmax(is_black_vertical)\n",
    "    bottom = np.argmax(is_black_vertical[::-1])\n",
    "    height, width = image.shape\n",
    "    cropped_image = image[left:height - right, top:width - bottom]\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에폭당 30초 더걸림\n",
    "# helper function\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def crop_resize(img0, size=IMG_SIZE, pad=16):\n",
    "    #crop a box around pixels large than the threshold \n",
    "    #some images contain line at the sides\n",
    "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "    #cropping may cut too much, so we need to add it back\n",
    "    xmin = xmin - 13 if (xmin > 13) else 0\n",
    "    ymin = ymin - 10 if (ymin > 10) else 0\n",
    "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
    "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
    "    img = img0[ymin:ymax,xmin:xmax]\n",
    "    #remove lo intensity pixels as noise\n",
    "    img[img < 28] = 0\n",
    "    lx, ly = xmax-xmin,ymax-ymin\n",
    "    l = max(lx,ly) + pad\n",
    "    #make sure that the aspect ratio is kept in rescaling\n",
    "    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "    \n",
    "    return cv2.resize(img,(size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmix : https://github.com/google-research/augmix\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "\n",
    "def int_parameter(level, maxval):\n",
    "    \"\"\"Helper function to scale `val` between 0 and maxval .\n",
    "    Args:\n",
    "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
    "    maxval: Maximum value that the operation can have. This will be scaled to\n",
    "      level/PARAMETER_MAX.\n",
    "    Returns:\n",
    "    An int that results from scaling `maxval` according to `level`.\n",
    "    \"\"\"\n",
    "    return int(level * maxval / 10)\n",
    "\n",
    "\n",
    "def float_parameter(level, maxval):\n",
    "    \"\"\"Helper function to scale `val` between 0 and maxval.\n",
    "    Args:\n",
    "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
    "    maxval: Maximum value that the operation can have. This will be scaled to\n",
    "      level/PARAMETER_MAX.\n",
    "    Returns:\n",
    "    A float that results from scaling `maxval` according to `level`.\n",
    "    \"\"\"\n",
    "    return float(level) * maxval / 10.\n",
    "\n",
    "def sample_level(n):\n",
    "    return np.random.uniform(low=0.1, high=n)\n",
    "\n",
    "def autocontrast(pil_img, _):\n",
    "    return ImageOps.autocontrast(pil_img)\n",
    "\n",
    "def equalize(pil_img, _):\n",
    "    return ImageOps.equalize(pil_img)\n",
    "\n",
    "def posterize(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), 4)\n",
    "    return ImageOps.posterize(pil_img, 4 - level)\n",
    "\n",
    "def rotate(pil_img, level):\n",
    "    degrees = int_parameter(sample_level(level), 30)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        degrees = -degrees\n",
    "    return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
    "\n",
    "def solarize(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), 256)\n",
    "    return ImageOps.solarize(pil_img, 256 - level)\n",
    "\n",
    "def shear_x(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 0.3)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((IMG_SIZE, IMG_SIZE),\n",
    "                           Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "def shear_y(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 0.3)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((IMG_SIZE, IMG_SIZE),\n",
    "                           Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "def translate_x(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), IMG_SIZE / 3)\n",
    "    if np.random.random() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((IMG_SIZE, IMG_SIZE),\n",
    "                           Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "def translate_y(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), IMG_SIZE / 3)\n",
    "    if np.random.random() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((IMG_SIZE, IMG_SIZE),\n",
    "                           Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "augmentations = [\n",
    "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
    "    translate_x, translate_y\n",
    "]\n",
    "\n",
    "# taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "\n",
    "def normalize(image):\n",
    "    \"\"\"Normalize input image channel-wise to zero mean and unit variance.\"\"\"\n",
    "    image = image.transpose(2, 0, 1)  # Switch to channel-first\n",
    "    mean, std = np.array(MEAN), np.array(STD)\n",
    "    image = (image - mean[:, None, None]) / std[:, None, None]\n",
    "    return image.transpose(1, 2, 0)\n",
    "#     return image\n",
    "    \n",
    "\n",
    "\n",
    "def apply_op(image, op, severity):\n",
    "    image = np.clip(image * 255., 0, 255).astype(np.uint8)\n",
    "    print(image.shape)\n",
    "    pil_img = Image.fromarray(image)  # Convert to PIL.Image\n",
    "    pil_img = op(pil_img, severity)\n",
    "    return np.asarray(pil_img) / 255.\n",
    "\n",
    "\n",
    "def augment_and_mix(image, severity=1, width=3, depth=1, alpha=1.):\n",
    "    \"\"\"Perform AugMix augmentations and compute mixture.\n",
    "    Args:\n",
    "    image: Raw input image as float32 np.ndarray of shape (h, w, c)\n",
    "    severity: Severity of underlying augmentation operators (between 1 to 10).\n",
    "    width: Width of augmentation chain\n",
    "    depth: Depth of augmentation chain. -1 enables stochastic depth uniformly\n",
    "      from [1, 3]\n",
    "    alpha: Probability coefficient for Beta and Dirichlet distributions.\n",
    "    Returns:\n",
    "    mixed: Augmented and mixed image.\n",
    "  \"\"\"\n",
    "    ws = np.float32(\n",
    "      np.random.dirichlet([alpha] * width))\n",
    "    m = np.float32(np.random.beta(alpha, alpha))\n",
    "\n",
    "    mix = np.zeros_like(image)\n",
    "    for i in range(width):\n",
    "        image_aug = image.copy()\n",
    "        depth = depth if depth > 0 else np.random.randint(1, 4)\n",
    "        \n",
    "        for _ in range(depth):\n",
    "            op = np.random.choice(augmentations)\n",
    "            image_aug = apply_op(image_aug, op, severity)\n",
    "        mix = np.add(mix, ws[i] * normalize(image_aug), out=mix, \n",
    "                     casting=\"unsafe\")\n",
    "\n",
    "    mixed = (1 - m) * normalize(image) + m * mix\n",
    "    return mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridMask(DualTransform):\n",
    "    \"\"\"GridMask augmentation for image classification and object detection.\n",
    "\n",
    "    Args:\n",
    "        num_grid (int): number of grid in a row or column.\n",
    "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
    "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
    "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
    "        mode (int):\n",
    "            0 - cropout a quarter of the square of each grid (left top)\n",
    "            1 - reserve a quarter of the square of each grid (left top)\n",
    "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
    "\n",
    "    Targets:\n",
    "        image, mask\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "\n",
    "    Reference:\n",
    "    |  https://arxiv.org/abs/2001.04086\n",
    "    |  https://github.com/akuxcw/GridMask\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "\n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        return image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이게 느리다.\n",
    "\n",
    "\"\"\"\n",
    "From https://www.kaggle.com/corochann/deep-learning-cnn-with-chainer-lb-0-99700\n",
    "\"\"\"\n",
    "import cv2\n",
    "from skimage.transform import AffineTransform, warp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def affine_image(img):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        img: (h, w) or (1, h, w)\n",
    "\n",
    "    Returns:\n",
    "        img: (h, w)\n",
    "    \"\"\"\n",
    "    # ch, h, w = img.shape\n",
    "    # img = img / 255.\n",
    "    if img.ndim == 3:\n",
    "        img = img[0]\n",
    "\n",
    "    # --- scale ---\n",
    "    min_scale = 0.8\n",
    "    max_scale = 1.2\n",
    "    sx = np.random.uniform(min_scale, max_scale)\n",
    "    sy = np.random.uniform(min_scale, max_scale)\n",
    "\n",
    "    # --- rotation ---\n",
    "    max_rot_angle = 7\n",
    "    rot_angle = np.random.uniform(-max_rot_angle, max_rot_angle) * np.pi / 180.\n",
    "\n",
    "    # --- shear ---\n",
    "    max_shear_angle = 10\n",
    "    shear_angle = np.random.uniform(-max_shear_angle, max_shear_angle) * np.pi / 180.\n",
    "\n",
    "    # --- translation ---\n",
    "    max_translation = 4\n",
    "    tx = np.random.randint(-max_translation, max_translation)\n",
    "    ty = np.random.randint(-max_translation, max_translation)\n",
    "\n",
    "    tform = AffineTransform(scale=(sx, sy), rotation=rot_angle, shear=shear_angle,\n",
    "                            translation=(tx, ty))\n",
    "    transformed_image = warp(img, tform)\n",
    "    assert transformed_image.ndim == 2\n",
    "    return transformed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_applications.resnext import ResNeXt101\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras_efficientnets import EfficientNetB3\n",
    "from keras import backend as K\n",
    "from keras import layers, models, optimizers, utils, backend,regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, GlobalAveragePooling2D\n",
    "from keras import layers, models, optimizers, utils, backend,regularizers\n",
    "from keras.layers import LeakyReLU\n",
    "def get_model(model_name='EfficientNetB3'):\n",
    "#     inputs = Input(shape = (IMG_SIZE, IMG_SIZE, 1))\n",
    "    pretrained_model = EfficientNetB3(weights=\"imagenet\", include_top=False, input_shape=(64,64,3))\n",
    "#     resNet_model = DenseNet121(include_top= False, input_shape = (128,128,3)\n",
    "#                             , backend =backend, layers=layers, models = models,\n",
    "#                              utils = utils\n",
    "#                             )\n",
    "    \n",
    "    \n",
    "    inputs = Input(shape = (IMG_SIZE, IMG_SIZE, 1))\n",
    "    model = Conv2D(3, (3, 3), padding='same')(inputs)\n",
    "    model = pretrained_model(model)\n",
    "\n",
    "\n",
    "#     model = resNet_model.layers[-1].output\n",
    "    model = GlobalAveragePooling2D()(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "    \n",
    "#     model = Flatten()(model)\n",
    "    model = Dense(1024, activation = \"relu\")(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "    dense = Dense(512, activation = \"relu\")(model)\n",
    "    \n",
    "    head_root = Dense(168, activation = 'softmax',name = 'root')(model)\n",
    "    head_vowel = Dense(11, activation = 'softmax', name ='vowel')(model)\n",
    "    head_consonant = Dense(7, activation = 'softmax', name = 'consonant')(model)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])\n",
    "    \n",
    "    model.summary()\n",
    "    adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "   \n",
    "    model.compile( optimizer = adam, \n",
    "                 loss = {'root' : 'categorical_crossentropy', \n",
    "                        'vowel' : 'categorical_crossentropy', \n",
    "                        'consonant': 'categorical_crossentropy'},\n",
    "               metrics = {'root' : 'accuracy', \n",
    "                        'vowel' : 'accuracy', \n",
    "                        'consonant': 'accuracy'}\n",
    "                 )\n",
    "#     model.compile(optimizer = adam,loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    # compile 할때 넣어줘야지 아래에서 early stopping 할때 사용 가능하다\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-154615619aa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-0f4f5bcdf6a7>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpretrained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer. Learning rate will be half after 3 epochs if accuracy is not increased\n",
    "from keras.callbacks import  EarlyStopping\n",
    "# root_accuracy: 0.7609 - vowel_accuracy: 0.9383 - consonant_accuracy: 0.9436 \n",
    "learning_rate_reduction_root = ReduceLROnPlateau(monitor='root_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_vowel = ReduceLROnPlateau(monitor='vowel_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_consonant = ReduceLROnPlateau(monitor='consonant_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "# Callback : Early Stop\n",
    "earlyStop = EarlyStopping(monitor='val_root_accuracy',#'val_loss',\n",
    "                          mode = 'max',\n",
    "                          patience = 10,\n",
    "                          min_delta = 0,\n",
    "                          verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "epochs = 100\n",
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n",
    "    RandomBrightness, RandomContrast, RandomGamma,\n",
    "    ToFloat, ShiftScaleRotate\n",
    ")\n",
    "# grid mask augmentation\n",
    "transforms_train = albumentations.Compose([\n",
    "#     GridMask(num_grid=3, rotate=15, p=1),\n",
    "    \n",
    "    # 학습이 안된다. 이건\n",
    "#     ShiftScaleRotate(\n",
    "#         shift_limit=0.0625, scale_limit=0.1, \n",
    "#         rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f9f57c4b83408d87f520e9ca463757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=45189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539120e095ca44cdad356546dfc29d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5021.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yseon\\Anaconda3\\envs\\bengali\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 54s 362ms/step - loss: 7.8754 - root_loss: 4.8747 - vowel_loss: 1.7586 - consonant_loss: 1.2421 - root_accuracy: 0.0273 - vowel_accuracy: 0.3939 - consonant_accuracy: 0.5882 - val_loss: 7.7046 - val_root_loss: 4.7762 - val_vowel_loss: 1.6918 - val_consonant_loss: 1.2572 - val_root_accuracy: 0.0317 - val_vowel_accuracy: 0.4471 - val_consonant_accuracy: 0.6398\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 6.2279 - root_loss: 4.5050 - vowel_loss: 0.9034 - consonant_loss: 0.8195 - root_accuracy: 0.0524 - vowel_accuracy: 0.6924 - consonant_accuracy: 0.7192 - val_loss: 5.9359 - val_root_loss: 4.3468 - val_vowel_loss: 0.8073 - val_consonant_loss: 0.7559 - val_root_accuracy: 0.0667 - val_vowel_accuracy: 0.7231 - val_consonant_accuracy: 0.7375\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 5.2945 - root_loss: 4.1265 - vowel_loss: 0.5928 - consonant_loss: 0.5752 - root_accuracy: 0.0858 - vowel_accuracy: 0.7958 - consonant_accuracy: 0.7983 - val_loss: 5.0482 - val_root_loss: 3.9185 - val_vowel_loss: 0.5674 - val_consonant_loss: 0.5427 - val_root_accuracy: 0.1148 - val_vowel_accuracy: 0.8050 - val_consonant_accuracy: 0.8060\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 4.4973 - root_loss: 3.6471 - vowel_loss: 0.4386 - consonant_loss: 0.4116 - root_accuracy: 0.1413 - vowel_accuracy: 0.8495 - consonant_accuracy: 0.8539 - val_loss: 4.4405 - val_root_loss: 3.4523 - val_vowel_loss: 0.4730 - val_consonant_loss: 0.4625 - val_root_accuracy: 0.1785 - val_vowel_accuracy: 0.8398 - val_consonant_accuracy: 0.8390\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 3.7486 - root_loss: 3.1081 - vowel_loss: 0.3324 - consonant_loss: 0.3081 - root_accuracy: 0.2219 - vowel_accuracy: 0.8864 - consonant_accuracy: 0.8897 - val_loss: 4.0039 - val_root_loss: 3.0531 - val_vowel_loss: 0.4364 - val_consonant_loss: 0.4191 - val_root_accuracy: 0.2467 - val_vowel_accuracy: 0.8521 - val_consonant_accuracy: 0.8556\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 3.0679 - root_loss: 2.5924 - vowel_loss: 0.2544 - consonant_loss: 0.2211 - root_accuracy: 0.3210 - vowel_accuracy: 0.9143 - consonant_accuracy: 0.9225 - val_loss: 3.7787 - val_root_loss: 2.7388 - val_vowel_loss: 0.4175 - val_consonant_loss: 0.4188 - val_root_accuracy: 0.2990 - val_vowel_accuracy: 0.8635 - val_consonant_accuracy: 0.8627\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 2.4618 - root_loss: 2.1222 - vowel_loss: 0.1893 - consonant_loss: 0.1503 - root_accuracy: 0.4217 - vowel_accuracy: 0.9364 - consonant_accuracy: 0.9474 - val_loss: 3.6174 - val_root_loss: 2.5389 - val_vowel_loss: 0.4269 - val_consonant_loss: 0.4622 - val_root_accuracy: 0.3423 - val_vowel_accuracy: 0.8621 - val_consonant_accuracy: 0.8654\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.9417 - root_loss: 1.7020 - vowel_loss: 0.1376 - consonant_loss: 0.1022 - root_accuracy: 0.5238 - vowel_accuracy: 0.9542 - consonant_accuracy: 0.9657 - val_loss: 3.4853 - val_root_loss: 2.3695 - val_vowel_loss: 0.4267 - val_consonant_loss: 0.4724 - val_root_accuracy: 0.3746 - val_vowel_accuracy: 0.8712 - val_consonant_accuracy: 0.8600\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.5215 - root_loss: 1.3452 - vowel_loss: 0.1032 - consonant_loss: 0.0731 - root_accuracy: 0.6161 - vowel_accuracy: 0.9669 - consonant_accuracy: 0.9750 - val_loss: 3.4806 - val_root_loss: 2.3218 - val_vowel_loss: 0.4396 - val_consonant_loss: 0.5019 - val_root_accuracy: 0.4002 - val_vowel_accuracy: 0.8742 - val_consonant_accuracy: 0.8692\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 1.1827 - root_loss: 1.0488 - vowel_loss: 0.0777 - consonant_loss: 0.0562 - root_accuracy: 0.6970 - vowel_accuracy: 0.9746 - consonant_accuracy: 0.9809 - val_loss: 3.5221 - val_root_loss: 2.3152 - val_vowel_loss: 0.4762 - val_consonant_loss: 0.5368 - val_root_accuracy: 0.4108 - val_vowel_accuracy: 0.8706 - val_consonant_accuracy: 0.8685\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.9076 - root_loss: 0.8046 - vowel_loss: 0.0605 - consonant_loss: 0.0425 - root_accuracy: 0.7649 - vowel_accuracy: 0.9816 - consonant_accuracy: 0.9863 - val_loss: 3.5663 - val_root_loss: 2.3786 - val_vowel_loss: 0.5043 - val_consonant_loss: 0.5967 - val_root_accuracy: 0.4160 - val_vowel_accuracy: 0.8771 - val_consonant_accuracy: 0.8710\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.7044 - root_loss: 0.6122 - vowel_loss: 0.0526 - consonant_loss: 0.0396 - root_accuracy: 0.8242 - vowel_accuracy: 0.9836 - consonant_accuracy: 0.9872 - val_loss: 3.7118 - val_root_loss: 2.3669 - val_vowel_loss: 0.5039 - val_consonant_loss: 0.6107 - val_root_accuracy: 0.4329 - val_vowel_accuracy: 0.8760 - val_consonant_accuracy: 0.8773\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.5481 - root_loss: 0.4729 - vowel_loss: 0.0441 - consonant_loss: 0.0311 - root_accuracy: 0.8653 - vowel_accuracy: 0.9866 - consonant_accuracy: 0.9899 - val_loss: 3.7379 - val_root_loss: 2.3930 - val_vowel_loss: 0.5207 - val_consonant_loss: 0.5869 - val_root_accuracy: 0.4350 - val_vowel_accuracy: 0.8746 - val_consonant_accuracy: 0.8775\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.4182 - root_loss: 0.3552 - vowel_loss: 0.0356 - consonant_loss: 0.0274 - root_accuracy: 0.9016 - vowel_accuracy: 0.9893 - consonant_accuracy: 0.9910 - val_loss: 3.8941 - val_root_loss: 2.4793 - val_vowel_loss: 0.5277 - val_consonant_loss: 0.6168 - val_root_accuracy: 0.4381 - val_vowel_accuracy: 0.8796 - val_consonant_accuracy: 0.8746\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.3342 - root_loss: 0.2780 - vowel_loss: 0.0313 - consonant_loss: 0.0249 - root_accuracy: 0.9239 - vowel_accuracy: 0.9901 - consonant_accuracy: 0.9922 - val_loss: 4.1249 - val_root_loss: 2.5323 - val_vowel_loss: 0.5627 - val_consonant_loss: 0.6454 - val_root_accuracy: 0.4450 - val_vowel_accuracy: 0.8794 - val_consonant_accuracy: 0.8756\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.2725 - root_loss: 0.2230 - vowel_loss: 0.0284 - consonant_loss: 0.0211 - root_accuracy: 0.9395 - vowel_accuracy: 0.9914 - consonant_accuracy: 0.9932 - val_loss: 3.9045 - val_root_loss: 2.6123 - val_vowel_loss: 0.5466 - val_consonant_loss: 0.6571 - val_root_accuracy: 0.4352 - val_vowel_accuracy: 0.8810 - val_consonant_accuracy: 0.8802\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.2168 - root_loss: 0.1747 - vowel_loss: 0.0232 - consonant_loss: 0.0189 - root_accuracy: 0.9552 - vowel_accuracy: 0.9930 - consonant_accuracy: 0.9941 - val_loss: 4.3230 - val_root_loss: 2.6728 - val_vowel_loss: 0.5955 - val_consonant_loss: 0.6752 - val_root_accuracy: 0.4467 - val_vowel_accuracy: 0.8794 - val_consonant_accuracy: 0.8794\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1766 - root_loss: 0.1405 - vowel_loss: 0.0205 - consonant_loss: 0.0156 - root_accuracy: 0.9633 - vowel_accuracy: 0.9937 - consonant_accuracy: 0.9950 - val_loss: 4.2845 - val_root_loss: 2.7221 - val_vowel_loss: 0.5731 - val_consonant_loss: 0.6989 - val_root_accuracy: 0.4525 - val_vowel_accuracy: 0.8815 - val_consonant_accuracy: 0.8767\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1568 - root_loss: 0.1212 - vowel_loss: 0.0200 - consonant_loss: 0.0156 - root_accuracy: 0.9704 - vowel_accuracy: 0.9941 - consonant_accuracy: 0.9949 - val_loss: 4.3739 - val_root_loss: 2.7748 - val_vowel_loss: 0.6097 - val_consonant_loss: 0.7186 - val_root_accuracy: 0.4473 - val_vowel_accuracy: 0.8831 - val_consonant_accuracy: 0.8781\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1408 - root_loss: 0.1071 - vowel_loss: 0.0196 - consonant_loss: 0.0141 - root_accuracy: 0.9724 - vowel_accuracy: 0.9941 - consonant_accuracy: 0.9952 - val_loss: 4.4458 - val_root_loss: 2.8284 - val_vowel_loss: 0.5942 - val_consonant_loss: 0.7096 - val_root_accuracy: 0.4521 - val_vowel_accuracy: 0.8883 - val_consonant_accuracy: 0.8794\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1269 - root_loss: 0.0944 - vowel_loss: 0.0186 - consonant_loss: 0.0139 - root_accuracy: 0.9757 - vowel_accuracy: 0.9943 - consonant_accuracy: 0.9955 - val_loss: 4.5805 - val_root_loss: 2.8850 - val_vowel_loss: 0.6388 - val_consonant_loss: 0.7333 - val_root_accuracy: 0.4477 - val_vowel_accuracy: 0.8854 - val_consonant_accuracy: 0.8813\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1176 - root_loss: 0.0862 - vowel_loss: 0.0166 - consonant_loss: 0.0148 - root_accuracy: 0.9775 - vowel_accuracy: 0.9948 - consonant_accuracy: 0.9950 - val_loss: 4.4821 - val_root_loss: 2.9323 - val_vowel_loss: 0.6339 - val_consonant_loss: 0.7512 - val_root_accuracy: 0.4490 - val_vowel_accuracy: 0.8873 - val_consonant_accuracy: 0.8813\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1048 - root_loss: 0.0753 - vowel_loss: 0.0166 - consonant_loss: 0.0129 - root_accuracy: 0.9819 - vowel_accuracy: 0.9948 - consonant_accuracy: 0.9959 - val_loss: 4.5725 - val_root_loss: 2.9668 - val_vowel_loss: 0.6357 - val_consonant_loss: 0.7818 - val_root_accuracy: 0.4535 - val_vowel_accuracy: 0.8879 - val_consonant_accuracy: 0.8817\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0984 - root_loss: 0.0724 - vowel_loss: 0.0146 - consonant_loss: 0.0113 - root_accuracy: 0.9811 - vowel_accuracy: 0.9956 - consonant_accuracy: 0.9962 - val_loss: 4.6202 - val_root_loss: 2.9675 - val_vowel_loss: 0.6415 - val_consonant_loss: 0.7290 - val_root_accuracy: 0.4500 - val_vowel_accuracy: 0.8863 - val_consonant_accuracy: 0.8785\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0959 - root_loss: 0.0690 - vowel_loss: 0.0154 - consonant_loss: 0.0114 - root_accuracy: 0.9819 - vowel_accuracy: 0.9951 - consonant_accuracy: 0.9965 - val_loss: 4.5530 - val_root_loss: 2.9854 - val_vowel_loss: 0.6496 - val_consonant_loss: 0.7635 - val_root_accuracy: 0.4554 - val_vowel_accuracy: 0.8921 - val_consonant_accuracy: 0.8833\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0869 - root_loss: 0.0629 - vowel_loss: 0.0125 - consonant_loss: 0.0115 - root_accuracy: 0.9834 - vowel_accuracy: 0.9957 - consonant_accuracy: 0.9962 - val_loss: 4.6615 - val_root_loss: 3.0757 - val_vowel_loss: 0.6501 - val_consonant_loss: 0.7460 - val_root_accuracy: 0.4610 - val_vowel_accuracy: 0.8883 - val_consonant_accuracy: 0.8848\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0828 - root_loss: 0.0589 - vowel_loss: 0.0125 - consonant_loss: 0.0114 - root_accuracy: 0.9842 - vowel_accuracy: 0.9961 - consonant_accuracy: 0.9960 - val_loss: 4.7001 - val_root_loss: 3.0463 - val_vowel_loss: 0.6713 - val_consonant_loss: 0.7526 - val_root_accuracy: 0.4642 - val_vowel_accuracy: 0.8902 - val_consonant_accuracy: 0.8831\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0775 - root_loss: 0.0550 - vowel_loss: 0.0124 - consonant_loss: 0.0102 - root_accuracy: 0.9854 - vowel_accuracy: 0.9961 - consonant_accuracy: 0.9969 - val_loss: 4.6806 - val_root_loss: 3.0632 - val_vowel_loss: 0.6779 - val_consonant_loss: 0.7318 - val_root_accuracy: 0.4602 - val_vowel_accuracy: 0.8871 - val_consonant_accuracy: 0.8865\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0728 - root_loss: 0.0520 - vowel_loss: 0.0107 - consonant_loss: 0.0100 - root_accuracy: 0.9862 - vowel_accuracy: 0.9967 - consonant_accuracy: 0.9968 - val_loss: 4.9163 - val_root_loss: 3.1239 - val_vowel_loss: 0.6760 - val_consonant_loss: 0.7770 - val_root_accuracy: 0.4638 - val_vowel_accuracy: 0.8885 - val_consonant_accuracy: 0.8819\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.0692 - root_loss: 0.0488 - vowel_loss: 0.0103 - consonant_loss: 0.0101 - root_accuracy: 0.9866 - vowel_accuracy: 0.9965 - consonant_accuracy: 0.9972 - val_loss: 4.9696 - val_root_loss: 3.1628 - val_vowel_loss: 0.6850 - val_consonant_loss: 0.8064 - val_root_accuracy: 0.4656 - val_vowel_accuracy: 0.8896 - val_consonant_accuracy: 0.8767\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.0716 - root_loss: 0.0490 - vowel_loss: 0.0128 - consonant_loss: 0.0098 - root_accuracy: 0.9871 - vowel_accuracy: 0.9960 - consonant_accuracy: 0.9967 - val_loss: 4.9793 - val_root_loss: 3.1596 - val_vowel_loss: 0.6917 - val_consonant_loss: 0.7982 - val_root_accuracy: 0.4706 - val_vowel_accuracy: 0.8854 - val_consonant_accuracy: 0.8825\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0687 - root_loss: 0.0483 - vowel_loss: 0.0108 - consonant_loss: 0.0096 - root_accuracy: 0.9872 - vowel_accuracy: 0.9964 - consonant_accuracy: 0.9969 - val_loss: 4.9782 - val_root_loss: 3.1771 - val_vowel_loss: 0.6928 - val_consonant_loss: 0.7844 - val_root_accuracy: 0.4698 - val_vowel_accuracy: 0.8871 - val_consonant_accuracy: 0.8840\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0465 - root_loss: 0.0331 - vowel_loss: 0.0074 - consonant_loss: 0.0060 - root_accuracy: 0.9919 - vowel_accuracy: 0.9977 - consonant_accuracy: 0.9980 - val_loss: 4.9549 - val_root_loss: 3.1289 - val_vowel_loss: 0.6553 - val_consonant_loss: 0.7917 - val_root_accuracy: 0.4758 - val_vowel_accuracy: 0.8950 - val_consonant_accuracy: 0.8906\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0305 - root_loss: 0.0214 - vowel_loss: 0.0046 - consonant_loss: 0.0046 - root_accuracy: 0.9953 - vowel_accuracy: 0.9986 - consonant_accuracy: 0.9985 - val_loss: 4.8283 - val_root_loss: 3.0792 - val_vowel_loss: 0.6556 - val_consonant_loss: 0.7637 - val_root_accuracy: 0.4777 - val_vowel_accuracy: 0.8944 - val_consonant_accuracy: 0.8913\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0242 - root_loss: 0.0168 - vowel_loss: 0.0046 - consonant_loss: 0.0027 - root_accuracy: 0.9965 - vowel_accuracy: 0.9986 - consonant_accuracy: 0.9993 - val_loss: 5.0402 - val_root_loss: 3.1150 - val_vowel_loss: 0.6830 - val_consonant_loss: 0.8034 - val_root_accuracy: 0.4856 - val_vowel_accuracy: 0.8931 - val_consonant_accuracy: 0.8933\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 0.0231 - root_loss: 0.0155 - vowel_loss: 0.0042 - consonant_loss: 0.0034 - root_accuracy: 0.9969 - vowel_accuracy: 0.9986 - consonant_accuracy: 0.9991 - val_loss: 4.9637 - val_root_loss: 3.1212 - val_vowel_loss: 0.6598 - val_consonant_loss: 0.7760 - val_root_accuracy: 0.4825 - val_vowel_accuracy: 0.8952 - val_consonant_accuracy: 0.8894\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 40s 264ms/step - loss: 0.0193 - root_loss: 0.0130 - vowel_loss: 0.0036 - consonant_loss: 0.0027 - root_accuracy: 0.9976 - vowel_accuracy: 0.9992 - consonant_accuracy: 0.9992 - val_loss: 4.8060 - val_root_loss: 3.1245 - val_vowel_loss: 0.6736 - val_consonant_loss: 0.7759 - val_root_accuracy: 0.4823 - val_vowel_accuracy: 0.8960 - val_consonant_accuracy: 0.8898\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 40s 265ms/step - loss: 0.0182 - root_loss: 0.0130 - vowel_loss: 0.0030 - consonant_loss: 0.0022 - root_accuracy: 0.9975 - vowel_accuracy: 0.9991 - consonant_accuracy: 0.9994 - val_loss: 4.9892 - val_root_loss: 3.1831 - val_vowel_loss: 0.6715 - val_consonant_loss: 0.8069 - val_root_accuracy: 0.4771 - val_vowel_accuracy: 0.8979 - val_consonant_accuracy: 0.8894\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 39s 262ms/step - loss: 0.0150 - root_loss: 0.0106 - vowel_loss: 0.0023 - consonant_loss: 0.0021 - root_accuracy: 0.9984 - vowel_accuracy: 0.9995 - consonant_accuracy: 0.9995 - val_loss: 4.9624 - val_root_loss: 3.1657 - val_vowel_loss: 0.6663 - val_consonant_loss: 0.7904 - val_root_accuracy: 0.4777 - val_vowel_accuracy: 0.8954 - val_consonant_accuracy: 0.8904\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 39s 263ms/step - loss: 0.0149 - root_loss: 0.0105 - vowel_loss: 0.0028 - consonant_loss: 0.0016 - root_accuracy: 0.9982 - vowel_accuracy: 0.9992 - consonant_accuracy: 0.9996 - val_loss: 5.0101 - val_root_loss: 3.1438 - val_vowel_loss: 0.6620 - val_consonant_loss: 0.7949 - val_root_accuracy: 0.4815 - val_vowel_accuracy: 0.8965 - val_consonant_accuracy: 0.8894\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 39s 263ms/step - loss: 0.0135 - root_loss: 0.0094 - vowel_loss: 0.0022 - consonant_loss: 0.0019 - root_accuracy: 0.9982 - vowel_accuracy: 0.9995 - consonant_accuracy: 0.9996 - val_loss: 4.9172 - val_root_loss: 3.1588 - val_vowel_loss: 0.6636 - val_consonant_loss: 0.7946 - val_root_accuracy: 0.4823 - val_vowel_accuracy: 0.8971 - val_consonant_accuracy: 0.8925\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.0132 - root_loss: 0.0094 - vowel_loss: 0.0024 - consonant_loss: 0.0014 - root_accuracy: 0.9982 - vowel_accuracy: 0.9993 - consonant_accuracy: 0.9997 - val_loss: 4.9496 - val_root_loss: 3.1504 - val_vowel_loss: 0.6684 - val_consonant_loss: 0.7941 - val_root_accuracy: 0.4865 - val_vowel_accuracy: 0.8992 - val_consonant_accuracy: 0.8919\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.0115 - root_loss: 0.0081 - vowel_loss: 0.0020 - consonant_loss: 0.0014 - root_accuracy: 0.9988 - vowel_accuracy: 0.9996 - consonant_accuracy: 0.9996 - val_loss: 4.9253 - val_root_loss: 3.1454 - val_vowel_loss: 0.6650 - val_consonant_loss: 0.7944 - val_root_accuracy: 0.4877 - val_vowel_accuracy: 0.8985 - val_consonant_accuracy: 0.8929\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 39s 263ms/step - loss: 0.0108 - root_loss: 0.0077 - vowel_loss: 0.0019 - consonant_loss: 0.0011 - root_accuracy: 0.9988 - vowel_accuracy: 0.9995 - consonant_accuracy: 0.9997 - val_loss: 4.8965 - val_root_loss: 3.1552 - val_vowel_loss: 0.6616 - val_consonant_loss: 0.7926 - val_root_accuracy: 0.4900 - val_vowel_accuracy: 0.8983 - val_consonant_accuracy: 0.8935\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 0.0110 - root_loss: 0.0079 - vowel_loss: 0.0019 - consonant_loss: 0.0012 - root_accuracy: 0.9985 - vowel_accuracy: 0.9995 - consonant_accuracy: 0.9997 - val_loss: 4.9733 - val_root_loss: 3.1565 - val_vowel_loss: 0.6625 - val_consonant_loss: 0.7942 - val_root_accuracy: 0.4881 - val_vowel_accuracy: 0.8990 - val_consonant_accuracy: 0.8935\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 0.0095 - root_loss: 0.0067 - vowel_loss: 0.0016 - consonant_loss: 0.0012 - root_accuracy: 0.9993 - vowel_accuracy: 0.9997 - consonant_accuracy: 0.9998 - val_loss: 4.9743 - val_root_loss: 3.1555 - val_vowel_loss: 0.6661 - val_consonant_loss: 0.7905 - val_root_accuracy: 0.4888 - val_vowel_accuracy: 0.8985 - val_consonant_accuracy: 0.8923\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 0.0089 - root_loss: 0.0063 - vowel_loss: 0.0017 - consonant_loss: 8.3204e-04 - root_accuracy: 0.9993 - vowel_accuracy: 0.9997 - consonant_accuracy: 0.9998 - val_loss: 5.0104 - val_root_loss: 3.1583 - val_vowel_loss: 0.6696 - val_consonant_loss: 0.7993 - val_root_accuracy: 0.4875 - val_vowel_accuracy: 0.8973 - val_consonant_accuracy: 0.8923\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 0.0088 - root_loss: 0.0062 - vowel_loss: 0.0017 - consonant_loss: 8.8389e-04 - root_accuracy: 0.9993 - vowel_accuracy: 0.9996 - consonant_accuracy: 0.9998 - val_loss: 4.9837 - val_root_loss: 3.1575 - val_vowel_loss: 0.6713 - val_consonant_loss: 0.7897 - val_root_accuracy: 0.4869 - val_vowel_accuracy: 0.8990 - val_consonant_accuracy: 0.8908\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0088 - root_loss: 0.0062 - vowel_loss: 0.0016 - consonant_loss: 0.0011 - root_accuracy: 0.9992 - vowel_accuracy: 0.9997 - consonant_accuracy: 0.9998 - val_loss: 4.9919 - val_root_loss: 3.1667 - val_vowel_loss: 0.6731 - val_consonant_loss: 0.8049 - val_root_accuracy: 0.4860 - val_vowel_accuracy: 0.8990 - val_consonant_accuracy: 0.8931\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0088 - root_loss: 0.0060 - vowel_loss: 0.0017 - consonant_loss: 0.0011 - root_accuracy: 0.9992 - vowel_accuracy: 0.9996 - consonant_accuracy: 0.9997 - val_loss: 5.0280 - val_root_loss: 3.1772 - val_vowel_loss: 0.6751 - val_consonant_loss: 0.8108 - val_root_accuracy: 0.4867 - val_vowel_accuracy: 0.8994 - val_consonant_accuracy: 0.8931\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.0092 - root_loss: 0.0064 - vowel_loss: 0.0015 - consonant_loss: 0.0013 - root_accuracy: 0.9989 - vowel_accuracy: 0.9996 - consonant_accuracy: 0.9997 - val_loss: 5.0131 - val_root_loss: 3.1818 - val_vowel_loss: 0.6763 - val_consonant_loss: 0.8042 - val_root_accuracy: 0.4854 - val_vowel_accuracy: 0.8992 - val_consonant_accuracy: 0.8929\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0081 - root_loss: 0.0058 - vowel_loss: 0.0014 - consonant_loss: 8.9580e-04 - root_accuracy: 0.9992 - vowel_accuracy: 0.9998 - consonant_accuracy: 0.9998 - val_loss: 5.0307 - val_root_loss: 3.1806 - val_vowel_loss: 0.6746 - val_consonant_loss: 0.8088 - val_root_accuracy: 0.4892 - val_vowel_accuracy: 0.8992 - val_consonant_accuracy: 0.8919\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0083 - root_loss: 0.0058 - vowel_loss: 0.0016 - consonant_loss: 9.3578e-04 - root_accuracy: 0.9990 - vowel_accuracy: 0.9997 - consonant_accuracy: 0.9998 - val_loss: 5.0387 - val_root_loss: 3.1844 - val_vowel_loss: 0.6773 - val_consonant_loss: 0.8119 - val_root_accuracy: 0.4877 - val_vowel_accuracy: 0.8983 - val_consonant_accuracy: 0.8935\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0080 - root_loss: 0.0056 - vowel_loss: 0.0014 - consonant_loss: 9.7511e-04 - root_accuracy: 0.9993 - vowel_accuracy: 0.9996 - consonant_accuracy: 0.9998 - val_loss: 5.0311 - val_root_loss: 3.1760 - val_vowel_loss: 0.6753 - val_consonant_loss: 0.7988 - val_root_accuracy: 0.4908 - val_vowel_accuracy: 0.8971 - val_consonant_accuracy: 0.8929\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0076 - root_loss: 0.0056 - vowel_loss: 0.0013 - consonant_loss: 7.3482e-04 - root_accuracy: 0.9994 - vowel_accuracy: 0.9997 - consonant_accuracy: 0.9999 - val_loss: 5.0805 - val_root_loss: 3.1887 - val_vowel_loss: 0.6796 - val_consonant_loss: 0.8107 - val_root_accuracy: 0.4875 - val_vowel_accuracy: 0.8977 - val_consonant_accuracy: 0.8940\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0073 - root_loss: 0.0050 - vowel_loss: 0.0015 - consonant_loss: 8.4326e-04 - root_accuracy: 0.9995 - vowel_accuracy: 0.9997 - consonant_accuracy: 0.9999 - val_loss: 5.0376 - val_root_loss: 3.1938 - val_vowel_loss: 0.6847 - val_consonant_loss: 0.8091 - val_root_accuracy: 0.4908 - val_vowel_accuracy: 0.8960 - val_consonant_accuracy: 0.8942\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0071 - root_loss: 0.0051 - vowel_loss: 0.0013 - consonant_loss: 7.6389e-04 - root_accuracy: 0.9995 - vowel_accuracy: 0.9997 - consonant_accuracy: 0.9999 - val_loss: 5.0295 - val_root_loss: 3.2000 - val_vowel_loss: 0.6892 - val_consonant_loss: 0.8121 - val_root_accuracy: 0.4863 - val_vowel_accuracy: 0.8963 - val_consonant_accuracy: 0.8921\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0076 - root_loss: 0.0051 - vowel_loss: 0.0016 - consonant_loss: 9.0828e-04 - root_accuracy: 0.9994 - vowel_accuracy: 0.9996 - consonant_accuracy: 0.9998 - val_loss: 4.9858 - val_root_loss: 3.2071 - val_vowel_loss: 0.6866 - val_consonant_loss: 0.8090 - val_root_accuracy: 0.4910 - val_vowel_accuracy: 0.8977 - val_consonant_accuracy: 0.8923\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0069 - root_loss: 0.0047 - vowel_loss: 0.0013 - consonant_loss: 9.0213e-04 - root_accuracy: 0.9995 - vowel_accuracy: 0.9998 - consonant_accuracy: 0.9998 - val_loss: 5.0536 - val_root_loss: 3.2051 - val_vowel_loss: 0.6948 - val_consonant_loss: 0.8095 - val_root_accuracy: 0.4898 - val_vowel_accuracy: 0.8977 - val_consonant_accuracy: 0.8942\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0062 - root_loss: 0.0045 - vowel_loss: 9.6515e-04 - consonant_loss: 7.6458e-04 - root_accuracy: 0.9996 - vowel_accuracy: 0.9998 - consonant_accuracy: 0.9998 - val_loss: 5.0737 - val_root_loss: 3.2159 - val_vowel_loss: 0.6983 - val_consonant_loss: 0.8082 - val_root_accuracy: 0.4900 - val_vowel_accuracy: 0.8973 - val_consonant_accuracy: 0.8935\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0066 - root_loss: 0.0047 - vowel_loss: 0.0011 - consonant_loss: 7.8057e-04 - root_accuracy: 0.9995 - vowel_accuracy: 0.9998 - consonant_accuracy: 0.9998 - val_loss: 5.1116 - val_root_loss: 3.2194 - val_vowel_loss: 0.6902 - val_consonant_loss: 0.8134 - val_root_accuracy: 0.4902 - val_vowel_accuracy: 0.8996 - val_consonant_accuracy: 0.8929\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0068 - root_loss: 0.0050 - vowel_loss: 0.0012 - consonant_loss: 6.6745e-04 - root_accuracy: 0.9993 - vowel_accuracy: 0.9997 - consonant_accuracy: 0.9998 - val_loss: 5.2424 - val_root_loss: 3.2265 - val_vowel_loss: 0.6995 - val_consonant_loss: 0.8263 - val_root_accuracy: 0.4844 - val_vowel_accuracy: 0.8969 - val_consonant_accuracy: 0.8931\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0064 - root_loss: 0.0044 - vowel_loss: 0.0011 - consonant_loss: 8.0990e-04 - root_accuracy: 0.9995 - vowel_accuracy: 0.9998 - consonant_accuracy: 0.9998 - val_loss: 5.1532 - val_root_loss: 3.2171 - val_vowel_loss: 0.6950 - val_consonant_loss: 0.8194 - val_root_accuracy: 0.4881 - val_vowel_accuracy: 0.8988 - val_consonant_accuracy: 0.8925\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0063 - root_loss: 0.0045 - vowel_loss: 0.0011 - consonant_loss: 6.2093e-04 - root_accuracy: 0.9994 - vowel_accuracy: 0.9998 - consonant_accuracy: 0.9999 - val_loss: 5.1243 - val_root_loss: 3.2129 - val_vowel_loss: 0.6995 - val_consonant_loss: 0.8193 - val_root_accuracy: 0.4885 - val_vowel_accuracy: 0.8975 - val_consonant_accuracy: 0.8919\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0057 - root_loss: 0.0041 - vowel_loss: 0.0011 - consonant_loss: 5.7736e-04 - root_accuracy: 0.9995 - vowel_accuracy: 0.9998 - consonant_accuracy: 0.9999 - val_loss: 5.1307 - val_root_loss: 3.2310 - val_vowel_loss: 0.6967 - val_consonant_loss: 0.8236 - val_root_accuracy: 0.4904 - val_vowel_accuracy: 0.8969 - val_consonant_accuracy: 0.8927\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.0064 - root_loss: 0.0045 - vowel_loss: 0.0012 - consonant_loss: 7.1408e-04 - root_accuracy: 0.9994 - vowel_accuracy: 0.9998 - consonant_accuracy: 0.9998 - val_loss: 5.1276 - val_root_loss: 3.2227 - val_vowel_loss: 0.6990 - val_consonant_loss: 0.8173 - val_root_accuracy: 0.4885 - val_vowel_accuracy: 0.8983 - val_consonant_accuracy: 0.8927\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.0059 - root_loss: 0.0041 - vowel_loss: 0.0011 - consonant_loss: 6.4972e-04 - root_accuracy: 0.9994 - vowel_accuracy: 0.9998 - consonant_accuracy: 0.9999 - val_loss: 5.1429 - val_root_loss: 3.2286 - val_vowel_loss: 0.6970 - val_consonant_loss: 0.8209 - val_root_accuracy: 0.4890 - val_vowel_accuracy: 0.8973 - val_consonant_accuracy: 0.8940\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.0061 - root_loss: 0.0041 - vowel_loss: 0.0013 - consonant_loss: 6.7781e-04 - root_accuracy: 0.9995 - vowel_accuracy: 0.9997 - consonant_accuracy: 0.9999 - val_loss: 5.1706 - val_root_loss: 3.2387 - val_vowel_loss: 0.7023 - val_consonant_loss: 0.8224 - val_root_accuracy: 0.4871 - val_vowel_accuracy: 0.8967 - val_consonant_accuracy: 0.8935\n",
      "Epoch 00068: early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c0ec18a77a4b79b6938ea7c451f07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=45189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103941463eb64207a225645343f7cecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5021.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 4.7730 - root_loss: 3.3292 - vowel_loss: 0.6815 - consonant_loss: 0.7623 - root_accuracy: 0.4670 - vowel_accuracy: 0.8918 - consonant_accuracy: 0.8839 - val_loss: 3.5076 - val_root_loss: 2.6184 - val_vowel_loss: 0.4972 - val_consonant_loss: 0.5576 - val_root_accuracy: 0.5021 - val_vowel_accuracy: 0.9065 - val_consonant_accuracy: 0.8879\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 3.1491 - root_loss: 2.3128 - vowel_loss: 0.4095 - consonant_loss: 0.4268 - root_accuracy: 0.5391 - vowel_accuracy: 0.9134 - consonant_accuracy: 0.9060 - val_loss: 3.2982 - val_root_loss: 2.4680 - val_vowel_loss: 0.4587 - val_consonant_loss: 0.4960 - val_root_accuracy: 0.5177 - val_vowel_accuracy: 0.9087 - val_consonant_accuracy: 0.8954\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 2.6158 - root_loss: 1.9514 - vowel_loss: 0.3308 - consonant_loss: 0.3336 - root_accuracy: 0.5693 - vowel_accuracy: 0.9214 - consonant_accuracy: 0.9154 - val_loss: 3.0580 - val_root_loss: 2.3421 - val_vowel_loss: 0.4330 - val_consonant_loss: 0.4625 - val_root_accuracy: 0.5242 - val_vowel_accuracy: 0.9104 - val_consonant_accuracy: 0.8981\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 2.2851 - root_loss: 1.7298 - vowel_loss: 0.2731 - consonant_loss: 0.2821 - root_accuracy: 0.5922 - vowel_accuracy: 0.9291 - consonant_accuracy: 0.9226 - val_loss: 2.9420 - val_root_loss: 2.2455 - val_vowel_loss: 0.4091 - val_consonant_loss: 0.4424 - val_root_accuracy: 0.5306 - val_vowel_accuracy: 0.9115 - val_consonant_accuracy: 0.8994\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 2.0649 - root_loss: 1.5648 - vowel_loss: 0.2474 - consonant_loss: 0.2527 - root_accuracy: 0.6110 - vowel_accuracy: 0.9319 - consonant_accuracy: 0.9265 - val_loss: 2.8400 - val_root_loss: 2.1817 - val_vowel_loss: 0.3996 - val_consonant_loss: 0.4270 - val_root_accuracy: 0.5371 - val_vowel_accuracy: 0.9100 - val_consonant_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.8955 - root_loss: 1.4485 - vowel_loss: 0.2201 - consonant_loss: 0.2268 - root_accuracy: 0.6292 - vowel_accuracy: 0.9375 - consonant_accuracy: 0.9325 - val_loss: 2.7575 - val_root_loss: 2.1195 - val_vowel_loss: 0.3855 - val_consonant_loss: 0.4144 - val_root_accuracy: 0.5446 - val_vowel_accuracy: 0.9117 - val_consonant_accuracy: 0.9025\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.7451 - root_loss: 1.3419 - vowel_loss: 0.1962 - consonant_loss: 0.2070 - root_accuracy: 0.6438 - vowel_accuracy: 0.9424 - consonant_accuracy: 0.9370 - val_loss: 2.7559 - val_root_loss: 2.0783 - val_vowel_loss: 0.3820 - val_consonant_loss: 0.4047 - val_root_accuracy: 0.5465 - val_vowel_accuracy: 0.9087 - val_consonant_accuracy: 0.9019\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.6280 - root_loss: 1.2585 - vowel_loss: 0.1783 - consonant_loss: 0.1912 - root_accuracy: 0.6588 - vowel_accuracy: 0.9458 - consonant_accuracy: 0.9398 - val_loss: 2.7146 - val_root_loss: 2.0430 - val_vowel_loss: 0.3744 - val_consonant_loss: 0.3980 - val_root_accuracy: 0.5487 - val_vowel_accuracy: 0.9096 - val_consonant_accuracy: 0.9010\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.5220 - root_loss: 1.1804 - vowel_loss: 0.1671 - consonant_loss: 0.1745 - root_accuracy: 0.6760 - vowel_accuracy: 0.9473 - consonant_accuracy: 0.9434 - val_loss: 2.6708 - val_root_loss: 2.0106 - val_vowel_loss: 0.3703 - val_consonant_loss: 0.3936 - val_root_accuracy: 0.5552 - val_vowel_accuracy: 0.9123 - val_consonant_accuracy: 0.9013\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.4326 - root_loss: 1.1162 - vowel_loss: 0.1540 - consonant_loss: 0.1624 - root_accuracy: 0.6903 - vowel_accuracy: 0.9510 - consonant_accuracy: 0.9465 - val_loss: 2.6607 - val_root_loss: 1.9906 - val_vowel_loss: 0.3646 - val_consonant_loss: 0.3901 - val_root_accuracy: 0.5542 - val_vowel_accuracy: 0.9125 - val_consonant_accuracy: 0.9027\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.3537 - root_loss: 1.0572 - vowel_loss: 0.1438 - consonant_loss: 0.1527 - root_accuracy: 0.7010 - vowel_accuracy: 0.9540 - consonant_accuracy: 0.9494 - val_loss: 2.6506 - val_root_loss: 1.9801 - val_vowel_loss: 0.3668 - val_consonant_loss: 0.3890 - val_root_accuracy: 0.5606 - val_vowel_accuracy: 0.9115 - val_consonant_accuracy: 0.9029\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.2676 - root_loss: 0.9953 - vowel_loss: 0.1346 - consonant_loss: 0.1377 - root_accuracy: 0.7156 - vowel_accuracy: 0.9561 - consonant_accuracy: 0.9537 - val_loss: 2.6128 - val_root_loss: 1.9609 - val_vowel_loss: 0.3638 - val_consonant_loss: 0.3863 - val_root_accuracy: 0.5567 - val_vowel_accuracy: 0.9137 - val_consonant_accuracy: 0.9006\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 1.2018 - root_loss: 0.9459 - vowel_loss: 0.1254 - consonant_loss: 0.1306 - root_accuracy: 0.7253 - vowel_accuracy: 0.9587 - consonant_accuracy: 0.9562 - val_loss: 2.6278 - val_root_loss: 1.9614 - val_vowel_loss: 0.3635 - val_consonant_loss: 0.3895 - val_root_accuracy: 0.5594 - val_vowel_accuracy: 0.9123 - val_consonant_accuracy: 0.9031\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 1.1345 - root_loss: 0.8950 - vowel_loss: 0.1161 - consonant_loss: 0.1234 - root_accuracy: 0.7399 - vowel_accuracy: 0.9627 - consonant_accuracy: 0.9593 - val_loss: 2.6014 - val_root_loss: 1.9480 - val_vowel_loss: 0.3620 - val_consonant_loss: 0.3875 - val_root_accuracy: 0.5612 - val_vowel_accuracy: 0.9129 - val_consonant_accuracy: 0.9042\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 1.0684 - root_loss: 0.8485 - vowel_loss: 0.1061 - consonant_loss: 0.1138 - root_accuracy: 0.7506 - vowel_accuracy: 0.9646 - consonant_accuracy: 0.9607 - val_loss: 2.6128 - val_root_loss: 1.9542 - val_vowel_loss: 0.3631 - val_consonant_loss: 0.3911 - val_root_accuracy: 0.5598 - val_vowel_accuracy: 0.9127 - val_consonant_accuracy: 0.9021\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 1.0138 - root_loss: 0.8030 - vowel_loss: 0.1035 - consonant_loss: 0.1073 - root_accuracy: 0.7613 - vowel_accuracy: 0.9658 - consonant_accuracy: 0.9632 - val_loss: 2.5964 - val_root_loss: 1.9511 - val_vowel_loss: 0.3632 - val_consonant_loss: 0.3916 - val_root_accuracy: 0.5606 - val_vowel_accuracy: 0.9125 - val_consonant_accuracy: 0.9027\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 0.9655 - root_loss: 0.7689 - vowel_loss: 0.0954 - consonant_loss: 0.1012 - root_accuracy: 0.7731 - vowel_accuracy: 0.9683 - consonant_accuracy: 0.9650 - val_loss: 2.5889 - val_root_loss: 1.9527 - val_vowel_loss: 0.3616 - val_consonant_loss: 0.3926 - val_root_accuracy: 0.5658 - val_vowel_accuracy: 0.9146 - val_consonant_accuracy: 0.9031\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.9010 - root_loss: 0.7162 - vowel_loss: 0.0909 - consonant_loss: 0.0939 - root_accuracy: 0.7864 - vowel_accuracy: 0.9695 - consonant_accuracy: 0.9675 - val_loss: 2.6148 - val_root_loss: 1.9525 - val_vowel_loss: 0.3625 - val_consonant_loss: 0.3925 - val_root_accuracy: 0.5646 - val_vowel_accuracy: 0.9144 - val_consonant_accuracy: 0.9035\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.8524 - root_loss: 0.6794 - vowel_loss: 0.0848 - consonant_loss: 0.0882 - root_accuracy: 0.7944 - vowel_accuracy: 0.9706 - consonant_accuracy: 0.9700 - val_loss: 2.6043 - val_root_loss: 1.9499 - val_vowel_loss: 0.3623 - val_consonant_loss: 0.3945 - val_root_accuracy: 0.5669 - val_vowel_accuracy: 0.9154 - val_consonant_accuracy: 0.9029\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.8084 - root_loss: 0.6470 - vowel_loss: 0.0802 - consonant_loss: 0.0813 - root_accuracy: 0.8045 - vowel_accuracy: 0.9729 - consonant_accuracy: 0.9719 - val_loss: 2.6180 - val_root_loss: 1.9578 - val_vowel_loss: 0.3687 - val_consonant_loss: 0.4014 - val_root_accuracy: 0.5650 - val_vowel_accuracy: 0.9131 - val_consonant_accuracy: 0.9038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.7602 - root_loss: 0.6088 - vowel_loss: 0.0754 - consonant_loss: 0.0759 - root_accuracy: 0.8166 - vowel_accuracy: 0.9748 - consonant_accuracy: 0.9739 - val_loss: 2.6419 - val_root_loss: 1.9629 - val_vowel_loss: 0.3693 - val_consonant_loss: 0.4050 - val_root_accuracy: 0.5660 - val_vowel_accuracy: 0.9135 - val_consonant_accuracy: 0.9033\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.7117 - root_loss: 0.5738 - vowel_loss: 0.0695 - consonant_loss: 0.0684 - root_accuracy: 0.8283 - vowel_accuracy: 0.9774 - consonant_accuracy: 0.9768 - val_loss: 2.6585 - val_root_loss: 1.9702 - val_vowel_loss: 0.3693 - val_consonant_loss: 0.4089 - val_root_accuracy: 0.5654 - val_vowel_accuracy: 0.9133 - val_consonant_accuracy: 0.9023\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.6789 - root_loss: 0.5448 - vowel_loss: 0.0674 - consonant_loss: 0.0667 - root_accuracy: 0.8340 - vowel_accuracy: 0.9776 - consonant_accuracy: 0.9764 - val_loss: 2.6612 - val_root_loss: 1.9729 - val_vowel_loss: 0.3733 - val_consonant_loss: 0.4116 - val_root_accuracy: 0.5665 - val_vowel_accuracy: 0.9137 - val_consonant_accuracy: 0.9038\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.6426 - root_loss: 0.5177 - vowel_loss: 0.0632 - consonant_loss: 0.0617 - root_accuracy: 0.8430 - vowel_accuracy: 0.9786 - consonant_accuracy: 0.9787 - val_loss: 2.7156 - val_root_loss: 1.9798 - val_vowel_loss: 0.3762 - val_consonant_loss: 0.4154 - val_root_accuracy: 0.5688 - val_vowel_accuracy: 0.9135 - val_consonant_accuracy: 0.9035\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.6028 - root_loss: 0.4850 - vowel_loss: 0.0608 - consonant_loss: 0.0571 - root_accuracy: 0.8535 - vowel_accuracy: 0.9801 - consonant_accuracy: 0.9808 - val_loss: 2.7084 - val_root_loss: 1.9865 - val_vowel_loss: 0.3761 - val_consonant_loss: 0.4196 - val_root_accuracy: 0.5690 - val_vowel_accuracy: 0.9137 - val_consonant_accuracy: 0.9027\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.5717 - root_loss: 0.4616 - vowel_loss: 0.0574 - consonant_loss: 0.0527 - root_accuracy: 0.8599 - vowel_accuracy: 0.9810 - consonant_accuracy: 0.9824 - val_loss: 2.7082 - val_root_loss: 1.9990 - val_vowel_loss: 0.3808 - val_consonant_loss: 0.4258 - val_root_accuracy: 0.5681 - val_vowel_accuracy: 0.9133 - val_consonant_accuracy: 0.9025\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.5320 - root_loss: 0.4302 - vowel_loss: 0.0543 - consonant_loss: 0.0475 - root_accuracy: 0.8702 - vowel_accuracy: 0.9826 - consonant_accuracy: 0.9844 - val_loss: 2.7048 - val_root_loss: 2.0059 - val_vowel_loss: 0.3836 - val_consonant_loss: 0.4297 - val_root_accuracy: 0.5704 - val_vowel_accuracy: 0.9156 - val_consonant_accuracy: 0.9029\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.5087 - root_loss: 0.4104 - vowel_loss: 0.0521 - consonant_loss: 0.0463 - root_accuracy: 0.8746 - vowel_accuracy: 0.9833 - consonant_accuracy: 0.9842 - val_loss: 2.7329 - val_root_loss: 2.0196 - val_vowel_loss: 0.3835 - val_consonant_loss: 0.4316 - val_root_accuracy: 0.5692 - val_vowel_accuracy: 0.9144 - val_consonant_accuracy: 0.9038\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 0.4786 - root_loss: 0.3856 - vowel_loss: 0.0493 - consonant_loss: 0.0437 - root_accuracy: 0.8831 - vowel_accuracy: 0.9841 - consonant_accuracy: 0.9846 - val_loss: 2.7838 - val_root_loss: 2.0292 - val_vowel_loss: 0.3925 - val_consonant_loss: 0.4363 - val_root_accuracy: 0.5706 - val_vowel_accuracy: 0.9137 - val_consonant_accuracy: 0.9027\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.4499 - root_loss: 0.3611 - vowel_loss: 0.0475 - consonant_loss: 0.0413 - root_accuracy: 0.8909 - vowel_accuracy: 0.9840 - consonant_accuracy: 0.9863 - val_loss: 2.7648 - val_root_loss: 2.0303 - val_vowel_loss: 0.3908 - val_consonant_loss: 0.4404 - val_root_accuracy: 0.5746 - val_vowel_accuracy: 0.9146 - val_consonant_accuracy: 0.9046\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.4273 - root_loss: 0.3460 - vowel_loss: 0.0432 - consonant_loss: 0.0381 - root_accuracy: 0.8964 - vowel_accuracy: 0.9856 - consonant_accuracy: 0.9866 - val_loss: 2.7930 - val_root_loss: 2.0457 - val_vowel_loss: 0.3919 - val_consonant_loss: 0.4492 - val_root_accuracy: 0.5708 - val_vowel_accuracy: 0.9158 - val_consonant_accuracy: 0.9023\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.3962 - root_loss: 0.3186 - vowel_loss: 0.0421 - consonant_loss: 0.0356 - root_accuracy: 0.9036 - vowel_accuracy: 0.9864 - consonant_accuracy: 0.9878 - val_loss: 2.8162 - val_root_loss: 2.0520 - val_vowel_loss: 0.3952 - val_consonant_loss: 0.4515 - val_root_accuracy: 0.5717 - val_vowel_accuracy: 0.9152 - val_consonant_accuracy: 0.9035\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.3671 - root_loss: 0.2966 - vowel_loss: 0.0368 - consonant_loss: 0.0338 - root_accuracy: 0.9120 - vowel_accuracy: 0.9883 - consonant_accuracy: 0.9884 - val_loss: 2.8041 - val_root_loss: 2.0629 - val_vowel_loss: 0.3981 - val_consonant_loss: 0.4564 - val_root_accuracy: 0.5706 - val_vowel_accuracy: 0.9152 - val_consonant_accuracy: 0.9033\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.3521 - root_loss: 0.2812 - vowel_loss: 0.0388 - consonant_loss: 0.0321 - root_accuracy: 0.9168 - vowel_accuracy: 0.9875 - consonant_accuracy: 0.9891 - val_loss: 2.8634 - val_root_loss: 2.0826 - val_vowel_loss: 0.4021 - val_consonant_loss: 0.4626 - val_root_accuracy: 0.5725 - val_vowel_accuracy: 0.9144 - val_consonant_accuracy: 0.9048\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.3273 - root_loss: 0.2632 - vowel_loss: 0.0360 - consonant_loss: 0.0281 - root_accuracy: 0.9217 - vowel_accuracy: 0.9878 - consonant_accuracy: 0.9905 - val_loss: 2.8835 - val_root_loss: 2.0861 - val_vowel_loss: 0.4048 - val_consonant_loss: 0.4643 - val_root_accuracy: 0.5713 - val_vowel_accuracy: 0.9135 - val_consonant_accuracy: 0.9040\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.3165 - root_loss: 0.2544 - vowel_loss: 0.0342 - consonant_loss: 0.0279 - root_accuracy: 0.9261 - vowel_accuracy: 0.9893 - consonant_accuracy: 0.9910 - val_loss: 2.8775 - val_root_loss: 2.0957 - val_vowel_loss: 0.4047 - val_consonant_loss: 0.4678 - val_root_accuracy: 0.5708 - val_vowel_accuracy: 0.9156 - val_consonant_accuracy: 0.9035\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.2953 - root_loss: 0.2362 - vowel_loss: 0.0322 - consonant_loss: 0.0269 - root_accuracy: 0.9318 - vowel_accuracy: 0.9898 - consonant_accuracy: 0.9912 - val_loss: 2.8891 - val_root_loss: 2.1035 - val_vowel_loss: 0.4074 - val_consonant_loss: 0.4709 - val_root_accuracy: 0.5713 - val_vowel_accuracy: 0.9133 - val_consonant_accuracy: 0.9023\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.2784 - root_loss: 0.2216 - vowel_loss: 0.0316 - consonant_loss: 0.0252 - root_accuracy: 0.9368 - vowel_accuracy: 0.9900 - consonant_accuracy: 0.9919 - val_loss: 2.9062 - val_root_loss: 2.1197 - val_vowel_loss: 0.4112 - val_consonant_loss: 0.4741 - val_root_accuracy: 0.5744 - val_vowel_accuracy: 0.9142 - val_consonant_accuracy: 0.9029\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.2581 - root_loss: 0.2054 - vowel_loss: 0.0293 - consonant_loss: 0.0233 - root_accuracy: 0.9415 - vowel_accuracy: 0.9911 - consonant_accuracy: 0.9928 - val_loss: 2.9259 - val_root_loss: 2.1339 - val_vowel_loss: 0.4136 - val_consonant_loss: 0.4831 - val_root_accuracy: 0.5744 - val_vowel_accuracy: 0.9140 - val_consonant_accuracy: 0.9015\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.2410 - root_loss: 0.1928 - vowel_loss: 0.0271 - consonant_loss: 0.0211 - root_accuracy: 0.9450 - vowel_accuracy: 0.9918 - consonant_accuracy: 0.9932 - val_loss: 2.9410 - val_root_loss: 2.1489 - val_vowel_loss: 0.4178 - val_consonant_loss: 0.4873 - val_root_accuracy: 0.5710 - val_vowel_accuracy: 0.9125 - val_consonant_accuracy: 0.9013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00040: early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c1ccb8496949019d2213b8e5c7ef12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=45189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583030dcf84140b2a50dabc786259b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5021.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 3.0888 - root_loss: 2.1761 - vowel_loss: 0.4282 - consonant_loss: 0.4845 - root_accuracy: 0.5525 - vowel_accuracy: 0.9074 - consonant_accuracy: 0.8984 - val_loss: 2.1894 - val_root_loss: 1.7867 - val_vowel_loss: 0.3450 - val_consonant_loss: 0.3511 - val_root_accuracy: 0.6010 - val_vowel_accuracy: 0.9208 - val_consonant_accuracy: 0.9071\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 2.2558 - root_loss: 1.6518 - vowel_loss: 0.2957 - consonant_loss: 0.3083 - root_accuracy: 0.5988 - vowel_accuracy: 0.9232 - consonant_accuracy: 0.9155 - val_loss: 2.0096 - val_root_loss: 1.6251 - val_vowel_loss: 0.3062 - val_consonant_loss: 0.3092 - val_root_accuracy: 0.6167 - val_vowel_accuracy: 0.9273 - val_consonant_accuracy: 0.9123\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 1.9221 - root_loss: 1.4248 - vowel_loss: 0.2453 - consonant_loss: 0.2521 - root_accuracy: 0.6279 - vowel_accuracy: 0.9310 - consonant_accuracy: 0.9241 - val_loss: 1.9003 - val_root_loss: 1.5343 - val_vowel_loss: 0.2845 - val_consonant_loss: 0.2873 - val_root_accuracy: 0.6183 - val_vowel_accuracy: 0.9258 - val_consonant_accuracy: 0.9152\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 1.7296 - root_loss: 1.2956 - vowel_loss: 0.2157 - consonant_loss: 0.2183 - root_accuracy: 0.6485 - vowel_accuracy: 0.9354 - consonant_accuracy: 0.9313 - val_loss: 1.8294 - val_root_loss: 1.4789 - val_vowel_loss: 0.2729 - val_consonant_loss: 0.2752 - val_root_accuracy: 0.6263 - val_vowel_accuracy: 0.9273 - val_consonant_accuracy: 0.9169\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 1.5959 - root_loss: 1.2002 - vowel_loss: 0.1982 - consonant_loss: 0.1975 - root_accuracy: 0.6667 - vowel_accuracy: 0.9396 - consonant_accuracy: 0.9368 - val_loss: 1.8036 - val_root_loss: 1.4431 - val_vowel_loss: 0.2643 - val_consonant_loss: 0.2682 - val_root_accuracy: 0.6273 - val_vowel_accuracy: 0.9287 - val_consonant_accuracy: 0.9177\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 1.4718 - root_loss: 1.1166 - vowel_loss: 0.1776 - consonant_loss: 0.1776 - root_accuracy: 0.6850 - vowel_accuracy: 0.9451 - consonant_accuracy: 0.9414 - val_loss: 1.7808 - val_root_loss: 1.4212 - val_vowel_loss: 0.2601 - val_consonant_loss: 0.2647 - val_root_accuracy: 0.6277 - val_vowel_accuracy: 0.9302 - val_consonant_accuracy: 0.9185\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.3784 - root_loss: 1.0483 - vowel_loss: 0.1637 - consonant_loss: 0.1665 - root_accuracy: 0.7004 - vowel_accuracy: 0.9482 - consonant_accuracy: 0.9450 - val_loss: 1.7754 - val_root_loss: 1.4087 - val_vowel_loss: 0.2583 - val_consonant_loss: 0.2633 - val_root_accuracy: 0.6283 - val_vowel_accuracy: 0.9279 - val_consonant_accuracy: 0.9173\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 1.2904 - root_loss: 0.9871 - vowel_loss: 0.1510 - consonant_loss: 0.1523 - root_accuracy: 0.7132 - vowel_accuracy: 0.9513 - consonant_accuracy: 0.9493 - val_loss: 1.7643 - val_root_loss: 1.3964 - val_vowel_loss: 0.2545 - val_consonant_loss: 0.2626 - val_root_accuracy: 0.6335 - val_vowel_accuracy: 0.9290 - val_consonant_accuracy: 0.9183\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.2201 - root_loss: 0.9364 - vowel_loss: 0.1421 - consonant_loss: 0.1416 - root_accuracy: 0.7280 - vowel_accuracy: 0.9545 - consonant_accuracy: 0.9517 - val_loss: 1.7620 - val_root_loss: 1.3943 - val_vowel_loss: 0.2563 - val_consonant_loss: 0.2637 - val_root_accuracy: 0.6319 - val_vowel_accuracy: 0.9304 - val_consonant_accuracy: 0.9183\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 1.1394 - root_loss: 0.8777 - vowel_loss: 0.1305 - consonant_loss: 0.1312 - root_accuracy: 0.7434 - vowel_accuracy: 0.9583 - consonant_accuracy: 0.9558 - val_loss: 1.7634 - val_root_loss: 1.3891 - val_vowel_loss: 0.2563 - val_consonant_loss: 0.2639 - val_root_accuracy: 0.6313 - val_vowel_accuracy: 0.9287 - val_consonant_accuracy: 0.9208\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 1.0718 - root_loss: 0.8286 - vowel_loss: 0.1223 - consonant_loss: 0.1209 - root_accuracy: 0.7547 - vowel_accuracy: 0.9612 - consonant_accuracy: 0.9588 - val_loss: 1.7800 - val_root_loss: 1.3908 - val_vowel_loss: 0.2562 - val_consonant_loss: 0.2671 - val_root_accuracy: 0.6354 - val_vowel_accuracy: 0.9300 - val_consonant_accuracy: 0.9206\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.0100 - root_loss: 0.7832 - vowel_loss: 0.1131 - consonant_loss: 0.1137 - root_accuracy: 0.7671 - vowel_accuracy: 0.9644 - consonant_accuracy: 0.9615 - val_loss: 1.7794 - val_root_loss: 1.3918 - val_vowel_loss: 0.2569 - val_consonant_loss: 0.2683 - val_root_accuracy: 0.6342 - val_vowel_accuracy: 0.9298 - val_consonant_accuracy: 0.9217\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.9455 - root_loss: 0.7407 - vowel_loss: 0.1028 - consonant_loss: 0.1020 - root_accuracy: 0.7804 - vowel_accuracy: 0.9673 - consonant_accuracy: 0.9647 - val_loss: 1.7925 - val_root_loss: 1.3966 - val_vowel_loss: 0.2602 - val_consonant_loss: 0.2709 - val_root_accuracy: 0.6358 - val_vowel_accuracy: 0.9290 - val_consonant_accuracy: 0.9187\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.8896 - root_loss: 0.6903 - vowel_loss: 0.1015 - consonant_loss: 0.0979 - root_accuracy: 0.7949 - vowel_accuracy: 0.9678 - consonant_accuracy: 0.9670 - val_loss: 1.7978 - val_root_loss: 1.4027 - val_vowel_loss: 0.2616 - val_consonant_loss: 0.2751 - val_root_accuracy: 0.6381 - val_vowel_accuracy: 0.9285 - val_consonant_accuracy: 0.9196\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.8294 - root_loss: 0.6537 - vowel_loss: 0.0894 - consonant_loss: 0.0862 - root_accuracy: 0.8039 - vowel_accuracy: 0.9723 - consonant_accuracy: 0.9710 - val_loss: 1.8255 - val_root_loss: 1.4109 - val_vowel_loss: 0.2660 - val_consonant_loss: 0.2792 - val_root_accuracy: 0.6375 - val_vowel_accuracy: 0.9290 - val_consonant_accuracy: 0.9204\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.7816 - root_loss: 0.6149 - vowel_loss: 0.0856 - consonant_loss: 0.0812 - root_accuracy: 0.8146 - vowel_accuracy: 0.9729 - consonant_accuracy: 0.9723 - val_loss: 1.8287 - val_root_loss: 1.4173 - val_vowel_loss: 0.2669 - val_consonant_loss: 0.2836 - val_root_accuracy: 0.6365 - val_vowel_accuracy: 0.9285 - val_consonant_accuracy: 0.9198\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.7327 - root_loss: 0.5781 - vowel_loss: 0.0805 - consonant_loss: 0.0742 - root_accuracy: 0.8262 - vowel_accuracy: 0.9743 - consonant_accuracy: 0.9754 - val_loss: 1.8523 - val_root_loss: 1.4354 - val_vowel_loss: 0.2707 - val_consonant_loss: 0.2896 - val_root_accuracy: 0.6394 - val_vowel_accuracy: 0.9283 - val_consonant_accuracy: 0.9212\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.6898 - root_loss: 0.5437 - vowel_loss: 0.0773 - consonant_loss: 0.0688 - root_accuracy: 0.8367 - vowel_accuracy: 0.9746 - consonant_accuracy: 0.9774 - val_loss: 1.8450 - val_root_loss: 1.4449 - val_vowel_loss: 0.2750 - val_consonant_loss: 0.2953 - val_root_accuracy: 0.6400 - val_vowel_accuracy: 0.9287 - val_consonant_accuracy: 0.9212\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.6443 - root_loss: 0.5093 - vowel_loss: 0.0704 - consonant_loss: 0.0646 - root_accuracy: 0.8465 - vowel_accuracy: 0.9768 - consonant_accuracy: 0.9779 - val_loss: 1.8995 - val_root_loss: 1.4605 - val_vowel_loss: 0.2781 - val_consonant_loss: 0.3009 - val_root_accuracy: 0.6377 - val_vowel_accuracy: 0.9277 - val_consonant_accuracy: 0.9200\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.6026 - root_loss: 0.4765 - vowel_loss: 0.0667 - consonant_loss: 0.0593 - root_accuracy: 0.8566 - vowel_accuracy: 0.9780 - consonant_accuracy: 0.9802 - val_loss: 1.8765 - val_root_loss: 1.4702 - val_vowel_loss: 0.2801 - val_consonant_loss: 0.3063 - val_root_accuracy: 0.6415 - val_vowel_accuracy: 0.9273 - val_consonant_accuracy: 0.9181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.5581 - root_loss: 0.4436 - vowel_loss: 0.0608 - consonant_loss: 0.0536 - root_accuracy: 0.8650 - vowel_accuracy: 0.9808 - consonant_accuracy: 0.9820 - val_loss: 1.9001 - val_root_loss: 1.4830 - val_vowel_loss: 0.2847 - val_consonant_loss: 0.3122 - val_root_accuracy: 0.6419 - val_vowel_accuracy: 0.9290 - val_consonant_accuracy: 0.9200\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.5213 - root_loss: 0.4137 - vowel_loss: 0.0574 - consonant_loss: 0.0502 - root_accuracy: 0.8747 - vowel_accuracy: 0.9814 - consonant_accuracy: 0.9830 - val_loss: 1.9169 - val_root_loss: 1.4937 - val_vowel_loss: 0.2873 - val_consonant_loss: 0.3174 - val_root_accuracy: 0.6433 - val_vowel_accuracy: 0.9277 - val_consonant_accuracy: 0.9192\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.4893 - root_loss: 0.3897 - vowel_loss: 0.0543 - consonant_loss: 0.0453 - root_accuracy: 0.8834 - vowel_accuracy: 0.9818 - consonant_accuracy: 0.9854 - val_loss: 1.9572 - val_root_loss: 1.5048 - val_vowel_loss: 0.2881 - val_consonant_loss: 0.3225 - val_root_accuracy: 0.6442 - val_vowel_accuracy: 0.9277 - val_consonant_accuracy: 0.9194\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.4638 - root_loss: 0.3701 - vowel_loss: 0.0499 - consonant_loss: 0.0438 - root_accuracy: 0.8881 - vowel_accuracy: 0.9842 - consonant_accuracy: 0.9858 - val_loss: 1.9701 - val_root_loss: 1.5177 - val_vowel_loss: 0.2934 - val_consonant_loss: 0.3271 - val_root_accuracy: 0.6433 - val_vowel_accuracy: 0.9275 - val_consonant_accuracy: 0.9192\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.4236 - root_loss: 0.3380 - vowel_loss: 0.0477 - consonant_loss: 0.0379 - root_accuracy: 0.8977 - vowel_accuracy: 0.9851 - consonant_accuracy: 0.9877 - val_loss: 1.9783 - val_root_loss: 1.5266 - val_vowel_loss: 0.2961 - val_consonant_loss: 0.3306 - val_root_accuracy: 0.6454 - val_vowel_accuracy: 0.9269 - val_consonant_accuracy: 0.9200\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.4010 - root_loss: 0.3186 - vowel_loss: 0.0444 - consonant_loss: 0.0380 - root_accuracy: 0.9040 - vowel_accuracy: 0.9860 - consonant_accuracy: 0.9870 - val_loss: 2.0028 - val_root_loss: 1.5340 - val_vowel_loss: 0.2984 - val_consonant_loss: 0.3343 - val_root_accuracy: 0.6431 - val_vowel_accuracy: 0.9277 - val_consonant_accuracy: 0.9192\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.3756 - root_loss: 0.2994 - vowel_loss: 0.0415 - consonant_loss: 0.0347 - root_accuracy: 0.9102 - vowel_accuracy: 0.9867 - consonant_accuracy: 0.9889 - val_loss: 2.0341 - val_root_loss: 1.5462 - val_vowel_loss: 0.3016 - val_consonant_loss: 0.3352 - val_root_accuracy: 0.6415 - val_vowel_accuracy: 0.9275 - val_consonant_accuracy: 0.9212\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 0.3461 - root_loss: 0.2748 - vowel_loss: 0.0400 - consonant_loss: 0.0314 - root_accuracy: 0.9192 - vowel_accuracy: 0.9872 - consonant_accuracy: 0.9906 - val_loss: 2.0378 - val_root_loss: 1.5601 - val_vowel_loss: 0.3041 - val_consonant_loss: 0.3460 - val_root_accuracy: 0.6423 - val_vowel_accuracy: 0.9275 - val_consonant_accuracy: 0.9194\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.3291 - root_loss: 0.2604 - vowel_loss: 0.0373 - consonant_loss: 0.0314 - root_accuracy: 0.9229 - vowel_accuracy: 0.9884 - consonant_accuracy: 0.9900 - val_loss: 2.0503 - val_root_loss: 1.5711 - val_vowel_loss: 0.3088 - val_consonant_loss: 0.3479 - val_root_accuracy: 0.6452 - val_vowel_accuracy: 0.9267 - val_consonant_accuracy: 0.9221\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.3070 - root_loss: 0.2441 - vowel_loss: 0.0352 - consonant_loss: 0.0277 - root_accuracy: 0.9275 - vowel_accuracy: 0.9893 - consonant_accuracy: 0.9914 - val_loss: 2.0685 - val_root_loss: 1.5820 - val_vowel_loss: 0.3090 - val_consonant_loss: 0.3554 - val_root_accuracy: 0.6429 - val_vowel_accuracy: 0.9277 - val_consonant_accuracy: 0.9200\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.2894 - root_loss: 0.2303 - vowel_loss: 0.0327 - consonant_loss: 0.0264 - root_accuracy: 0.9328 - vowel_accuracy: 0.9898 - consonant_accuracy: 0.9918 - val_loss: 2.0959 - val_root_loss: 1.5930 - val_vowel_loss: 0.3118 - val_consonant_loss: 0.3573 - val_root_accuracy: 0.6469 - val_vowel_accuracy: 0.9279 - val_consonant_accuracy: 0.9208\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 0.2657 - root_loss: 0.2108 - vowel_loss: 0.0304 - consonant_loss: 0.0245 - root_accuracy: 0.9389 - vowel_accuracy: 0.9905 - consonant_accuracy: 0.9921 - val_loss: 2.1336 - val_root_loss: 1.6069 - val_vowel_loss: 0.3148 - val_consonant_loss: 0.3645 - val_root_accuracy: 0.6452 - val_vowel_accuracy: 0.9281 - val_consonant_accuracy: 0.9200\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.2463 - root_loss: 0.1945 - vowel_loss: 0.0285 - consonant_loss: 0.0232 - root_accuracy: 0.9446 - vowel_accuracy: 0.9913 - consonant_accuracy: 0.9929 - val_loss: 2.1235 - val_root_loss: 1.6205 - val_vowel_loss: 0.3172 - val_consonant_loss: 0.3677 - val_root_accuracy: 0.6458 - val_vowel_accuracy: 0.9273 - val_consonant_accuracy: 0.9202\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.2318 - root_loss: 0.1850 - vowel_loss: 0.0262 - consonant_loss: 0.0206 - root_accuracy: 0.9474 - vowel_accuracy: 0.9925 - consonant_accuracy: 0.9939 - val_loss: 2.1381 - val_root_loss: 1.6262 - val_vowel_loss: 0.3175 - val_consonant_loss: 0.3703 - val_root_accuracy: 0.6471 - val_vowel_accuracy: 0.9283 - val_consonant_accuracy: 0.9196\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.2220 - root_loss: 0.1754 - vowel_loss: 0.0258 - consonant_loss: 0.0209 - root_accuracy: 0.9502 - vowel_accuracy: 0.9925 - consonant_accuracy: 0.9936 - val_loss: 2.1798 - val_root_loss: 1.6394 - val_vowel_loss: 0.3200 - val_consonant_loss: 0.3758 - val_root_accuracy: 0.6429 - val_vowel_accuracy: 0.9262 - val_consonant_accuracy: 0.9198\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 0.2079 - root_loss: 0.1614 - vowel_loss: 0.0261 - consonant_loss: 0.0203 - root_accuracy: 0.9551 - vowel_accuracy: 0.9918 - consonant_accuracy: 0.9936 - val_loss: 2.1860 - val_root_loss: 1.6497 - val_vowel_loss: 0.3219 - val_consonant_loss: 0.3800 - val_root_accuracy: 0.6425 - val_vowel_accuracy: 0.9281 - val_consonant_accuracy: 0.9200\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1933 - root_loss: 0.1499 - vowel_loss: 0.0249 - consonant_loss: 0.0185 - root_accuracy: 0.9592 - vowel_accuracy: 0.9926 - consonant_accuracy: 0.9945 - val_loss: 2.2020 - val_root_loss: 1.6576 - val_vowel_loss: 0.3246 - val_consonant_loss: 0.3832 - val_root_accuracy: 0.6456 - val_vowel_accuracy: 0.9287 - val_consonant_accuracy: 0.9190\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1797 - root_loss: 0.1385 - vowel_loss: 0.0234 - consonant_loss: 0.0178 - root_accuracy: 0.9631 - vowel_accuracy: 0.9930 - consonant_accuracy: 0.9948 - val_loss: 2.1984 - val_root_loss: 1.6722 - val_vowel_loss: 0.3289 - val_consonant_loss: 0.3900 - val_root_accuracy: 0.6473 - val_vowel_accuracy: 0.9287 - val_consonant_accuracy: 0.9190\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1678 - root_loss: 0.1308 - vowel_loss: 0.0208 - consonant_loss: 0.0163 - root_accuracy: 0.9639 - vowel_accuracy: 0.9942 - consonant_accuracy: 0.9957 - val_loss: 2.2385 - val_root_loss: 1.6813 - val_vowel_loss: 0.3305 - val_consonant_loss: 0.3929 - val_root_accuracy: 0.6440 - val_vowel_accuracy: 0.9285 - val_consonant_accuracy: 0.9192\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1633 - root_loss: 0.1264 - vowel_loss: 0.0219 - consonant_loss: 0.0151 - root_accuracy: 0.9667 - vowel_accuracy: 0.9937 - consonant_accuracy: 0.9957 - val_loss: 2.2306 - val_root_loss: 1.6938 - val_vowel_loss: 0.3311 - val_consonant_loss: 0.3939 - val_root_accuracy: 0.6471 - val_vowel_accuracy: 0.9279 - val_consonant_accuracy: 0.9181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1510 - root_loss: 0.1155 - vowel_loss: 0.0214 - consonant_loss: 0.0140 - root_accuracy: 0.9696 - vowel_accuracy: 0.9934 - consonant_accuracy: 0.9960 - val_loss: 2.2634 - val_root_loss: 1.6984 - val_vowel_loss: 0.3342 - val_consonant_loss: 0.3989 - val_root_accuracy: 0.6460 - val_vowel_accuracy: 0.9275 - val_consonant_accuracy: 0.9190\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1444 - root_loss: 0.1123 - vowel_loss: 0.0180 - consonant_loss: 0.0142 - root_accuracy: 0.9703 - vowel_accuracy: 0.9948 - consonant_accuracy: 0.9960 - val_loss: 2.2636 - val_root_loss: 1.7100 - val_vowel_loss: 0.3349 - val_consonant_loss: 0.4023 - val_root_accuracy: 0.6452 - val_vowel_accuracy: 0.9285 - val_consonant_accuracy: 0.9194\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1324 - root_loss: 0.1021 - vowel_loss: 0.0175 - consonant_loss: 0.0128 - root_accuracy: 0.9747 - vowel_accuracy: 0.9953 - consonant_accuracy: 0.9965 - val_loss: 2.2759 - val_root_loss: 1.7148 - val_vowel_loss: 0.3390 - val_consonant_loss: 0.4046 - val_root_accuracy: 0.6477 - val_vowel_accuracy: 0.9287 - val_consonant_accuracy: 0.9198\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1273 - root_loss: 0.0969 - vowel_loss: 0.0171 - consonant_loss: 0.0133 - root_accuracy: 0.9752 - vowel_accuracy: 0.9954 - consonant_accuracy: 0.9964 - val_loss: 2.3025 - val_root_loss: 1.7252 - val_vowel_loss: 0.3436 - val_consonant_loss: 0.4100 - val_root_accuracy: 0.6471 - val_vowel_accuracy: 0.9269 - val_consonant_accuracy: 0.9202\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1188 - root_loss: 0.0916 - vowel_loss: 0.0156 - consonant_loss: 0.0116 - root_accuracy: 0.9774 - vowel_accuracy: 0.9959 - consonant_accuracy: 0.9968 - val_loss: 2.3267 - val_root_loss: 1.7437 - val_vowel_loss: 0.3439 - val_consonant_loss: 0.4135 - val_root_accuracy: 0.6492 - val_vowel_accuracy: 0.9277 - val_consonant_accuracy: 0.9206\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1124 - root_loss: 0.0843 - vowel_loss: 0.0163 - consonant_loss: 0.0118 - root_accuracy: 0.9797 - vowel_accuracy: 0.9954 - consonant_accuracy: 0.9969 - val_loss: 2.3305 - val_root_loss: 1.7462 - val_vowel_loss: 0.3476 - val_consonant_loss: 0.4175 - val_root_accuracy: 0.6485 - val_vowel_accuracy: 0.9258 - val_consonant_accuracy: 0.9190\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1081 - root_loss: 0.0814 - vowel_loss: 0.0158 - consonant_loss: 0.0110 - root_accuracy: 0.9801 - vowel_accuracy: 0.9957 - consonant_accuracy: 0.9972 - val_loss: 2.3565 - val_root_loss: 1.7596 - val_vowel_loss: 0.3476 - val_consonant_loss: 0.4187 - val_root_accuracy: 0.6452 - val_vowel_accuracy: 0.9281 - val_consonant_accuracy: 0.9177\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.1003 - root_loss: 0.0755 - vowel_loss: 0.0146 - consonant_loss: 0.0102 - root_accuracy: 0.9824 - vowel_accuracy: 0.9962 - consonant_accuracy: 0.9974 - val_loss: 2.3833 - val_root_loss: 1.7671 - val_vowel_loss: 0.3490 - val_consonant_loss: 0.4237 - val_root_accuracy: 0.6465 - val_vowel_accuracy: 0.9279 - val_consonant_accuracy: 0.9192\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.0965 - root_loss: 0.0724 - vowel_loss: 0.0133 - consonant_loss: 0.0109 - root_accuracy: 0.9831 - vowel_accuracy: 0.9966 - consonant_accuracy: 0.9968 - val_loss: 2.3870 - val_root_loss: 1.7715 - val_vowel_loss: 0.3514 - val_consonant_loss: 0.4253 - val_root_accuracy: 0.6490 - val_vowel_accuracy: 0.9269 - val_consonant_accuracy: 0.9181\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 0.0918 - root_loss: 0.0691 - vowel_loss: 0.0134 - consonant_loss: 0.0094 - root_accuracy: 0.9835 - vowel_accuracy: 0.9962 - consonant_accuracy: 0.9974 - val_loss: 2.3534 - val_root_loss: 1.7865 - val_vowel_loss: 0.3540 - val_consonant_loss: 0.4273 - val_root_accuracy: 0.6454 - val_vowel_accuracy: 0.9277 - val_consonant_accuracy: 0.9177\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.0903 - root_loss: 0.0675 - vowel_loss: 0.0130 - consonant_loss: 0.0098 - root_accuracy: 0.9846 - vowel_accuracy: 0.9966 - consonant_accuracy: 0.9976 - val_loss: 2.4082 - val_root_loss: 1.7987 - val_vowel_loss: 0.3579 - val_consonant_loss: 0.4313 - val_root_accuracy: 0.6490 - val_vowel_accuracy: 0.9281 - val_consonant_accuracy: 0.9181\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0850 - root_loss: 0.0622 - vowel_loss: 0.0130 - consonant_loss: 0.0098 - root_accuracy: 0.9870 - vowel_accuracy: 0.9966 - consonant_accuracy: 0.9974 - val_loss: 2.3746 - val_root_loss: 1.7962 - val_vowel_loss: 0.3568 - val_consonant_loss: 0.4361 - val_root_accuracy: 0.6496 - val_vowel_accuracy: 0.9306 - val_consonant_accuracy: 0.9169\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.0798 - root_loss: 0.0589 - vowel_loss: 0.0117 - consonant_loss: 0.0091 - root_accuracy: 0.9867 - vowel_accuracy: 0.9968 - consonant_accuracy: 0.9975 - val_loss: 2.4308 - val_root_loss: 1.8072 - val_vowel_loss: 0.3569 - val_consonant_loss: 0.4333 - val_root_accuracy: 0.6467 - val_vowel_accuracy: 0.9273 - val_consonant_accuracy: 0.9183\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.0758 - root_loss: 0.0565 - vowel_loss: 0.0105 - consonant_loss: 0.0087 - root_accuracy: 0.9878 - vowel_accuracy: 0.9975 - consonant_accuracy: 0.9976 - val_loss: 2.4221 - val_root_loss: 1.8093 - val_vowel_loss: 0.3580 - val_consonant_loss: 0.4349 - val_root_accuracy: 0.6498 - val_vowel_accuracy: 0.9287 - val_consonant_accuracy: 0.9196\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0715 - root_loss: 0.0526 - vowel_loss: 0.0105 - consonant_loss: 0.0084 - root_accuracy: 0.9884 - vowel_accuracy: 0.9974 - consonant_accuracy: 0.9975 - val_loss: 2.4227 - val_root_loss: 1.8204 - val_vowel_loss: 0.3567 - val_consonant_loss: 0.4411 - val_root_accuracy: 0.6458 - val_vowel_accuracy: 0.9290 - val_consonant_accuracy: 0.9190\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0687 - root_loss: 0.0510 - vowel_loss: 0.0106 - consonant_loss: 0.0071 - root_accuracy: 0.9886 - vowel_accuracy: 0.9976 - consonant_accuracy: 0.9984 - val_loss: 2.4542 - val_root_loss: 1.8241 - val_vowel_loss: 0.3621 - val_consonant_loss: 0.4493 - val_root_accuracy: 0.6471 - val_vowel_accuracy: 0.9298 - val_consonant_accuracy: 0.9192\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0667 - root_loss: 0.0488 - vowel_loss: 0.0103 - consonant_loss: 0.0076 - root_accuracy: 0.9895 - vowel_accuracy: 0.9975 - consonant_accuracy: 0.9978 - val_loss: 2.4525 - val_root_loss: 1.8326 - val_vowel_loss: 0.3677 - val_consonant_loss: 0.4504 - val_root_accuracy: 0.6510 - val_vowel_accuracy: 0.9294 - val_consonant_accuracy: 0.9190\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.0646 - root_loss: 0.0478 - vowel_loss: 0.0097 - consonant_loss: 0.0070 - root_accuracy: 0.9890 - vowel_accuracy: 0.9973 - consonant_accuracy: 0.9981 - val_loss: 2.4630 - val_root_loss: 1.8478 - val_vowel_loss: 0.3679 - val_consonant_loss: 0.4516 - val_root_accuracy: 0.6473 - val_vowel_accuracy: 0.9300 - val_consonant_accuracy: 0.9177\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0609 - root_loss: 0.0451 - vowel_loss: 0.0092 - consonant_loss: 0.0065 - root_accuracy: 0.9908 - vowel_accuracy: 0.9978 - consonant_accuracy: 0.9984 - val_loss: 2.4766 - val_root_loss: 1.8537 - val_vowel_loss: 0.3671 - val_consonant_loss: 0.4569 - val_root_accuracy: 0.6488 - val_vowel_accuracy: 0.9312 - val_consonant_accuracy: 0.9179\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0587 - root_loss: 0.0428 - vowel_loss: 0.0088 - consonant_loss: 0.0071 - root_accuracy: 0.9911 - vowel_accuracy: 0.9981 - consonant_accuracy: 0.9983 - val_loss: 2.4814 - val_root_loss: 1.8712 - val_vowel_loss: 0.3711 - val_consonant_loss: 0.4605 - val_root_accuracy: 0.6467 - val_vowel_accuracy: 0.9296 - val_consonant_accuracy: 0.9169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0560 - root_loss: 0.0414 - vowel_loss: 0.0086 - consonant_loss: 0.0061 - root_accuracy: 0.9912 - vowel_accuracy: 0.9980 - consonant_accuracy: 0.9983 - val_loss: 2.4936 - val_root_loss: 1.8696 - val_vowel_loss: 0.3711 - val_consonant_loss: 0.4592 - val_root_accuracy: 0.6479 - val_vowel_accuracy: 0.9298 - val_consonant_accuracy: 0.9194\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0557 - root_loss: 0.0404 - vowel_loss: 0.0088 - consonant_loss: 0.0065 - root_accuracy: 0.9914 - vowel_accuracy: 0.9977 - consonant_accuracy: 0.9983 - val_loss: 2.4758 - val_root_loss: 1.8743 - val_vowel_loss: 0.3709 - val_consonant_loss: 0.4655 - val_root_accuracy: 0.6508 - val_vowel_accuracy: 0.9283 - val_consonant_accuracy: 0.9196\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0539 - root_loss: 0.0386 - vowel_loss: 0.0088 - consonant_loss: 0.0065 - root_accuracy: 0.9918 - vowel_accuracy: 0.9979 - consonant_accuracy: 0.9983 - val_loss: 2.5011 - val_root_loss: 1.8799 - val_vowel_loss: 0.3690 - val_consonant_loss: 0.4652 - val_root_accuracy: 0.6456 - val_vowel_accuracy: 0.9302 - val_consonant_accuracy: 0.9162\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0486 - root_loss: 0.0357 - vowel_loss: 0.0076 - consonant_loss: 0.0053 - root_accuracy: 0.9928 - vowel_accuracy: 0.9981 - consonant_accuracy: 0.9987 - val_loss: 2.4713 - val_root_loss: 1.8871 - val_vowel_loss: 0.3684 - val_consonant_loss: 0.4683 - val_root_accuracy: 0.6467 - val_vowel_accuracy: 0.9308 - val_consonant_accuracy: 0.9177\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0484 - root_loss: 0.0347 - vowel_loss: 0.0084 - consonant_loss: 0.0052 - root_accuracy: 0.9933 - vowel_accuracy: 0.9977 - consonant_accuracy: 0.9987 - val_loss: 2.4932 - val_root_loss: 1.9030 - val_vowel_loss: 0.3737 - val_consonant_loss: 0.4714 - val_root_accuracy: 0.6450 - val_vowel_accuracy: 0.9298 - val_consonant_accuracy: 0.9175\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.0461 - root_loss: 0.0339 - vowel_loss: 0.0069 - consonant_loss: 0.0053 - root_accuracy: 0.9933 - vowel_accuracy: 0.9985 - consonant_accuracy: 0.9988 - val_loss: 2.5270 - val_root_loss: 1.9020 - val_vowel_loss: 0.3749 - val_consonant_loss: 0.4720 - val_root_accuracy: 0.6510 - val_vowel_accuracy: 0.9302 - val_consonant_accuracy: 0.9183\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 39s 258ms/step - loss: 0.0459 - root_loss: 0.0329 - vowel_loss: 0.0078 - consonant_loss: 0.0052 - root_accuracy: 0.9931 - vowel_accuracy: 0.9977 - consonant_accuracy: 0.9988 - val_loss: 2.4965 - val_root_loss: 1.8992 - val_vowel_loss: 0.3775 - val_consonant_loss: 0.4713 - val_root_accuracy: 0.6500 - val_vowel_accuracy: 0.9300 - val_consonant_accuracy: 0.9185\n",
      "Epoch 00067: early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3266dd6605724b9584b2903c64558aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=45189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827b2f5624cc43a493f5d65d12689b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5021.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 2.8654 - root_loss: 1.9894 - vowel_loss: 0.4120 - consonant_loss: 0.4640 - root_accuracy: 0.6173 - vowel_accuracy: 0.9173 - consonant_accuracy: 0.9135 - val_loss: 2.6415 - val_root_loss: 1.6043 - val_vowel_loss: 0.2930 - val_consonant_loss: 0.3562 - val_root_accuracy: 0.6579 - val_vowel_accuracy: 0.9300 - val_consonant_accuracy: 0.9162\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 39s 258ms/step - loss: 1.8204 - root_loss: 1.3230 - vowel_loss: 0.2478 - consonant_loss: 0.2496 - root_accuracy: 0.6779 - vowel_accuracy: 0.9358 - consonant_accuracy: 0.9338 - val_loss: 2.3550 - val_root_loss: 1.4786 - val_vowel_loss: 0.2643 - val_consonant_loss: 0.3184 - val_root_accuracy: 0.6658 - val_vowel_accuracy: 0.9356 - val_consonant_accuracy: 0.9175\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 39s 258ms/step - loss: 1.5058 - root_loss: 1.1136 - vowel_loss: 0.1986 - consonant_loss: 0.1935 - root_accuracy: 0.7052 - vowel_accuracy: 0.9436 - consonant_accuracy: 0.9433 - val_loss: 2.2368 - val_root_loss: 1.3982 - val_vowel_loss: 0.2518 - val_consonant_loss: 0.2984 - val_root_accuracy: 0.6671 - val_vowel_accuracy: 0.9375 - val_consonant_accuracy: 0.9204\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 39s 258ms/step - loss: 1.3279 - root_loss: 0.9890 - vowel_loss: 0.1733 - consonant_loss: 0.1656 - root_accuracy: 0.7284 - vowel_accuracy: 0.9486 - consonant_accuracy: 0.9480 - val_loss: 2.1484 - val_root_loss: 1.3534 - val_vowel_loss: 0.2425 - val_consonant_loss: 0.2882 - val_root_accuracy: 0.6740 - val_vowel_accuracy: 0.9350 - val_consonant_accuracy: 0.9219\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 1.1940 - root_loss: 0.8961 - vowel_loss: 0.1535 - consonant_loss: 0.1444 - root_accuracy: 0.7471 - vowel_accuracy: 0.9530 - consonant_accuracy: 0.9557 - val_loss: 2.1073 - val_root_loss: 1.3248 - val_vowel_loss: 0.2377 - val_consonant_loss: 0.2822 - val_root_accuracy: 0.6767 - val_vowel_accuracy: 0.9360 - val_consonant_accuracy: 0.9246\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 39s 261ms/step - loss: 1.0867 - root_loss: 0.8224 - vowel_loss: 0.1345 - consonant_loss: 0.1298 - root_accuracy: 0.7628 - vowel_accuracy: 0.9580 - consonant_accuracy: 0.9577 - val_loss: 2.0753 - val_root_loss: 1.3137 - val_vowel_loss: 0.2367 - val_consonant_loss: 0.2813 - val_root_accuracy: 0.6798 - val_vowel_accuracy: 0.9373 - val_consonant_accuracy: 0.9248\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 1.0097 - root_loss: 0.7743 - vowel_loss: 0.1209 - consonant_loss: 0.1145 - root_accuracy: 0.7728 - vowel_accuracy: 0.9624 - consonant_accuracy: 0.9626 - val_loss: 2.0775 - val_root_loss: 1.3017 - val_vowel_loss: 0.2365 - val_consonant_loss: 0.2821 - val_root_accuracy: 0.6817 - val_vowel_accuracy: 0.9394 - val_consonant_accuracy: 0.9227\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.9336 - root_loss: 0.7187 - vowel_loss: 0.1117 - consonant_loss: 0.1031 - root_accuracy: 0.7868 - vowel_accuracy: 0.9642 - consonant_accuracy: 0.9665 - val_loss: 2.0512 - val_root_loss: 1.2977 - val_vowel_loss: 0.2367 - val_consonant_loss: 0.2827 - val_root_accuracy: 0.6827 - val_vowel_accuracy: 0.9369 - val_consonant_accuracy: 0.9244\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.8591 - root_loss: 0.6630 - vowel_loss: 0.1017 - consonant_loss: 0.0944 - root_accuracy: 0.8013 - vowel_accuracy: 0.9673 - consonant_accuracy: 0.9679 - val_loss: 2.0667 - val_root_loss: 1.2987 - val_vowel_loss: 0.2369 - val_consonant_loss: 0.2847 - val_root_accuracy: 0.6835 - val_vowel_accuracy: 0.9365 - val_consonant_accuracy: 0.9246\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.8013 - root_loss: 0.6195 - vowel_loss: 0.0952 - consonant_loss: 0.0866 - root_accuracy: 0.8140 - vowel_accuracy: 0.9688 - consonant_accuracy: 0.9714 - val_loss: 2.0775 - val_root_loss: 1.3013 - val_vowel_loss: 0.2391 - val_consonant_loss: 0.2866 - val_root_accuracy: 0.6869 - val_vowel_accuracy: 0.9369 - val_consonant_accuracy: 0.9242\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.7503 - root_loss: 0.5822 - vowel_loss: 0.0874 - consonant_loss: 0.0807 - root_accuracy: 0.8247 - vowel_accuracy: 0.9716 - consonant_accuracy: 0.9728 - val_loss: 2.0770 - val_root_loss: 1.3047 - val_vowel_loss: 0.2414 - val_consonant_loss: 0.2912 - val_root_accuracy: 0.6858 - val_vowel_accuracy: 0.9377 - val_consonant_accuracy: 0.9256\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.6900 - root_loss: 0.5372 - vowel_loss: 0.0819 - consonant_loss: 0.0709 - root_accuracy: 0.8370 - vowel_accuracy: 0.9739 - consonant_accuracy: 0.9771 - val_loss: 2.1087 - val_root_loss: 1.3208 - val_vowel_loss: 0.2458 - val_consonant_loss: 0.2959 - val_root_accuracy: 0.6885 - val_vowel_accuracy: 0.9367 - val_consonant_accuracy: 0.9242\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.6450 - root_loss: 0.5028 - vowel_loss: 0.0749 - consonant_loss: 0.0673 - root_accuracy: 0.8483 - vowel_accuracy: 0.9758 - consonant_accuracy: 0.9780 - val_loss: 2.1000 - val_root_loss: 1.3279 - val_vowel_loss: 0.2459 - val_consonant_loss: 0.3021 - val_root_accuracy: 0.6877 - val_vowel_accuracy: 0.9371 - val_consonant_accuracy: 0.9219\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.5963 - root_loss: 0.4657 - vowel_loss: 0.0693 - consonant_loss: 0.0613 - root_accuracy: 0.8577 - vowel_accuracy: 0.9776 - consonant_accuracy: 0.9794 - val_loss: 2.1153 - val_root_loss: 1.3352 - val_vowel_loss: 0.2506 - val_consonant_loss: 0.3042 - val_root_accuracy: 0.6896 - val_vowel_accuracy: 0.9375 - val_consonant_accuracy: 0.9235\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.5530 - root_loss: 0.4346 - vowel_loss: 0.0651 - consonant_loss: 0.0534 - root_accuracy: 0.8672 - vowel_accuracy: 0.9786 - consonant_accuracy: 0.9830 - val_loss: 2.1310 - val_root_loss: 1.3502 - val_vowel_loss: 0.2515 - val_consonant_loss: 0.3103 - val_root_accuracy: 0.6846 - val_vowel_accuracy: 0.9369 - val_consonant_accuracy: 0.9248\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.5106 - root_loss: 0.4009 - vowel_loss: 0.0607 - consonant_loss: 0.0490 - root_accuracy: 0.8768 - vowel_accuracy: 0.9805 - consonant_accuracy: 0.9837 - val_loss: 2.1508 - val_root_loss: 1.3640 - val_vowel_loss: 0.2560 - val_consonant_loss: 0.3173 - val_root_accuracy: 0.6896 - val_vowel_accuracy: 0.9383 - val_consonant_accuracy: 0.9219\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.4727 - root_loss: 0.3739 - vowel_loss: 0.0534 - consonant_loss: 0.0454 - root_accuracy: 0.8854 - vowel_accuracy: 0.9824 - consonant_accuracy: 0.9848 - val_loss: 2.1930 - val_root_loss: 1.3763 - val_vowel_loss: 0.2586 - val_consonant_loss: 0.3229 - val_root_accuracy: 0.6896 - val_vowel_accuracy: 0.9377 - val_consonant_accuracy: 0.9221\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.4456 - root_loss: 0.3517 - vowel_loss: 0.0509 - consonant_loss: 0.0429 - root_accuracy: 0.8921 - vowel_accuracy: 0.9832 - consonant_accuracy: 0.9857 - val_loss: 2.1989 - val_root_loss: 1.3841 - val_vowel_loss: 0.2612 - val_consonant_loss: 0.3268 - val_root_accuracy: 0.6894 - val_vowel_accuracy: 0.9367 - val_consonant_accuracy: 0.9219\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.4150 - root_loss: 0.3243 - vowel_loss: 0.0503 - consonant_loss: 0.0403 - root_accuracy: 0.8995 - vowel_accuracy: 0.9838 - consonant_accuracy: 0.9872 - val_loss: 2.2122 - val_root_loss: 1.3960 - val_vowel_loss: 0.2629 - val_consonant_loss: 0.3292 - val_root_accuracy: 0.6904 - val_vowel_accuracy: 0.9360 - val_consonant_accuracy: 0.9231\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.3824 - root_loss: 0.3003 - vowel_loss: 0.0451 - consonant_loss: 0.0370 - root_accuracy: 0.9076 - vowel_accuracy: 0.9851 - consonant_accuracy: 0.9878 - val_loss: 2.2265 - val_root_loss: 1.4047 - val_vowel_loss: 0.2661 - val_consonant_loss: 0.3342 - val_root_accuracy: 0.6921 - val_vowel_accuracy: 0.9388 - val_consonant_accuracy: 0.9227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.3480 - root_loss: 0.2734 - vowel_loss: 0.0409 - consonant_loss: 0.0336 - root_accuracy: 0.9166 - vowel_accuracy: 0.9869 - consonant_accuracy: 0.9893 - val_loss: 2.2093 - val_root_loss: 1.4163 - val_vowel_loss: 0.2675 - val_consonant_loss: 0.3402 - val_root_accuracy: 0.6883 - val_vowel_accuracy: 0.9379 - val_consonant_accuracy: 0.9244\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.3218 - root_loss: 0.2518 - vowel_loss: 0.0385 - consonant_loss: 0.0314 - root_accuracy: 0.9237 - vowel_accuracy: 0.9880 - consonant_accuracy: 0.9899 - val_loss: 2.2812 - val_root_loss: 1.4327 - val_vowel_loss: 0.2706 - val_consonant_loss: 0.3431 - val_root_accuracy: 0.6890 - val_vowel_accuracy: 0.9388 - val_consonant_accuracy: 0.9235\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.3069 - root_loss: 0.2414 - vowel_loss: 0.0367 - consonant_loss: 0.0287 - root_accuracy: 0.9261 - vowel_accuracy: 0.9876 - consonant_accuracy: 0.9910 - val_loss: 2.2867 - val_root_loss: 1.4399 - val_vowel_loss: 0.2722 - val_consonant_loss: 0.3474 - val_root_accuracy: 0.6879 - val_vowel_accuracy: 0.9381 - val_consonant_accuracy: 0.9229\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.2761 - root_loss: 0.2171 - vowel_loss: 0.0327 - consonant_loss: 0.0262 - root_accuracy: 0.9340 - vowel_accuracy: 0.9896 - consonant_accuracy: 0.9918 - val_loss: 2.2892 - val_root_loss: 1.4479 - val_vowel_loss: 0.2736 - val_consonant_loss: 0.3520 - val_root_accuracy: 0.6898 - val_vowel_accuracy: 0.9381 - val_consonant_accuracy: 0.9240\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.2636 - root_loss: 0.2058 - vowel_loss: 0.0322 - consonant_loss: 0.0256 - root_accuracy: 0.9383 - vowel_accuracy: 0.9899 - consonant_accuracy: 0.9915 - val_loss: 2.3300 - val_root_loss: 1.4608 - val_vowel_loss: 0.2762 - val_consonant_loss: 0.3565 - val_root_accuracy: 0.6910 - val_vowel_accuracy: 0.9379 - val_consonant_accuracy: 0.9229\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.2403 - root_loss: 0.1880 - vowel_loss: 0.0299 - consonant_loss: 0.0225 - root_accuracy: 0.9456 - vowel_accuracy: 0.9905 - consonant_accuracy: 0.9928 - val_loss: 2.3701 - val_root_loss: 1.4693 - val_vowel_loss: 0.2822 - val_consonant_loss: 0.3578 - val_root_accuracy: 0.6908 - val_vowel_accuracy: 0.9369 - val_consonant_accuracy: 0.9229\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.2259 - root_loss: 0.1755 - vowel_loss: 0.0279 - consonant_loss: 0.0225 - root_accuracy: 0.9494 - vowel_accuracy: 0.9916 - consonant_accuracy: 0.9928 - val_loss: 2.3848 - val_root_loss: 1.4849 - val_vowel_loss: 0.2812 - val_consonant_loss: 0.3688 - val_root_accuracy: 0.6900 - val_vowel_accuracy: 0.9392 - val_consonant_accuracy: 0.9219\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.2130 - root_loss: 0.1650 - vowel_loss: 0.0274 - consonant_loss: 0.0207 - root_accuracy: 0.9522 - vowel_accuracy: 0.9910 - consonant_accuracy: 0.9937 - val_loss: 2.4078 - val_root_loss: 1.4946 - val_vowel_loss: 0.2853 - val_consonant_loss: 0.3711 - val_root_accuracy: 0.6906 - val_vowel_accuracy: 0.9388 - val_consonant_accuracy: 0.9242\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1951 - root_loss: 0.1515 - vowel_loss: 0.0255 - consonant_loss: 0.0181 - root_accuracy: 0.9571 - vowel_accuracy: 0.9923 - consonant_accuracy: 0.9948 - val_loss: 2.4012 - val_root_loss: 1.5027 - val_vowel_loss: 0.2879 - val_consonant_loss: 0.3767 - val_root_accuracy: 0.6933 - val_vowel_accuracy: 0.9375 - val_consonant_accuracy: 0.9233\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.1808 - root_loss: 0.1403 - vowel_loss: 0.0231 - consonant_loss: 0.0175 - root_accuracy: 0.9611 - vowel_accuracy: 0.9925 - consonant_accuracy: 0.9948 - val_loss: 2.4089 - val_root_loss: 1.5102 - val_vowel_loss: 0.2908 - val_consonant_loss: 0.3812 - val_root_accuracy: 0.6898 - val_vowel_accuracy: 0.9354 - val_consonant_accuracy: 0.9223\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1769 - root_loss: 0.1359 - vowel_loss: 0.0231 - consonant_loss: 0.0179 - root_accuracy: 0.9616 - vowel_accuracy: 0.9931 - consonant_accuracy: 0.9944 - val_loss: 2.4232 - val_root_loss: 1.5148 - val_vowel_loss: 0.2892 - val_consonant_loss: 0.3791 - val_root_accuracy: 0.6923 - val_vowel_accuracy: 0.9369 - val_consonant_accuracy: 0.9231\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1626 - root_loss: 0.1244 - vowel_loss: 0.0224 - consonant_loss: 0.0158 - root_accuracy: 0.9658 - vowel_accuracy: 0.9932 - consonant_accuracy: 0.9957 - val_loss: 2.4454 - val_root_loss: 1.5190 - val_vowel_loss: 0.2898 - val_consonant_loss: 0.3838 - val_root_accuracy: 0.6927 - val_vowel_accuracy: 0.9402 - val_consonant_accuracy: 0.9227\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1519 - root_loss: 0.1154 - vowel_loss: 0.0221 - consonant_loss: 0.0144 - root_accuracy: 0.9685 - vowel_accuracy: 0.9929 - consonant_accuracy: 0.9958 - val_loss: 2.4821 - val_root_loss: 1.5318 - val_vowel_loss: 0.2911 - val_consonant_loss: 0.3898 - val_root_accuracy: 0.6923 - val_vowel_accuracy: 0.9385 - val_consonant_accuracy: 0.9242\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1409 - root_loss: 0.1068 - vowel_loss: 0.0201 - consonant_loss: 0.0140 - root_accuracy: 0.9711 - vowel_accuracy: 0.9941 - consonant_accuracy: 0.9959 - val_loss: 2.4985 - val_root_loss: 1.5469 - val_vowel_loss: 0.2929 - val_consonant_loss: 0.3926 - val_root_accuracy: 0.6925 - val_vowel_accuracy: 0.9377 - val_consonant_accuracy: 0.9223\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1332 - root_loss: 0.1009 - vowel_loss: 0.0180 - consonant_loss: 0.0142 - root_accuracy: 0.9731 - vowel_accuracy: 0.9949 - consonant_accuracy: 0.9957 - val_loss: 2.5278 - val_root_loss: 1.5518 - val_vowel_loss: 0.2959 - val_consonant_loss: 0.3983 - val_root_accuracy: 0.6908 - val_vowel_accuracy: 0.9379 - val_consonant_accuracy: 0.9237\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1235 - root_loss: 0.0932 - vowel_loss: 0.0170 - consonant_loss: 0.0133 - root_accuracy: 0.9758 - vowel_accuracy: 0.9952 - consonant_accuracy: 0.9959 - val_loss: 2.5352 - val_root_loss: 1.5624 - val_vowel_loss: 0.2982 - val_consonant_loss: 0.3994 - val_root_accuracy: 0.6904 - val_vowel_accuracy: 0.9360 - val_consonant_accuracy: 0.9235\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1205 - root_loss: 0.0898 - vowel_loss: 0.0177 - consonant_loss: 0.0131 - root_accuracy: 0.9764 - vowel_accuracy: 0.9948 - consonant_accuracy: 0.9961 - val_loss: 2.5458 - val_root_loss: 1.5671 - val_vowel_loss: 0.2975 - val_consonant_loss: 0.4051 - val_root_accuracy: 0.6902 - val_vowel_accuracy: 0.9369 - val_consonant_accuracy: 0.9227\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.1160 - root_loss: 0.0876 - vowel_loss: 0.0169 - consonant_loss: 0.0115 - root_accuracy: 0.9774 - vowel_accuracy: 0.9952 - consonant_accuracy: 0.9968 - val_loss: 2.5468 - val_root_loss: 1.5701 - val_vowel_loss: 0.3023 - val_consonant_loss: 0.4086 - val_root_accuracy: 0.6927 - val_vowel_accuracy: 0.9377 - val_consonant_accuracy: 0.9240\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 39s 259ms/step - loss: 0.1061 - root_loss: 0.0796 - vowel_loss: 0.0155 - consonant_loss: 0.0110 - root_accuracy: 0.9802 - vowel_accuracy: 0.9960 - consonant_accuracy: 0.9972 - val_loss: 2.5396 - val_root_loss: 1.5733 - val_vowel_loss: 0.3037 - val_consonant_loss: 0.4061 - val_root_accuracy: 0.6915 - val_vowel_accuracy: 0.9383 - val_consonant_accuracy: 0.9235\n",
      "Epoch 00039: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "histories = []\n",
    "for i in range(4):\n",
    "    train_df = pd.merge(pd.read_parquet(f'bengaliai-cv19/train_image_data_{i}.parquet'), train_df_, on='image_id').drop(['image_id'], axis=1)\n",
    "    \n",
    "    train_, valid_ = train_test_split(train_df, test_size = 0.10, random_state = SEED,\n",
    "                                                stratify = train_df[['grapheme_root', \n",
    "                                                                  'vowel_diacritic', \n",
    "                                                                  'consonant_diacritic']])\n",
    "    \n",
    "    # training generator\n",
    "    train_generator = GraphemeGenerator(train_, batch_size, IMG_SIZE, \n",
    "                                    shuffle = True)#, transform=transforms_train)\n",
    "\n",
    "    # validation generator: no shuffle , not augmentation\n",
    "    val_generator = GraphemeGenerator(valid_, batch_size, IMG_SIZE, \n",
    "                                  shuffle = False)\n",
    "\n",
    "\n",
    "#     checkpoint = ModelCheckpoint('model/Efficient_B3_%s.h5'% (1), \n",
    "#                                      monitor = 'val_loss', \n",
    "#                                      verbose = 0, save_best_only=True, \n",
    "#                                      mode = 'min',\n",
    "#                                      save_weights_only = True)\n",
    "\n",
    "    callbacks = [learning_rate_reduction_root, learning_rate_reduction_vowel, \n",
    "                 learning_rate_reduction_consonant,earlyStop]#,checkpoint]\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=int(train_.shape[0]/batch_size), \n",
    "        validation_data=val_generator,\n",
    "        validation_steps = int(valid_.shape[0]/batch_size),\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks)\n",
    "    \n",
    "    histories.append(history)\n",
    "        \n",
    "        \n",
    "    del train_, valid_, train_df\n",
    "    gc.collect()\n",
    "\n",
    "model.save('New_EfficientB3_64.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('dense_model7_64_early.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic','grapheme'], axis=1).loc[0]\n",
    "# # print(tmp)\n",
    "# # tmp =tmp.\n",
    "# image=tmp.values.reshape(137,236)\n",
    "# #             image = cv2.imread(im_path + self._data['image_id'][k] + '.png')\n",
    "# image = cv2.resize(image, (64,64)) \n",
    "# print(image.shape)\n",
    "# image = image.reshape((IMG_SIZE,IMG_SIZE),N_CHANNELS)\n",
    "# print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bengali",
   "language": "python",
   "name": "bengali"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
